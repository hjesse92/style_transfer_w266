{"cells":[{"cell_type":"markdown","metadata":{"id":"so-yur1S9mS4"},"source":["## 1. Setup\n","\n","### 1.1. Libraries and Helper Functions\n","\n","This notebook requires the below prerequisites that must be downloaded. "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uQnMctL9mS5","outputId":"ac44e39b-69eb-45e0-a816-41b8b6c2a3b2","executionInfo":{"status":"ok","timestamp":1680247139141,"user_tz":420,"elapsed":62009,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#@title Installs\n","!pip install transformers --quiet\n","!pip install tqdm boto3 requests regex sentencepiece sacremoses evaluate --quiet\n","!pip install rouge --quiet\n","!pip install better_profanity --quiet\n","!pip install rouge-score --quiet\n","!pip install -U evaluate --quiet"]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"j0jokLO9GqZp"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"7CALja8vLcZ9","executionInfo":{"status":"ok","timestamp":1680247145334,"user_tz":420,"elapsed":6200,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[],"source":["import torch\n","import pandas as pd\n","from tqdm import tqdm\n","# upload external file before import\n","from google.colab import files\n","\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from transformers import DistilBertTokenizer, DistilBertModel\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from rouge import Rouge \n","from nltk.translate.bleu_score import sentence_bleu\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import time\n","import datetime\n","import string\n","import regex as re\n","from google.colab import drive\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cbELEg_S5iX","outputId":"8fb20e45-9e85-4c29-cfbb-48e6f2eea0cb","executionInfo":{"status":"ok","timestamp":1680247145453,"user_tz":420,"elapsed":122,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}],"source":["# Check if a GPU is available, otherwise use CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnqrYaGuxo3M","outputId":"15a27305-d3ae-47e3-dc44-2c17b7bec3d4","executionInfo":{"status":"ok","timestamp":1680247166363,"user_tz":420,"elapsed":20919,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCThYsKtyrOn","outputId":"c75ea42e-abcb-4257-bd25-66e5afc0d54b","executionInfo":{"status":"ok","timestamp":1680247167738,"user_tz":420,"elapsed":1388,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["clean_dev.csv\tclean_train.csv   original-test.tsv   test.csv\n","clean_test.csv\toriginal-dev.tsv  original-train.tsv  train.csv\n"]}],"source":["!ls \"/content/drive/MyDrive/Colab Notebooks/data\""]},{"cell_type":"code","source":["train_path='/content/drive/MyDrive/Colab Notebooks/data/original-train.tsv'\n","dev_path='/content/drive/MyDrive/Colab Notebooks/data/original-dev.tsv'\n","test_path='/content/drive/MyDrive/Colab Notebooks/data/original-test.tsv'"],"metadata":{"id":"gMBfqnnShB06","executionInfo":{"status":"ok","timestamp":1680247167739,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train=pd.read_csv(train_path,sep=\"\\t\", header=0) \n","display(train[1:])"],"metadata":{"id":"7mzdBizMi1gj","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"1f492577-6dd3-40b4-8122-41cfb4b37e8c","executionInfo":{"status":"ok","timestamp":1680243453724,"user_tz":420,"elapsed":1145,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                         offensive-text  \\\n","1     Ok, this makes no sense. This will create vigi...   \n","2     so fucking true. the amount of up and coming r...   \n","3     Go f yourself Republican scum who put us here ...   \n","4          Dumb fucking take. People want to do things.   \n","5                                             Fuck no ğŸ˜‚   \n","...                                                 ...   \n","1579  The View! And this crap hits my front page!? l...   \n","1580                                     Thatâ€™s racist.   \n","1581     Cultural Marxism isn't a thing you weird fuck.   \n","1582  LOL, anyone that questions the Democrat progra...   \n","1583  How about you guys actually read the bill, if ...   \n","\n","                                 style-transferred-text  \n","1     Ok, this makes no sense. This will create vigi...  \n","2     so true. the amount of up and coming rappers t...  \n","3     Republicans put us in this situation. I would ...  \n","4     That's not a smart take. People want to do thi...  \n","5                                                    no  \n","...                                                 ...  \n","1579  This must be mostly bots but still, it's stran...  \n","1580                          Those actions are racist.  \n","1581                    Cultural Marxism isn't a thing.  \n","1582  LOL, anyone that questions the Democrat progra...  \n","1583            I wish everyone actually read the bill.  \n","\n","[1583 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-97833d08-67ee-4cb7-a3c4-54da531ab2df\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Ok, this makes no sense. This will create vigi...</td>\n","      <td>Ok, this makes no sense. This will create vigi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>so fucking true. the amount of up and coming r...</td>\n","      <td>so true. the amount of up and coming rappers t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go f yourself Republican scum who put us here ...</td>\n","      <td>Republicans put us in this situation. I would ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dumb fucking take. People want to do things.</td>\n","      <td>That's not a smart take. People want to do thi...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Fuck no ğŸ˜‚</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1579</th>\n","      <td>The View! And this crap hits my front page!? l...</td>\n","      <td>This must be mostly bots but still, it's stran...</td>\n","    </tr>\n","    <tr>\n","      <th>1580</th>\n","      <td>Thatâ€™s racist.</td>\n","      <td>Those actions are racist.</td>\n","    </tr>\n","    <tr>\n","      <th>1581</th>\n","      <td>Cultural Marxism isn't a thing you weird fuck.</td>\n","      <td>Cultural Marxism isn't a thing.</td>\n","    </tr>\n","    <tr>\n","      <th>1582</th>\n","      <td>LOL, anyone that questions the Democrat progra...</td>\n","      <td>LOL, anyone that questions the Democrat progra...</td>\n","    </tr>\n","    <tr>\n","      <th>1583</th>\n","      <td>How about you guys actually read the bill, if ...</td>\n","      <td>I wish everyone actually read the bill.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1583 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97833d08-67ee-4cb7-a3c4-54da531ab2df')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-97833d08-67ee-4cb7-a3c4-54da531ab2df button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-97833d08-67ee-4cb7-a3c4-54da531ab2df');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niEwhBdNFnxW","outputId":"b4b931dc-20ce-4f4e-f52e-c1b7a3f543b0","executionInfo":{"status":"ok","timestamp":1680243460781,"user_tz":420,"elapsed":407,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["238"]},"metadata":{},"execution_count":8}],"source":["train['offensive-text'].str.len().max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2MqDpHEGNyi","outputId":"da8280e4-494f-453c-ad61-66cd4bd2691b","executionInfo":{"status":"ok","timestamp":1680243463365,"user_tz":420,"elapsed":811,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":9}],"source":["train['offensive-text'].str.len().min()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBfPJTp0Tg6T","outputId":"1d8127e5-8300-4ec2-bca5-5fe456575643","executionInfo":{"status":"ok","timestamp":1680243464574,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["69.85353535353535"]},"metadata":{},"execution_count":10}],"source":["train['offensive-text'].str.len().mean()"]},{"cell_type":"code","source":["train[train['style-transferred-text']=='']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"i8Qz4GMUDCV3","outputId":"865a358d-b4d2-4d7f-9f1b-0db9bd57c0e5","executionInfo":{"status":"ok","timestamp":1680243472578,"user_tz":420,"elapsed":274,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [offensive-text, style-transferred-text]\n","Index: []"],"text/html":["\n","  <div id=\"df-681b2c4f-c26a-466e-b24f-2e8db3fc563b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-681b2c4f-c26a-466e-b24f-2e8db3fc563b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-681b2c4f-c26a-466e-b24f-2e8db3fc563b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-681b2c4f-c26a-466e-b24f-2e8db3fc563b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["dev=pd.read_csv(dev_path,sep=\"\\t\", header=0) \n","display(dev)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"rJ-0TJFCChu5","outputId":"7014b706-2942-4733-b42f-5a9413ffe4df","executionInfo":{"status":"ok","timestamp":1680243488522,"user_tz":420,"elapsed":911,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                        offensive-text  \\\n","0    Anyone who thinks canceling a pipeline and han...   \n","1    My favorite part is that youâ€™re still madly re...   \n","2    But did you try it? Lol. That and medical mari...   \n","3    By the downvotes, I see there are a bunch of u...   \n","4                         CUCKOLD Carlson is a problem   \n","..                                                 ...   \n","193                             Karma whore right here   \n","194  Anyone who is still huffing paint thinner by c...   \n","195         And you have never made a stupid decision?   \n","196  You couldn't maybe just think about this for a...   \n","197  Where the fuck are the mods? Seriously this is...   \n","\n","                                style-transferred-text  \n","0    Anyone who thinks canceling a pipeline and han...  \n","1     My favorite part is that you are still replying.  \n","2    Have you tried it? That helped my cousin's tin...  \n","3    By the downvotes, I see there are a bunch of T...  \n","4                               Carlson is the problem  \n","..                                                 ...  \n","193                       Hunting for karma right here  \n","194  Anyone who is still huffing paint thinner by c...  \n","195          And you have never made a wrong decision?  \n","196  You couldn't maybe just come up with the answe...  \n","197  Where are the mods? Seriously this is the most...  \n","\n","[198 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-1a74bdd7-5b44-45bc-afb9-b994c3d05102\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Anyone who thinks canceling a pipeline and han...</td>\n","      <td>Anyone who thinks canceling a pipeline and han...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>My favorite part is that youâ€™re still madly re...</td>\n","      <td>My favorite part is that you are still replying.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>But did you try it? Lol. That and medical mari...</td>\n","      <td>Have you tried it? That helped my cousin's tin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>By the downvotes, I see there are a bunch of u...</td>\n","      <td>By the downvotes, I see there are a bunch of T...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CUCKOLD Carlson is a problem</td>\n","      <td>Carlson is the problem</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>Karma whore right here</td>\n","      <td>Hunting for karma right here</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>Anyone who is still huffing paint thinner by c...</td>\n","      <td>Anyone who is still huffing paint thinner by c...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>And you have never made a stupid decision?</td>\n","      <td>And you have never made a wrong decision?</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>You couldn't maybe just think about this for a...</td>\n","      <td>You couldn't maybe just come up with the answe...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>Where the fuck are the mods? Seriously this is...</td>\n","      <td>Where are the mods? Seriously this is the most...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>198 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a74bdd7-5b44-45bc-afb9-b994c3d05102')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1a74bdd7-5b44-45bc-afb9-b994c3d05102 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1a74bdd7-5b44-45bc-afb9-b994c3d05102');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def read_process_data(df):\n","    # SPECIAL_CHARS_PATTERN = re.compile(r\"(\\*)|(\\=\\=)|(\\~)|(\\=)|(\\.\\.\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\|)|()|()|(\\%)|($)|(\\>)|(\\<)|(\\{)|(\\})\")\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.lower()\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n","\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \") #\\n|\\r|\\r\\n|\n","\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.lower()\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \")\n","  \n","    df['offensive-text']=df['offensive-text'].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n","\n","    print('The null count :: ',df.isnull().sum())\n","    return df"],"metadata":{"id":"5d13W9myt0w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# UNCOMMENT THIS ONE TO CREATE CLEANED DATASET : ONE TIME EFFORT\n","# x=read_process_data(train)\n","# x.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_train.csv', header = False)\n","# z=read_process_data(test)\n","# z.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_test.csv', header = False)\n","# y=read_process_data(dev)\n","# y.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_dev.csv', header = False)"],"metadata":{"id":"h1sOu0-tufhH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path='/content/drive/MyDrive/Colab Notebooks/data/clean_train.csv'\n","dev_path='/content/drive/MyDrive/Colab Notebooks/data/clean_dev.csv'\n","test_path='/content/drive/MyDrive/Colab Notebooks/data/clean_test.csv'\n","\n","def format_time(seconds):\n","    return str(datetime.timedelta(seconds=int(round(seconds))))"],"metadata":{"id":"94gfhdG80nt5","executionInfo":{"status":"ok","timestamp":1680247177264,"user_tz":420,"elapsed":119,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oeRVnvQ10d1K"},"source":["Below code is implementation of BART (Bidirectional and Auto-Regressive Transformer) model for sequence-to-sequence (seq2seq) tasks using PyTorch. The BART model is a variant of the Transformer model and is pre-trained on a large corpus of text data using a denoising autoencoder objective. It is capable of generating high-quality text with coherent sentence structures.\n","\n","The code defines a PyTorch Dataset class MyDataset that reads the input and target text sequences from a text file and tokenizes them using the BART tokenizer. It then defines the collate_fn function to pad the sequences in each batch to the same length. The code then defines the BartEncoderDecoder class, which is the main model class that uses the BART encoder and decoder architecture.\n","\n","The code instantiates the BART tokenizer and the BartEncoderDecoder model, and loads the training and validation data using the MyDataset class. It also defines the optimizer and loss function. The code then runs the training loop for a specified number of epochs, during which it trains the model on the training set and evaluates it on the validation set.\n","\n","During training, the code iterates over the batches of training data and performs forward and backward passes through the model to compute the loss and update the model parameters using the Adam optimizer. The code also implements gradient accumulation by accumulating the gradients over a specified number of batches to reduce the memory requirements during training. After training on all the batches, the code computes the average loss over the entire training set and evaluates the model on the validation set.\n","\n","During validation, the code iterates over the batches of validation data and generates the predicted text sequences using the generate method of the BART decoder. It then computes the loss between the predicted and target sequences and accumulates the loss over all the batches to compute the average loss over the entire validation set. Finally, the code prints the average training and validation loss for each epoch."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6olz1mhT-ovf","executionInfo":{"status":"ok","timestamp":1680247184310,"user_tz":420,"elapsed":3327,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["708a2e28684c43ecb270073464fd3240","9e408840d4d345b09a141a98c510214b","fb99a1f42a18459cb2ae7bfbd5ff8f6a","6f32f5662d354c7bbbaa43a05078ffa3","fa56fd27e7f140abbb7a63aa7121a876","f2e1f6b527f146ad8187ccbf9ebaa616","f0c8916eb79444d68490b7240cc18b27","c3df7f790dda4feab0b229e80576c1b5","c8825cec597a45d8b4613b3fadf03918","4fdafd22af8247aabcb64015eac9a6f6","920755c5b5da4c939ff9a27bad1b1148","384309c83eb9438190d1f2822727f397","514899b3089043c096ffc89a63fb678c","12c1a12908fc4b74bba26a4a03c9369a","27cd2b573790413992779985729b0712","ead22d8741d547aca6c66f479f19d176","8f44002026094d74a65c163c5933b1d6","6ae74445a37a477aa561a9aa54aef66f","51151a25b9004e4680a1561870870f9b","e225a4570304433d9a9f6800a7eba381","b117a937c411475a966b4cb711df08fb","630922d35fcd4ed8a50727acf03e0634","07ede60c080249f9b360c3cedcac9a50","24e5c95bbe6b45be893160970cf015c6","311b0a44d44d4e6fae006cf820970071","ec6b399f6a494b44bae1ebdc6b1fe88c","0b89f9fda6ff455abcd8f4cf0c702974","ec4148a8e0cc472b8bfe3a72a87cc207","e7ac50164034429e9d4847836948002c","4678e2c7df974891803d9471274be006","6abe1eefe6824a81a4685cd9285f35ef","9c0c703253e4444f9f401e0c20b7e8d6","3f8409b6e50c4803aa21d62f39f832fa"]},"outputId":"5773f6d0-8581-4885-e26c-bb08ef4ed0e9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708a2e28684c43ecb270073464fd3240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"384309c83eb9438190d1f2822727f397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ede60c080249f9b360c3cedcac9a50"}},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import Adam\n","from transformers import BartTokenizer, BartConfig, BartForConditionalGeneration,BartModel,AutoTokenizer\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from better_profanity import profanity\n","# the MyDataset class takes three arguments:\n","\n","# data_path: The path to the training data file.\n","# tokenizer: The tokenizer used to preprocess the input data.\n","# max_seq_len: The maximum sequence length allowed for the input sequences.\n","# In the __init__ method, the training data is loaded from the specified file, and each line of text is stored in a list.\n","\n","# In the __len__ method, the length of the dataset is returned (i.e., the number of lines in the training data file).\n","\n","# In the __getitem__ method, an individual training example is retrieved based on the specified index. The input text is tokenized using the specified tokenizer and truncated to the specified maximum sequence length, and the resulting token ids are converted to a PyTorch tensor and returned as the training example.\n","\n","# Instantiate BART tokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base') \n","profanity.load_censor_words()\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path, max_seq_len,kind):\n","        \n","        self.max_seq_len = max_seq_len\n","\n","        self.toxic_ids = []\n","        self.non_toxic_ids = []\n","        self.masked_toxic_ids=[]\n","\n","        c=0\n","        with open(data_path, 'r') as f:\n","            for line in f:\n","                line = line.strip()\n","                if line:\n","                    parts = line.split(',')\n","                    toxic_seq = parts[1]\n","                    non_toxic_seq = parts[2]\n","\n","                    censored_text = profanity.censor(toxic_seq)\n","                    masked_toxic_seq=censored_text.replace('****','<mask>')\n","               \n","                    toxic_ids = tokenizer(toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)  #, return_tensors='pt'\n","                    non_toxic_ids = tokenizer(non_toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)\n","                    masked_toxic_ids= tokenizer(masked_toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)\n","                    \n","                    self.toxic_ids.append(toxic_ids.input_ids)\n","                    self.non_toxic_ids.append(non_toxic_ids.input_ids)\n","                    self.masked_toxic_ids.append(masked_toxic_ids.input_ids)\n","\n","                    if c==0:\n","                      print('\\n',kind,' dataset preview .....')\n","                      print('*******************************************')\n","                      print('Input :: toxic        ::',toxic_seq)\n","                      print('Input :: masked toxic ::',masked_toxic_seq)\n","                      print('Input :: non toxic    ::',non_toxic_seq)\n","                      print('encoded length toxic :',toxic_ids)\n","                      print('encoded length masked toxic: ',masked_toxic_ids)\n","                      print('encoded length non toxic: ',non_toxic_ids)\n","                      print('*******************************************')\n","                    c=c+1\n","            print('total number of',kind,' data processed : ',c)\n","\n","    def __len__(self):\n","        return len(self.toxic_ids)\n","\n","    def __getitem__(self, index):\n","        toxic_ids = self.toxic_ids[index]\n","        non_toxic_ids = self.non_toxic_ids[index]\n","        masked_toxic_ids =self.masked_toxic_ids[index]\n","\n","        # Create a PyTorch tensor from the tokenized sequences\n","        toxic_ids = torch.tensor(toxic_ids, dtype=torch.int64)\n","        non_toxic_ids = torch.tensor(non_toxic_ids, dtype=torch.int64)\n","        masked_toxic_ids = torch.tensor(masked_toxic_ids, dtype=torch.int64)\n","\n","        return {'toxic_ids': toxic_ids, 'non_toxic_ids': non_toxic_ids, 'masked_toxic_ids': masked_toxic_ids}\n"]},{"cell_type":"code","source":["#uncomment if memory issue happens. This will free up some space\n","# import torch\n","# torch.cuda.empty_cache()\n","BADWORDS = [\n","    'suck',\n","    'stupid',\n","    'pimp',\n","    'dumb',\n","    'homo',\n","    'slut',\n","    'damn',\n","    'ass',\n","    'rape',\n","    'poop',\n","    'cock',\n","    'lol',\n","    'crap',\n","    'sex',\n","    'nazi',\n","    'neo-nazi',\n","    'fuck',\n","    'bitch',\n","    'pussy',\n","    'penis',\n","    'vagina',\n","    'whore',\n","    'shit',\n","    'nigger',\n","    'nigga',\n","    'cocksucker',\n","    'assrape',\n","    'motherfucker',\n","    'wanker',\n","    'cunt',\n","    'faggot',\n","    'fags',\n","    'asshole',\n","    'piss',\n","    'cum',\n","    'moron',\n","    'cuckold',\n","    'shit' ,\n","    'filthy','retarded','screw','cucked'\n","]"],"metadata":{"id":"I-Ck9Yi_uCL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bart_model=None"],"metadata":{"id":"mg6gQJZioTpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TYQd-fO70q4z","executionInfo":{"status":"ok","timestamp":1680247219600,"user_tz":420,"elapsed":18601,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f379afd91f4045ab96e204156dddb4bf","29b1c12140134e1c9ee9d80057375f29","031caaf7a2eb49e483e02a325aba7b90","0b3d28bf760f45f98d7289ba1ccab7e9","c148d170c2a9433aa94e85da10409846","907666e2df4d46f39d7808520a9ef220","415de31dbd2048848ab58b86e920f469","9f5a266ee36448d18ec7a64fb81f735c","d1b0226f06a74a78ad6a9aa8578f7dae","ccb3af07f82c45f583a657d9d06cba53","c106a577911a41fc9d8fe9ce05c6c9ee"]},"outputId":"6a37b0ed-eacf-4f37-8ddf-9c614478e46d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f379afd91f4045ab96e204156dddb4bf"}},"metadata":{}}],"source":["# Define hyperparameters\n","\n","BATCH_SIZE = 16 #4\n","NUM_EPOCHS = 4\n","LEARNING_RATE = 2e-5 #5e-5 #2e-4\n","WEIGHT_DECAY = 2e-5\n","MAX_SEQ_LEN = 128 #64\n","D_MODEL = 256 #dimensionality of the input and output vectors of the Transformer model. It is also commonly referred to as the \"hidden size\" of the model.POWER OF 2\n","NUM_HEADS = 4 #8 #number of attention heads used in multi-head attention (D_MODEL/NUM_HEADS=INT)\n","NUM_ENCODER_LAYERS = 4 #6\n","NUM_DECODER_LAYERS = 1 #1\n","DIM_FEEDFORWARD = 1024 #(4 times of D_MODEL)\n","DROPOUT = 0.3\n","GRADIENT_ACCUMULATION_STEPS = 2 #2  # accumulate gradients over 2 batches\n","HIDDEN_SIZE = 768\n","\n"," # Define BART encoder-decoder model\n","class BartEncoderDecoder(nn.Module):\n","    def __init__(self, bart_config):\n","        super().__init__()\n","\n","        self.encoder = BartModel.from_pretrained('facebook/bart-base') #The bare BART Model outputting raw hidden-states without any specific head on top.\n","        self.encoder.config = bart_config\n","        self.decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","        self.decoder.config = bart_config\n","        self.bart_config=bart_config\n","       \n","    def forward(self, input_ids, masked_input_ids, target_ids=None):\n","\n","        # Generate hidden representations for the modified input sequence using the encoder\n","        encoder_outputs = self.encoder(input_ids=input_ids)\n","\n","        # Pass the modified input sequence as input to the decoder and generate the output sequence\n","        decoder_input_ids = masked_input_ids\n","        # decoder_outputs = self.decoder(input_ids=decoder_input_ids, encoder_outputs=encoder_outputs.encoder_last_hidden_state)\n","         # Pass the modified input sequence as input to the decoder and generate the output sequence\n","        decoder_outputs = self.decoder(input_ids=masked_input_ids, encoder_outputs=encoder_outputs, \n","                                       labels=target_ids) #, return_dict=True\n","        \n","        return decoder_outputs\n","\n","# Instantiate BART encoder-decoder model\n","bart_config = BartConfig(d_model=D_MODEL, encoder_layers=NUM_ENCODER_LAYERS, decoder_layers=NUM_DECODER_LAYERS, \n","                         encoder_attention_heads=NUM_HEADS, decoder_attention_heads=NUM_HEADS,\n","                         encoder_ffn_dim=DIM_FEEDFORWARD, decoder_ffn_dim=DIM_FEEDFORWARD, dropout=DROPOUT, hidden_size=HIDDEN_SIZE) #\n","bart_model = BartEncoderDecoder(bart_config).cuda() # move the model to CUDA"]},{"cell_type":"code","source":["def loss_fn(outputs, targets):\n","    batch_size, seq_len, vocab_size = outputs.logits.shape\n","    outputs = outputs.logits.view(batch_size * seq_len, vocab_size)\n","    \n","    # Reshape the targets tensor to (batch_size * seq_len)\n","    targets = targets.view(-1)\n","    loss = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)(outputs, targets)\n","    return loss\n","\n","def collate_fn(batch, batch_size=BATCH_SIZE):\n","    # Pad sequences in batch to have the same length\n","    toxic_ids = pad_sequence([item['toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","    masked_toxic_ids = pad_sequence([item['masked_toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","    non_toxic_ids = pad_sequence([item['non_toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    # Split data into batches of the desired size\n","    num_batches = len(batch) // batch_size\n","    if len(batch) % batch_size != 0:\n","        num_batches += 1\n","    toxic_batches = list(torch.split(toxic_ids[:num_batches*batch_size], batch_size))\n","    masked_toxic_batches = list(torch.split(masked_toxic_ids[:num_batches*batch_size], batch_size))\n","    non_toxic_batches = list(torch.split(non_toxic_ids[:num_batches*batch_size], batch_size))\n","\n","    # Pad the last batch to ensure that all batches have the same size\n","    if len(toxic_batches[-1]) < batch_size:\n","        toxic_batches[-1] = nn.functional.pad(toxic_batches[-1], (0, 0, 0, batch_size - len(toxic_batches[-1])), value=tokenizer.pad_token_id)\n","        masked_toxic_batches[-1] = nn.functional.pad(masked_toxic_batches[-1], (0, 0, 0, batch_size - len(masked_toxic_batches[-1])), value=tokenizer.pad_token_id)\n","        non_toxic_batches[-1] = nn.functional.pad(non_toxic_batches[-1], (0, 0, 0, batch_size - len(non_toxic_batches[-1])), value=tokenizer.pad_token_id)\n","\n","    return [{'toxic_ids': t, 'non_toxic_ids': nt,'masked_toxic_ids': mt} for t, nt, mt in zip(toxic_batches, non_toxic_batches,masked_toxic_batches)][0]\n","\n","# def get_bad_word_indices(batch, bad_word_ids):\n","#     bad_word_indices_batch = []\n","#     for src in batch:\n","#         bad_word_indices = [i for i in range(len(src)) if src[i] in bad_word_ids]\n","#         bad_word_indices_batch.append(bad_word_indices)\n","#     return bad_word_indices_batch"],"metadata":{"id":"r2hZfkqE9c2I","executionInfo":{"status":"ok","timestamp":1680247231048,"user_tz":420,"elapsed":230,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["bart_model"],"metadata":{"id":"2T65jPqJVe3H","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd710f7e-0c9f-4411-e6fb-3a8b44ef5234","executionInfo":{"status":"ok","timestamp":1680247236145,"user_tz":420,"elapsed":135,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartEncoderDecoder(\n","  (encoder): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (decoder): BartForConditionalGeneration(\n","    (model): BartModel(\n","      (shared): Embedding(50265, 768, padding_idx=1)\n","      (encoder): BartEncoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (decoder): BartDecoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["In the line source_embeddings = bart_model.encoder(input_ids=src)[0][:, 0, :], bart_model.encoder(input_ids=src) applies the BART encoder to the input sequence src and returns a tuple of encoder hidden states, attention weights, and the final hidden state of the last layer.\n","\n","The [0] at the end of the function call accesses only the encoder hidden states from the tuple. The [:, 0, :] at the end selects the first token embedding for each input sequence in the batch. The first dimension : means that we want all the input sequences in the batch. The second dimension 0 selects only the first token embedding for each sequence, and the third dimension : selects all the features (or dimensions) in the embedding vector.\n","\n","The first token embedding is often referred to as the \"CLS\" token embedding, and it typically contains information about the overall sequence, which is useful for tasks such as sequence classification or sentence pair classification. In this case, the first token embedding is used to compute the similarity loss between the source and target embeddings."],"metadata":{"id":"5vPomRZ10PuP"}},{"cell_type":"code","source":["import torch.autograd as autograd\n","# CUDA_LAUNCH_BLOCKING=1\n","\n","# Load training and validation data\n","train_data = MyDataset(train_path, MAX_SEQ_LEN,'training')\n","val_data = MyDataset(dev_path, MAX_SEQ_LEN,'validation')\n","\n","print('Instatiating Data loaders for training and validation dataset ......')\n","# Instantiate data loaders\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,collate_fn=collate_fn)\n","val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n","\n","def train(train_loader,learning_rate=LEARNING_RATE, epochs=NUM_EPOCHS, verbose=True, batch_size=BATCH_SIZE):\n","  autograd.set_detect_anomaly(True)\n","\n","  # Instantiate optimizer and loss function\n","  optimizer = Adam(bart_model.parameters(), lr=learning_rate) #, weight_decay=WEIGHT_DECAY\n","  train_losses=[]\n","  \n","  print('\\nTokenizer information :: ')\n","  print('eos_token_id :',tokenizer.eos_token_id)\n","  print('pad_token_id :',tokenizer.pad_token_id)\n","  print('bos_token_id :', tokenizer.bos_token_id)\n","  print('sep_token_id :', tokenizer.sep_token_id,'\\n')\n","\n","  # start time\n","  t0 = time.time()\n","\n","  # Training loop\n","  for epoch in range(epochs):\n","      print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n","      \n","      # Train the model\n","      bart_model.train()\n","      train_loss = 0\n","      epoch_loss=0\n","      for step, batch in enumerate(train_loader):\n","          src = batch['toxic_ids'].cuda()\n","          tgt = batch['non_toxic_ids'].cuda()\n","          masked_src=batch['masked_toxic_ids'].cuda()\n","\n","          optimizer.zero_grad()\n","          outputs=bart_model(input_ids=src, masked_input_ids=masked_src,target_ids=tgt)\n","\n","          loss = loss_fn(outputs, tgt.cuda())\n","          loss = loss.mean() # reduce the loss tensor to a scalar tensor by taking the mean\n","          loss /= GRADIENT_ACCUMULATION_STEPS\n","\n","          loss.backward()\n","          if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","          epoch_loss += loss.item()\n","\n","          # Report progress every batch\n","          if verbose and step % 10 == 0:\n","              print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(train_loader), loss.item()))\n","\n","      avg_loss = epoch_loss / len(train_loader)\n","      train_losses.append(avg_loss)\n","\n","      elapsed_time = time.time() - t0\n","      if verbose:\n","          print('Epoch [{}/{}], Average Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n","\n","  return train_losses, sum(train_losses) / len(train_losses)\n","\n","train_losses,avg_loss=train(train_loader)"],"metadata":{"id":"kNySrGWAVZM5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"91bf595b-09c7-4833-81be-d0d085387f8d","executionInfo":{"status":"ok","timestamp":1680247800211,"user_tz":420,"elapsed":551308,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," training  dataset preview .....\n","*******************************************\n","Input :: toxic        :: pussy nobody asked for your input\n","Input :: masked toxic :: <mask> nobody asked for your input\n","Input :: non toxic    :: nobody asked for your input\n","encoded length toxic : {'input_ids': [0, 642, 28102, 5907, 553, 13, 110, 8135, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length masked toxic:  {'input_ids': [0, 50264, 5907, 553, 13, 110, 8135, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length non toxic:  {'input_ids': [0, 33212, 9956, 553, 13, 110, 8135, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","*******************************************\n","total number of training  data processed :  1584\n","\n"," validation  dataset preview .....\n","*******************************************\n","Input :: toxic        :: anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is a fucking moron\n","Input :: masked toxic :: anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is a <mask> <mask>\n","Input :: non toxic    :: anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is not thinking about this\n","encoded length toxic : {'input_ids': [0, 3785, 1264, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 201, 74, 33, 117, 1683, 15, 1123, 850, 16, 10, 23523, 14628, 261, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length masked toxic:  {'input_ids': [0, 3785, 1264, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 201, 74, 33, 117, 1683, 15, 1123, 850, 16, 10, 50264, 50264, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length non toxic:  {'input_ids': [0, 3785, 1264, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 201, 74, 33, 117, 1683, 15, 1123, 850, 16, 45, 2053, 59, 42, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","*******************************************\n","total number of validation  data processed :  198\n","Instatiating Data loaders for training and validation dataset ......\n","\n","Tokenizer information :: \n","eos_token_id : 2\n","pad_token_id : 1\n","bos_token_id : 0\n","sep_token_id : 2 \n","\n","######  Epoch 1/4 ######\n","Epoch [1/4], Step [1/99], Loss: 7.0676\n","Epoch [1/4], Step [11/99], Loss: 5.4936\n","Epoch [1/4], Step [21/99], Loss: 4.8100\n","Epoch [1/4], Step [31/99], Loss: 4.3317\n","Epoch [1/4], Step [41/99], Loss: 4.1647\n","Epoch [1/4], Step [51/99], Loss: 4.0643\n","Epoch [1/4], Step [61/99], Loss: 4.0701\n","Epoch [1/4], Step [71/99], Loss: 3.9318\n","Epoch [1/4], Step [81/99], Loss: 3.7303\n","Epoch [1/4], Step [91/99], Loss: 3.7642\n","Epoch [1/4], Average Loss: 4.3928, Elapsed Time: 0:02:02\n","######  Epoch 2/4 ######\n","Epoch [2/4], Step [1/99], Loss: 3.7280\n","Epoch [2/4], Step [11/99], Loss: 3.7528\n","Epoch [2/4], Step [21/99], Loss: 3.6058\n","Epoch [2/4], Step [31/99], Loss: 3.5136\n","Epoch [2/4], Step [41/99], Loss: 3.4946\n","Epoch [2/4], Step [51/99], Loss: 3.5623\n","Epoch [2/4], Step [61/99], Loss: 3.5278\n","Epoch [2/4], Step [71/99], Loss: 3.4656\n","Epoch [2/4], Step [81/99], Loss: 3.3521\n","Epoch [2/4], Step [91/99], Loss: 3.4010\n","Epoch [2/4], Average Loss: 3.5283, Elapsed Time: 0:04:03\n","######  Epoch 3/4 ######\n","Epoch [3/4], Step [1/99], Loss: 3.3032\n","Epoch [3/4], Step [11/99], Loss: 3.4140\n","Epoch [3/4], Step [21/99], Loss: 3.3862\n","Epoch [3/4], Step [31/99], Loss: 3.3431\n","Epoch [3/4], Step [41/99], Loss: 3.1862\n","Epoch [3/4], Step [51/99], Loss: 3.2527\n","Epoch [3/4], Step [61/99], Loss: 3.4245\n","Epoch [3/4], Step [71/99], Loss: 3.1647\n","Epoch [3/4], Step [81/99], Loss: 3.2112\n","Epoch [3/4], Step [91/99], Loss: 3.2129\n","Epoch [3/4], Average Loss: 3.2803, Elapsed Time: 0:06:03\n","######  Epoch 4/4 ######\n","Epoch [4/4], Step [1/99], Loss: 3.3122\n","Epoch [4/4], Step [11/99], Loss: 3.2755\n","Epoch [4/4], Step [21/99], Loss: 3.1106\n","Epoch [4/4], Step [31/99], Loss: 3.2041\n","Epoch [4/4], Step [41/99], Loss: 3.2442\n","Epoch [4/4], Step [51/99], Loss: 3.3608\n","Epoch [4/4], Step [61/99], Loss: 3.4746\n","Epoch [4/4], Step [71/99], Loss: 3.5638\n","Epoch [4/4], Step [81/99], Loss: 3.3443\n","Epoch [4/4], Step [91/99], Loss: 3.5278\n","Epoch [4/4], Average Loss: 3.2904, Elapsed Time: 0:08:05\n"]}]},{"cell_type":"code","source":["#uncomment below one only in case of cuda memory issue\n","# import torch\n","# torch.cuda.empty_cache()"],"metadata":{"id":"7Zm3RLmyvxbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQfgit4BLfue","outputId":"fb8ab9f7-e300-405f-e2a5-e8c7fa28bd9d","executionInfo":{"status":"ok","timestamp":1680247828088,"user_tz":420,"elapsed":266,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4.3928421747804896, 3.528293407324589, 3.2802525818949997, 3.290399573066018]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["\n","torch.save(bart_model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/models/bart_model2_checkpoint.pth')\n","# download checkpoint file\n","files.download('/content/drive/MyDrive/Colab Notebooks/models/bart_model2_checkpoint.pth')\n","# bart_model = bart_model.cuda()"],"metadata":{"id":"vIsZ-Es7qyOq","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d25144b8-b8f2-4ab8-fe5f-47621ab88e1b","executionInfo":{"status":"ok","timestamp":1680247860180,"user_tz":420,"elapsed":6351,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1ac86eba-e664-4858-b90d-0f4050366698\", \"bart_model2_checkpoint.pth\", 1115772090)"]},"metadata":{}}]},{"cell_type":"code","source":["state_dict = torch.load('/content/drive/MyDrive/Colab Notebooks/models/bart_model2_checkpoint.pth')\n","print(state_dict.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTabPdBs7_qc","outputId":"1a79acc2-9e45-492f-d436-b193d10ba503","executionInfo":{"status":"ok","timestamp":1680247881714,"user_tz":420,"elapsed":3401,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['encoder.shared.weight', 'encoder.encoder.embed_tokens.weight', 'encoder.encoder.embed_positions.weight', 'encoder.encoder.layers.0.self_attn.k_proj.weight', 'encoder.encoder.layers.0.self_attn.k_proj.bias', 'encoder.encoder.layers.0.self_attn.v_proj.weight', 'encoder.encoder.layers.0.self_attn.v_proj.bias', 'encoder.encoder.layers.0.self_attn.q_proj.weight', 'encoder.encoder.layers.0.self_attn.q_proj.bias', 'encoder.encoder.layers.0.self_attn.out_proj.weight', 'encoder.encoder.layers.0.self_attn.out_proj.bias', 'encoder.encoder.layers.0.self_attn_layer_norm.weight', 'encoder.encoder.layers.0.self_attn_layer_norm.bias', 'encoder.encoder.layers.0.fc1.weight', 'encoder.encoder.layers.0.fc1.bias', 'encoder.encoder.layers.0.fc2.weight', 'encoder.encoder.layers.0.fc2.bias', 'encoder.encoder.layers.0.final_layer_norm.weight', 'encoder.encoder.layers.0.final_layer_norm.bias', 'encoder.encoder.layers.1.self_attn.k_proj.weight', 'encoder.encoder.layers.1.self_attn.k_proj.bias', 'encoder.encoder.layers.1.self_attn.v_proj.weight', 'encoder.encoder.layers.1.self_attn.v_proj.bias', 'encoder.encoder.layers.1.self_attn.q_proj.weight', 'encoder.encoder.layers.1.self_attn.q_proj.bias', 'encoder.encoder.layers.1.self_attn.out_proj.weight', 'encoder.encoder.layers.1.self_attn.out_proj.bias', 'encoder.encoder.layers.1.self_attn_layer_norm.weight', 'encoder.encoder.layers.1.self_attn_layer_norm.bias', 'encoder.encoder.layers.1.fc1.weight', 'encoder.encoder.layers.1.fc1.bias', 'encoder.encoder.layers.1.fc2.weight', 'encoder.encoder.layers.1.fc2.bias', 'encoder.encoder.layers.1.final_layer_norm.weight', 'encoder.encoder.layers.1.final_layer_norm.bias', 'encoder.encoder.layers.2.self_attn.k_proj.weight', 'encoder.encoder.layers.2.self_attn.k_proj.bias', 'encoder.encoder.layers.2.self_attn.v_proj.weight', 'encoder.encoder.layers.2.self_attn.v_proj.bias', 'encoder.encoder.layers.2.self_attn.q_proj.weight', 'encoder.encoder.layers.2.self_attn.q_proj.bias', 'encoder.encoder.layers.2.self_attn.out_proj.weight', 'encoder.encoder.layers.2.self_attn.out_proj.bias', 'encoder.encoder.layers.2.self_attn_layer_norm.weight', 'encoder.encoder.layers.2.self_attn_layer_norm.bias', 'encoder.encoder.layers.2.fc1.weight', 'encoder.encoder.layers.2.fc1.bias', 'encoder.encoder.layers.2.fc2.weight', 'encoder.encoder.layers.2.fc2.bias', 'encoder.encoder.layers.2.final_layer_norm.weight', 'encoder.encoder.layers.2.final_layer_norm.bias', 'encoder.encoder.layers.3.self_attn.k_proj.weight', 'encoder.encoder.layers.3.self_attn.k_proj.bias', 'encoder.encoder.layers.3.self_attn.v_proj.weight', 'encoder.encoder.layers.3.self_attn.v_proj.bias', 'encoder.encoder.layers.3.self_attn.q_proj.weight', 'encoder.encoder.layers.3.self_attn.q_proj.bias', 'encoder.encoder.layers.3.self_attn.out_proj.weight', 'encoder.encoder.layers.3.self_attn.out_proj.bias', 'encoder.encoder.layers.3.self_attn_layer_norm.weight', 'encoder.encoder.layers.3.self_attn_layer_norm.bias', 'encoder.encoder.layers.3.fc1.weight', 'encoder.encoder.layers.3.fc1.bias', 'encoder.encoder.layers.3.fc2.weight', 'encoder.encoder.layers.3.fc2.bias', 'encoder.encoder.layers.3.final_layer_norm.weight', 'encoder.encoder.layers.3.final_layer_norm.bias', 'encoder.encoder.layers.4.self_attn.k_proj.weight', 'encoder.encoder.layers.4.self_attn.k_proj.bias', 'encoder.encoder.layers.4.self_attn.v_proj.weight', 'encoder.encoder.layers.4.self_attn.v_proj.bias', 'encoder.encoder.layers.4.self_attn.q_proj.weight', 'encoder.encoder.layers.4.self_attn.q_proj.bias', 'encoder.encoder.layers.4.self_attn.out_proj.weight', 'encoder.encoder.layers.4.self_attn.out_proj.bias', 'encoder.encoder.layers.4.self_attn_layer_norm.weight', 'encoder.encoder.layers.4.self_attn_layer_norm.bias', 'encoder.encoder.layers.4.fc1.weight', 'encoder.encoder.layers.4.fc1.bias', 'encoder.encoder.layers.4.fc2.weight', 'encoder.encoder.layers.4.fc2.bias', 'encoder.encoder.layers.4.final_layer_norm.weight', 'encoder.encoder.layers.4.final_layer_norm.bias', 'encoder.encoder.layers.5.self_attn.k_proj.weight', 'encoder.encoder.layers.5.self_attn.k_proj.bias', 'encoder.encoder.layers.5.self_attn.v_proj.weight', 'encoder.encoder.layers.5.self_attn.v_proj.bias', 'encoder.encoder.layers.5.self_attn.q_proj.weight', 'encoder.encoder.layers.5.self_attn.q_proj.bias', 'encoder.encoder.layers.5.self_attn.out_proj.weight', 'encoder.encoder.layers.5.self_attn.out_proj.bias', 'encoder.encoder.layers.5.self_attn_layer_norm.weight', 'encoder.encoder.layers.5.self_attn_layer_norm.bias', 'encoder.encoder.layers.5.fc1.weight', 'encoder.encoder.layers.5.fc1.bias', 'encoder.encoder.layers.5.fc2.weight', 'encoder.encoder.layers.5.fc2.bias', 'encoder.encoder.layers.5.final_layer_norm.weight', 'encoder.encoder.layers.5.final_layer_norm.bias', 'encoder.encoder.layernorm_embedding.weight', 'encoder.encoder.layernorm_embedding.bias', 'encoder.decoder.embed_tokens.weight', 'encoder.decoder.embed_positions.weight', 'encoder.decoder.layers.0.self_attn.k_proj.weight', 'encoder.decoder.layers.0.self_attn.k_proj.bias', 'encoder.decoder.layers.0.self_attn.v_proj.weight', 'encoder.decoder.layers.0.self_attn.v_proj.bias', 'encoder.decoder.layers.0.self_attn.q_proj.weight', 'encoder.decoder.layers.0.self_attn.q_proj.bias', 'encoder.decoder.layers.0.self_attn.out_proj.weight', 'encoder.decoder.layers.0.self_attn.out_proj.bias', 'encoder.decoder.layers.0.self_attn_layer_norm.weight', 'encoder.decoder.layers.0.self_attn_layer_norm.bias', 'encoder.decoder.layers.0.encoder_attn.k_proj.weight', 'encoder.decoder.layers.0.encoder_attn.k_proj.bias', 'encoder.decoder.layers.0.encoder_attn.v_proj.weight', 'encoder.decoder.layers.0.encoder_attn.v_proj.bias', 'encoder.decoder.layers.0.encoder_attn.q_proj.weight', 'encoder.decoder.layers.0.encoder_attn.q_proj.bias', 'encoder.decoder.layers.0.encoder_attn.out_proj.weight', 'encoder.decoder.layers.0.encoder_attn.out_proj.bias', 'encoder.decoder.layers.0.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.0.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.0.fc1.weight', 'encoder.decoder.layers.0.fc1.bias', 'encoder.decoder.layers.0.fc2.weight', 'encoder.decoder.layers.0.fc2.bias', 'encoder.decoder.layers.0.final_layer_norm.weight', 'encoder.decoder.layers.0.final_layer_norm.bias', 'encoder.decoder.layers.1.self_attn.k_proj.weight', 'encoder.decoder.layers.1.self_attn.k_proj.bias', 'encoder.decoder.layers.1.self_attn.v_proj.weight', 'encoder.decoder.layers.1.self_attn.v_proj.bias', 'encoder.decoder.layers.1.self_attn.q_proj.weight', 'encoder.decoder.layers.1.self_attn.q_proj.bias', 'encoder.decoder.layers.1.self_attn.out_proj.weight', 'encoder.decoder.layers.1.self_attn.out_proj.bias', 'encoder.decoder.layers.1.self_attn_layer_norm.weight', 'encoder.decoder.layers.1.self_attn_layer_norm.bias', 'encoder.decoder.layers.1.encoder_attn.k_proj.weight', 'encoder.decoder.layers.1.encoder_attn.k_proj.bias', 'encoder.decoder.layers.1.encoder_attn.v_proj.weight', 'encoder.decoder.layers.1.encoder_attn.v_proj.bias', 'encoder.decoder.layers.1.encoder_attn.q_proj.weight', 'encoder.decoder.layers.1.encoder_attn.q_proj.bias', 'encoder.decoder.layers.1.encoder_attn.out_proj.weight', 'encoder.decoder.layers.1.encoder_attn.out_proj.bias', 'encoder.decoder.layers.1.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.1.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.1.fc1.weight', 'encoder.decoder.layers.1.fc1.bias', 'encoder.decoder.layers.1.fc2.weight', 'encoder.decoder.layers.1.fc2.bias', 'encoder.decoder.layers.1.final_layer_norm.weight', 'encoder.decoder.layers.1.final_layer_norm.bias', 'encoder.decoder.layers.2.self_attn.k_proj.weight', 'encoder.decoder.layers.2.self_attn.k_proj.bias', 'encoder.decoder.layers.2.self_attn.v_proj.weight', 'encoder.decoder.layers.2.self_attn.v_proj.bias', 'encoder.decoder.layers.2.self_attn.q_proj.weight', 'encoder.decoder.layers.2.self_attn.q_proj.bias', 'encoder.decoder.layers.2.self_attn.out_proj.weight', 'encoder.decoder.layers.2.self_attn.out_proj.bias', 'encoder.decoder.layers.2.self_attn_layer_norm.weight', 'encoder.decoder.layers.2.self_attn_layer_norm.bias', 'encoder.decoder.layers.2.encoder_attn.k_proj.weight', 'encoder.decoder.layers.2.encoder_attn.k_proj.bias', 'encoder.decoder.layers.2.encoder_attn.v_proj.weight', 'encoder.decoder.layers.2.encoder_attn.v_proj.bias', 'encoder.decoder.layers.2.encoder_attn.q_proj.weight', 'encoder.decoder.layers.2.encoder_attn.q_proj.bias', 'encoder.decoder.layers.2.encoder_attn.out_proj.weight', 'encoder.decoder.layers.2.encoder_attn.out_proj.bias', 'encoder.decoder.layers.2.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.2.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.2.fc1.weight', 'encoder.decoder.layers.2.fc1.bias', 'encoder.decoder.layers.2.fc2.weight', 'encoder.decoder.layers.2.fc2.bias', 'encoder.decoder.layers.2.final_layer_norm.weight', 'encoder.decoder.layers.2.final_layer_norm.bias', 'encoder.decoder.layers.3.self_attn.k_proj.weight', 'encoder.decoder.layers.3.self_attn.k_proj.bias', 'encoder.decoder.layers.3.self_attn.v_proj.weight', 'encoder.decoder.layers.3.self_attn.v_proj.bias', 'encoder.decoder.layers.3.self_attn.q_proj.weight', 'encoder.decoder.layers.3.self_attn.q_proj.bias', 'encoder.decoder.layers.3.self_attn.out_proj.weight', 'encoder.decoder.layers.3.self_attn.out_proj.bias', 'encoder.decoder.layers.3.self_attn_layer_norm.weight', 'encoder.decoder.layers.3.self_attn_layer_norm.bias', 'encoder.decoder.layers.3.encoder_attn.k_proj.weight', 'encoder.decoder.layers.3.encoder_attn.k_proj.bias', 'encoder.decoder.layers.3.encoder_attn.v_proj.weight', 'encoder.decoder.layers.3.encoder_attn.v_proj.bias', 'encoder.decoder.layers.3.encoder_attn.q_proj.weight', 'encoder.decoder.layers.3.encoder_attn.q_proj.bias', 'encoder.decoder.layers.3.encoder_attn.out_proj.weight', 'encoder.decoder.layers.3.encoder_attn.out_proj.bias', 'encoder.decoder.layers.3.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.3.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.3.fc1.weight', 'encoder.decoder.layers.3.fc1.bias', 'encoder.decoder.layers.3.fc2.weight', 'encoder.decoder.layers.3.fc2.bias', 'encoder.decoder.layers.3.final_layer_norm.weight', 'encoder.decoder.layers.3.final_layer_norm.bias', 'encoder.decoder.layers.4.self_attn.k_proj.weight', 'encoder.decoder.layers.4.self_attn.k_proj.bias', 'encoder.decoder.layers.4.self_attn.v_proj.weight', 'encoder.decoder.layers.4.self_attn.v_proj.bias', 'encoder.decoder.layers.4.self_attn.q_proj.weight', 'encoder.decoder.layers.4.self_attn.q_proj.bias', 'encoder.decoder.layers.4.self_attn.out_proj.weight', 'encoder.decoder.layers.4.self_attn.out_proj.bias', 'encoder.decoder.layers.4.self_attn_layer_norm.weight', 'encoder.decoder.layers.4.self_attn_layer_norm.bias', 'encoder.decoder.layers.4.encoder_attn.k_proj.weight', 'encoder.decoder.layers.4.encoder_attn.k_proj.bias', 'encoder.decoder.layers.4.encoder_attn.v_proj.weight', 'encoder.decoder.layers.4.encoder_attn.v_proj.bias', 'encoder.decoder.layers.4.encoder_attn.q_proj.weight', 'encoder.decoder.layers.4.encoder_attn.q_proj.bias', 'encoder.decoder.layers.4.encoder_attn.out_proj.weight', 'encoder.decoder.layers.4.encoder_attn.out_proj.bias', 'encoder.decoder.layers.4.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.4.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.4.fc1.weight', 'encoder.decoder.layers.4.fc1.bias', 'encoder.decoder.layers.4.fc2.weight', 'encoder.decoder.layers.4.fc2.bias', 'encoder.decoder.layers.4.final_layer_norm.weight', 'encoder.decoder.layers.4.final_layer_norm.bias', 'encoder.decoder.layers.5.self_attn.k_proj.weight', 'encoder.decoder.layers.5.self_attn.k_proj.bias', 'encoder.decoder.layers.5.self_attn.v_proj.weight', 'encoder.decoder.layers.5.self_attn.v_proj.bias', 'encoder.decoder.layers.5.self_attn.q_proj.weight', 'encoder.decoder.layers.5.self_attn.q_proj.bias', 'encoder.decoder.layers.5.self_attn.out_proj.weight', 'encoder.decoder.layers.5.self_attn.out_proj.bias', 'encoder.decoder.layers.5.self_attn_layer_norm.weight', 'encoder.decoder.layers.5.self_attn_layer_norm.bias', 'encoder.decoder.layers.5.encoder_attn.k_proj.weight', 'encoder.decoder.layers.5.encoder_attn.k_proj.bias', 'encoder.decoder.layers.5.encoder_attn.v_proj.weight', 'encoder.decoder.layers.5.encoder_attn.v_proj.bias', 'encoder.decoder.layers.5.encoder_attn.q_proj.weight', 'encoder.decoder.layers.5.encoder_attn.q_proj.bias', 'encoder.decoder.layers.5.encoder_attn.out_proj.weight', 'encoder.decoder.layers.5.encoder_attn.out_proj.bias', 'encoder.decoder.layers.5.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.5.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.5.fc1.weight', 'encoder.decoder.layers.5.fc1.bias', 'encoder.decoder.layers.5.fc2.weight', 'encoder.decoder.layers.5.fc2.bias', 'encoder.decoder.layers.5.final_layer_norm.weight', 'encoder.decoder.layers.5.final_layer_norm.bias', 'encoder.decoder.layernorm_embedding.weight', 'encoder.decoder.layernorm_embedding.bias', 'decoder.final_logits_bias', 'decoder.model.shared.weight', 'decoder.model.encoder.embed_tokens.weight', 'decoder.model.encoder.embed_positions.weight', 'decoder.model.encoder.layers.0.self_attn.k_proj.weight', 'decoder.model.encoder.layers.0.self_attn.k_proj.bias', 'decoder.model.encoder.layers.0.self_attn.v_proj.weight', 'decoder.model.encoder.layers.0.self_attn.v_proj.bias', 'decoder.model.encoder.layers.0.self_attn.q_proj.weight', 'decoder.model.encoder.layers.0.self_attn.q_proj.bias', 'decoder.model.encoder.layers.0.self_attn.out_proj.weight', 'decoder.model.encoder.layers.0.self_attn.out_proj.bias', 'decoder.model.encoder.layers.0.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.0.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.0.fc1.weight', 'decoder.model.encoder.layers.0.fc1.bias', 'decoder.model.encoder.layers.0.fc2.weight', 'decoder.model.encoder.layers.0.fc2.bias', 'decoder.model.encoder.layers.0.final_layer_norm.weight', 'decoder.model.encoder.layers.0.final_layer_norm.bias', 'decoder.model.encoder.layers.1.self_attn.k_proj.weight', 'decoder.model.encoder.layers.1.self_attn.k_proj.bias', 'decoder.model.encoder.layers.1.self_attn.v_proj.weight', 'decoder.model.encoder.layers.1.self_attn.v_proj.bias', 'decoder.model.encoder.layers.1.self_attn.q_proj.weight', 'decoder.model.encoder.layers.1.self_attn.q_proj.bias', 'decoder.model.encoder.layers.1.self_attn.out_proj.weight', 'decoder.model.encoder.layers.1.self_attn.out_proj.bias', 'decoder.model.encoder.layers.1.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.1.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.1.fc1.weight', 'decoder.model.encoder.layers.1.fc1.bias', 'decoder.model.encoder.layers.1.fc2.weight', 'decoder.model.encoder.layers.1.fc2.bias', 'decoder.model.encoder.layers.1.final_layer_norm.weight', 'decoder.model.encoder.layers.1.final_layer_norm.bias', 'decoder.model.encoder.layers.2.self_attn.k_proj.weight', 'decoder.model.encoder.layers.2.self_attn.k_proj.bias', 'decoder.model.encoder.layers.2.self_attn.v_proj.weight', 'decoder.model.encoder.layers.2.self_attn.v_proj.bias', 'decoder.model.encoder.layers.2.self_attn.q_proj.weight', 'decoder.model.encoder.layers.2.self_attn.q_proj.bias', 'decoder.model.encoder.layers.2.self_attn.out_proj.weight', 'decoder.model.encoder.layers.2.self_attn.out_proj.bias', 'decoder.model.encoder.layers.2.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.2.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.2.fc1.weight', 'decoder.model.encoder.layers.2.fc1.bias', 'decoder.model.encoder.layers.2.fc2.weight', 'decoder.model.encoder.layers.2.fc2.bias', 'decoder.model.encoder.layers.2.final_layer_norm.weight', 'decoder.model.encoder.layers.2.final_layer_norm.bias', 'decoder.model.encoder.layers.3.self_attn.k_proj.weight', 'decoder.model.encoder.layers.3.self_attn.k_proj.bias', 'decoder.model.encoder.layers.3.self_attn.v_proj.weight', 'decoder.model.encoder.layers.3.self_attn.v_proj.bias', 'decoder.model.encoder.layers.3.self_attn.q_proj.weight', 'decoder.model.encoder.layers.3.self_attn.q_proj.bias', 'decoder.model.encoder.layers.3.self_attn.out_proj.weight', 'decoder.model.encoder.layers.3.self_attn.out_proj.bias', 'decoder.model.encoder.layers.3.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.3.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.3.fc1.weight', 'decoder.model.encoder.layers.3.fc1.bias', 'decoder.model.encoder.layers.3.fc2.weight', 'decoder.model.encoder.layers.3.fc2.bias', 'decoder.model.encoder.layers.3.final_layer_norm.weight', 'decoder.model.encoder.layers.3.final_layer_norm.bias', 'decoder.model.encoder.layers.4.self_attn.k_proj.weight', 'decoder.model.encoder.layers.4.self_attn.k_proj.bias', 'decoder.model.encoder.layers.4.self_attn.v_proj.weight', 'decoder.model.encoder.layers.4.self_attn.v_proj.bias', 'decoder.model.encoder.layers.4.self_attn.q_proj.weight', 'decoder.model.encoder.layers.4.self_attn.q_proj.bias', 'decoder.model.encoder.layers.4.self_attn.out_proj.weight', 'decoder.model.encoder.layers.4.self_attn.out_proj.bias', 'decoder.model.encoder.layers.4.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.4.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.4.fc1.weight', 'decoder.model.encoder.layers.4.fc1.bias', 'decoder.model.encoder.layers.4.fc2.weight', 'decoder.model.encoder.layers.4.fc2.bias', 'decoder.model.encoder.layers.4.final_layer_norm.weight', 'decoder.model.encoder.layers.4.final_layer_norm.bias', 'decoder.model.encoder.layers.5.self_attn.k_proj.weight', 'decoder.model.encoder.layers.5.self_attn.k_proj.bias', 'decoder.model.encoder.layers.5.self_attn.v_proj.weight', 'decoder.model.encoder.layers.5.self_attn.v_proj.bias', 'decoder.model.encoder.layers.5.self_attn.q_proj.weight', 'decoder.model.encoder.layers.5.self_attn.q_proj.bias', 'decoder.model.encoder.layers.5.self_attn.out_proj.weight', 'decoder.model.encoder.layers.5.self_attn.out_proj.bias', 'decoder.model.encoder.layers.5.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.5.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.5.fc1.weight', 'decoder.model.encoder.layers.5.fc1.bias', 'decoder.model.encoder.layers.5.fc2.weight', 'decoder.model.encoder.layers.5.fc2.bias', 'decoder.model.encoder.layers.5.final_layer_norm.weight', 'decoder.model.encoder.layers.5.final_layer_norm.bias', 'decoder.model.encoder.layernorm_embedding.weight', 'decoder.model.encoder.layernorm_embedding.bias', 'decoder.model.decoder.embed_tokens.weight', 'decoder.model.decoder.embed_positions.weight', 'decoder.model.decoder.layers.0.self_attn.k_proj.weight', 'decoder.model.decoder.layers.0.self_attn.k_proj.bias', 'decoder.model.decoder.layers.0.self_attn.v_proj.weight', 'decoder.model.decoder.layers.0.self_attn.v_proj.bias', 'decoder.model.decoder.layers.0.self_attn.q_proj.weight', 'decoder.model.decoder.layers.0.self_attn.q_proj.bias', 'decoder.model.decoder.layers.0.self_attn.out_proj.weight', 'decoder.model.decoder.layers.0.self_attn.out_proj.bias', 'decoder.model.decoder.layers.0.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.0.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.0.fc1.weight', 'decoder.model.decoder.layers.0.fc1.bias', 'decoder.model.decoder.layers.0.fc2.weight', 'decoder.model.decoder.layers.0.fc2.bias', 'decoder.model.decoder.layers.0.final_layer_norm.weight', 'decoder.model.decoder.layers.0.final_layer_norm.bias', 'decoder.model.decoder.layers.1.self_attn.k_proj.weight', 'decoder.model.decoder.layers.1.self_attn.k_proj.bias', 'decoder.model.decoder.layers.1.self_attn.v_proj.weight', 'decoder.model.decoder.layers.1.self_attn.v_proj.bias', 'decoder.model.decoder.layers.1.self_attn.q_proj.weight', 'decoder.model.decoder.layers.1.self_attn.q_proj.bias', 'decoder.model.decoder.layers.1.self_attn.out_proj.weight', 'decoder.model.decoder.layers.1.self_attn.out_proj.bias', 'decoder.model.decoder.layers.1.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.1.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.1.fc1.weight', 'decoder.model.decoder.layers.1.fc1.bias', 'decoder.model.decoder.layers.1.fc2.weight', 'decoder.model.decoder.layers.1.fc2.bias', 'decoder.model.decoder.layers.1.final_layer_norm.weight', 'decoder.model.decoder.layers.1.final_layer_norm.bias', 'decoder.model.decoder.layers.2.self_attn.k_proj.weight', 'decoder.model.decoder.layers.2.self_attn.k_proj.bias', 'decoder.model.decoder.layers.2.self_attn.v_proj.weight', 'decoder.model.decoder.layers.2.self_attn.v_proj.bias', 'decoder.model.decoder.layers.2.self_attn.q_proj.weight', 'decoder.model.decoder.layers.2.self_attn.q_proj.bias', 'decoder.model.decoder.layers.2.self_attn.out_proj.weight', 'decoder.model.decoder.layers.2.self_attn.out_proj.bias', 'decoder.model.decoder.layers.2.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.2.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.2.fc1.weight', 'decoder.model.decoder.layers.2.fc1.bias', 'decoder.model.decoder.layers.2.fc2.weight', 'decoder.model.decoder.layers.2.fc2.bias', 'decoder.model.decoder.layers.2.final_layer_norm.weight', 'decoder.model.decoder.layers.2.final_layer_norm.bias', 'decoder.model.decoder.layers.3.self_attn.k_proj.weight', 'decoder.model.decoder.layers.3.self_attn.k_proj.bias', 'decoder.model.decoder.layers.3.self_attn.v_proj.weight', 'decoder.model.decoder.layers.3.self_attn.v_proj.bias', 'decoder.model.decoder.layers.3.self_attn.q_proj.weight', 'decoder.model.decoder.layers.3.self_attn.q_proj.bias', 'decoder.model.decoder.layers.3.self_attn.out_proj.weight', 'decoder.model.decoder.layers.3.self_attn.out_proj.bias', 'decoder.model.decoder.layers.3.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.3.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.3.fc1.weight', 'decoder.model.decoder.layers.3.fc1.bias', 'decoder.model.decoder.layers.3.fc2.weight', 'decoder.model.decoder.layers.3.fc2.bias', 'decoder.model.decoder.layers.3.final_layer_norm.weight', 'decoder.model.decoder.layers.3.final_layer_norm.bias', 'decoder.model.decoder.layers.4.self_attn.k_proj.weight', 'decoder.model.decoder.layers.4.self_attn.k_proj.bias', 'decoder.model.decoder.layers.4.self_attn.v_proj.weight', 'decoder.model.decoder.layers.4.self_attn.v_proj.bias', 'decoder.model.decoder.layers.4.self_attn.q_proj.weight', 'decoder.model.decoder.layers.4.self_attn.q_proj.bias', 'decoder.model.decoder.layers.4.self_attn.out_proj.weight', 'decoder.model.decoder.layers.4.self_attn.out_proj.bias', 'decoder.model.decoder.layers.4.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.4.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.4.fc1.weight', 'decoder.model.decoder.layers.4.fc1.bias', 'decoder.model.decoder.layers.4.fc2.weight', 'decoder.model.decoder.layers.4.fc2.bias', 'decoder.model.decoder.layers.4.final_layer_norm.weight', 'decoder.model.decoder.layers.4.final_layer_norm.bias', 'decoder.model.decoder.layers.5.self_attn.k_proj.weight', 'decoder.model.decoder.layers.5.self_attn.k_proj.bias', 'decoder.model.decoder.layers.5.self_attn.v_proj.weight', 'decoder.model.decoder.layers.5.self_attn.v_proj.bias', 'decoder.model.decoder.layers.5.self_attn.q_proj.weight', 'decoder.model.decoder.layers.5.self_attn.q_proj.bias', 'decoder.model.decoder.layers.5.self_attn.out_proj.weight', 'decoder.model.decoder.layers.5.self_attn.out_proj.bias', 'decoder.model.decoder.layers.5.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.5.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.5.fc1.weight', 'decoder.model.decoder.layers.5.fc1.bias', 'decoder.model.decoder.layers.5.fc2.weight', 'decoder.model.decoder.layers.5.fc2.bias', 'decoder.model.decoder.layers.5.final_layer_norm.weight', 'decoder.model.decoder.layers.5.final_layer_norm.bias', 'decoder.model.decoder.layernorm_embedding.weight', 'decoder.model.decoder.layernorm_embedding.bias', 'decoder.lm_head.weight'])\n"]}]},{"cell_type":"markdown","source":["Model Hyperparamters fine tuning :  \n","In intial attempts we observed that generated text was very small in comparison to golden text. There could be several reasons why the generated text is very short with the given decoding parameters.\n","\n","One possibility is that the model is more likely to stop early when the most probable token indicates the end of the sentence. To address this, you may want to experiment with adjusting the decoding parameters, such as the length penalty or the minimum and maximum length constraints, to encourage the model to generate longer text.\n","\n","Another possibility is that the input may not provide enough context or information for the model to generate longer text. In this case, you may want to consider using a larger input sequence or incorporating additional information or features, such as metadata or external knowledge, to provide more context and guidance for the model.\n","\n","It's also worth noting that the number of returned sequences is set to 2, which may limit the diversity and length of the generated text. Increasing the number of return sequences, such as 5 or 10, may help generate longer and more diverse outputs.\n","\n","After fine tuning generate method,we observed that model started performing little well in case of short sentences.\n","\n","We had a choice to use decoder.generate or decoder.outputs to get generated token ids. We will be using generate method. torch.argmax(outputs.logits, dim=-1) gives the index of the highest logit value for each position in the output sequence. This is not the same as the sequence of generated IDs produced by decoder.generate(), because decoder.generate() applies several additional steps during decoding, such as beam search and top-k sampling, that are not present in a simple argmax operation.\n","\n","The decoder.generate() method in BART uses beam search to generate multiple possible sequences, and then returns the highest-scoring sequence according to a scoring function that takes into account both the log-likelihood of the sequence and various penalties for things like repeated n-grams. This process is more complex than simply taking the argmax of the logits, and can lead to better quality generated sequences."],"metadata":{"id":"E3Phlcnw8HcD"}},{"cell_type":"code","source":["def get_max_length(input_sequence):\n","    # Return a multiple of the input sequence length as the maximum length\n","    return 1.5 * len(input_sequence)\n","\n","bart_model=bart_model.cuda()\n","def validate(model, val_loader, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer_type='Adam', epochs=NUM_EPOCHS,verbose=True):\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate) if optimizer_type == 'Adam' else optim.SGD(model.parameters(), lr=learning_rate)\n","    model.eval()\n","    \n","    total_tokens = 0\n","    val_losses=[]\n","    generated_texts = []\n","    gold_texts = []\n","    t0 = time.time()\n","\n","    with torch.no_grad():\n","      for epoch in range(epochs):\n","        print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n","        epoch_loss=0\n","        for step,batch in enumerate(val_loader):\n","            src = batch['toxic_ids'].cuda()\n","            tgt = batch['non_toxic_ids'].cuda()\n","            masked_src=batch['masked_toxic_ids'].cuda()\n","\n","            # Perform style transfer       \n","            # generate translations\n","            generated_ids = model.decoder.generate(\n","                input_ids=masked_src.cuda(),\n","                max_length=get_max_length(masked_src.cuda()),\n","                num_beams=10,\n","                early_stopping=True,\n","                top_k=50,\n","                length_penalty=1,\n","                repetition_penalty=1.8,\n","                no_repeat_ngram_size=1,\n","                top_p = 0.95,\n","                temperature=0.1,\n","                decoder_start_token_id=bart_config.decoder_start_token_id\n","            )\n","\n","            generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","            generated_texts.extend(generated_text)\n","\n","            gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n","            gold_texts.extend(gold_text)\n","       \n","            # Compute loss\n","            outputs=bart_model(input_ids=src, masked_input_ids=masked_src)\n","\n","            loss = loss_fn(outputs, tgt.cuda())               \n","            epoch_loss += loss.item()\n","            \n","        # Report progress every batch\n","        if verbose and step % 1 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(val_loader), loss.item()))\n","\n","        avg_loss = epoch_loss / len(val_loader)\n","        val_losses.append(avg_loss)\n","\n","        elapsed_time = time.time() - t0\n","        if verbose:\n","            print('Epoch [{}/{}], Average Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n","\n","    return val_losses,avg_loss, generated_texts, gold_texts\n","\n","val_loss,avg_loss, generated_texts, gold_texts=validate(bart_model, val_loader, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer_type='Adam') #'SGD'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ez1kUWEcXi-F","outputId":"23c6525e-838f-42a5-f424-811abe5fe534","executionInfo":{"status":"ok","timestamp":1680247993266,"user_tz":420,"elapsed":76594,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["######  Epoch 1/4 ######\n","Epoch [1/4], Step [13/13], Loss: 5.9368\n","Epoch [1/4], Average Loss: 6.2163, Elapsed Time: 0:00:19\n","######  Epoch 2/4 ######\n","Epoch [2/4], Step [13/13], Loss: 5.9368\n","Epoch [2/4], Average Loss: 6.2163, Elapsed Time: 0:00:37\n","######  Epoch 3/4 ######\n","Epoch [3/4], Step [13/13], Loss: 5.9368\n","Epoch [3/4], Average Loss: 6.2163, Elapsed Time: 0:00:57\n","######  Epoch 4/4 ######\n","Epoch [4/4], Step [13/13], Loss: 5.9368\n","Epoch [4/4], Average Loss: 6.2163, Elapsed Time: 0:01:17\n"]}]},{"cell_type":"code","source":["val_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYC0GFzVgC27","outputId":"0fcfacd5-e1fa-47de-c0dc-06c1fafba463","executionInfo":{"status":"ok","timestamp":1680248016385,"user_tz":420,"elapsed":2,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[6.216278442969689, 6.216278442969689, 6.216278442969689, 6.216278442969689]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["dev=pd.read_csv(dev_path,sep=\",\", header=None) \n","\n","for i in range(len(generated_texts[:10])):\n","  print(i,'*'*20)\n","  print(' Original text   :: ',dev[1][i])\n","  print(' Gold text       :: ',gold_texts[i])\n","  print(' Translated text :: ',generated_texts[i])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bAn7pvYaiKK","outputId":"3bf6473a-9df8-4a09-8d28-b2df23618fbb","executionInfo":{"status":"ok","timestamp":1680248029149,"user_tz":420,"elapsed":748,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["0 ********************\n"," Original text   ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is a fucking moron\n"," Gold text       ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is not thinking about this\n"," Translated text ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no\n","1 ********************\n"," Original text   ::  my favorite part is that youre still madly replying as if its going to quell your cousin fucking urges\n"," Gold text       ::  my favorite part is that you are still replying\n"," Translated text ::  my favorite part is that youre still madly replying as if its going to quell your cousin\n","2 ********************\n"," Original text   ::  but did you try it lol that and medical marijuana helped my cousins tinnitus she used to puke cause she would be so dizzy\n"," Gold text       ::  have you tried it that helped my cousin s tinnitus she used to puke cause she would be so dizzy\n"," Translated text ::  but did you try it lol that and medical marijuana helped my cousins tinnitus she used to puke\n","3 ********************\n"," Original text   ::  by the downvotes i see there are a bunch of uneducated trumpers here who dont understand oil you probably think bideg contols gas prices too \n"," Gold text       ::  by the downvotes i see there are a bunch of trump supporters here who dont understand oil you probably think bideg contols gas prices too\n"," Translated text ::  by the downvotes i see there are a bunch of uneducated trumpers here who dont understand oil you\n","4 ********************\n"," Original text   ::  cuckold carlson is a problem\n"," Gold text       ::  carlson is the problem\n"," Translated text ::  cuckold carlson is a man who needs to get his mind off of what he's doing\n","5 ********************\n"," Original text   ::  shut tf up lmfaoooo youre soooo victimized\n"," Gold text       ::  please don t say anything you sound soooo victimized\n"," Translated text ::  shut tf up lmfaoooo youre soooo gonna get your ass outta my face i dont\n","6 ********************\n"," Original text   ::  remember when tucker cucked him on national tv and he begged for forgiveness dude is the definition of weak\n"," Gold text       ::  remember when tucker messed with him on national tv and he had to ask for forgiveness that was weak\n"," Translated text ::  remember when tucker cucked him on national tv and he begged for forgiveness dude is the definition of weak\n","7 ********************\n"," Original text   ::  it s not the hat that s offensive it s the smell of your breath from licking so much shit off of boots\n"," Gold text       ::  it s not the hat that s offensive it s the smell of your breath\n"," Translated text ::  it s not the hat that ll make you feel better about your outfit, it t anything elseyou think\n","8 ********************\n"," Original text   ::  i was gonna retort but looks like god already did you in with the als have a shitty life\n"," Gold text       ::  i was gonna retort but i feel bad because you have als\n"," Translated text ::  i was gonna retort but looks like i already did you in with the als have a bad life\n","9 ********************\n"," Original text   ::  hilariously nicotine iirc actually suppresses the cilia it s like a giant plot by tobacco to screw your lungs\n"," Gold text       ::  hilariously nicotine iirc actually suppresses the cilia it s like a giant plot by tobacco to mess up your lungs\n"," Translated text ::  hilariously nicotine iirc actually suppresses the cilia it s like a giant plot by tobacco to\n"]}]},{"cell_type":"code","source":["import seaborn as sns\n","### Plot Training & Validation Loss\n","data = {'Epoch': range(1, 5), 'Training Loss': train_losses, 'Validation Loss': val_loss}\n","df = pd.DataFrame(data)\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","sns.set_style('whitegrid')\n","sns.set(font_scale=1.5)\n","\n","# Plot train & val loss\n","sns.lineplot(data=df, x=\"Epoch\", y=\"Training Loss\", label=\"Training Loss\", marker='o')\n","sns.lineplot(data=df, x=\"Epoch\", y=\"Validation Loss\", label=\"Validation Loss\", marker='o')\n","\n","# set the axis labels and title\n","ax.set(xlabel='Epoch', ylabel='Loss')\n","ax.set_title('Training and Validation Loss', fontsize=18)\n","\n","# set the legend and adjust its position\n","plt.legend(fontsize=14)\n","\n","# set the ticks fontsize\n","ax.tick_params(axis='both', which='major', labelsize=14)\n","# ax.grid(True, which='both', linestyle='--', color='lightgray')"],"metadata":{"id":"DwIX28xsI4CQ","colab":{"base_uri":"https://localhost:8080/","height":574},"outputId":"b3e79f0b-23b4-40e9-a58a-680926986ca4","executionInfo":{"status":"ok","timestamp":1680248063194,"user_tz":420,"elapsed":453,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1cAAAItCAYAAADVDIDjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB72klEQVR4nO3dd3gU5d7G8Xs3vSeQUAOEEnqTXgQCSEcFPQcFlSIKgvXY8aigHl4LNrCAioKKgr2gIAhSRJoUUXqoAqEFSO/Zef8IWVlSCMmE3STfz3Xlgkx55jc7O7D3zszzWAzDMAQAAAAAKBGrswsAAAAAgPKAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQCSVq5cKYvFIovFYnrbc+fOlcViUUREhOltV3RTpkyRxWJRVFSUs0spssLeayV9H5bm+7goeK8DqOgIVwCumNwPfcX5mTt3rrPLRzlx5513ymKxqHLlykpPTy/yepGRkbJYLLruuutKsTrXdOjQIU2ZMkVTpkxxdiml4tChQ/xbA8AU7s4uAEDFUbVq1XynJyUlKTk5udBlfHx8Sq0uSfL19VWjRo1Kpe2goCA1atRINWvWLJX2cXnGjh2r2bNn6+zZs/ruu+80bNiwS66zatUq7du3z75+aSnN92FJHDp0SM8884wkFRqweK8DqOgIVwCumBMnTuQ7fcqUKfYPbgUtU9o6dOig3bt3l0rbQ4cO1dChQ0ulbVy+Tp06qWnTptq5c6fmzJlTpHA1Z84cSTnhf9CgQaVWW2m+D68E3usAKjpuCwQAVDi5V5+WLl2qY8eOFbpsYmKivvzyS0nSyJEj5e7O95IAgPwRrgC4vNxnIVauXKlTp07pwQcfVMOGDeXr6+vw4H5KSormz5+vkSNHqnXr1goLC5OXl5dq1KihIUOGaPHixQVuo7COAC5+SH/z5s0aNmyYqlevLi8vL9WrV08PPvigzp07l2/bhT3kf3GHDMuXL9egQYMUFhYmb29vNWnSRM8884zS0tIKfY2+++479erVS8HBwfL391erVq300ksvKTMzs0SdPpw7d07vv/++hg0bphYtWqhSpUry9vZWnTp1NGLECK1fv77Adc3at8WLF6tPnz757ltx3XbbbfLw8JDNZrvkMzafffaZ/bbV22+/XVLJ3muFKUqHFLt379Ytt9yiatWqydvbW/Xq1dO9996rkydPFtp2Zmamvv/+e40bN07t2rVT9erV5enpqSpVqqhfv36aP3++DMPIs15ERIR69uxp//3i5yFHjx5tn1eUDi3279+vCRMmKDIyUj4+PgoMDFSbNm307LPPKiEhoUivy759+3T77berVq1a8vLyUnh4uO68885LBuXS8vXXX2vw4MGqWrWqPD09VbVqVQ0ePFjffPNNoestWbJEN9xwg8LDw+Xp6anAwEDVq1dPffv21csvv6yzZ8/mWWfDhg265ZZbVLduXXl7e8vPz0916tRRjx499Nxzz+no0aOltZsAisIAACebPHmyIcko6J+k3HnvvfeeUbVqVUOS4e3tbQQEBDisM2fOHPuyFovFCAoKMnx9fe3TJBkPPfRQvttYsWJFgTXktlunTh3jk08+MTw8PAxJRlBQkGG1Wu3rNWvWzEhMTCx0/YL2vUePHsZLL71kWCwWw2KxGMHBwYbFYrG33bNnTyMrKyvf2h966CGHfQwODjbc3d0NSUb37t2NJ554wr6Ny3XhsXFzczNCQkIMLy8vh9d5+vTpha5bkn27cPv57dukSZOKvW833nijIclo0KBBoct16dLFkGR06dLFPq203muFzTMMw1i8eLHD6+/v7294e3sbkozq1asbH3zwQZHalmQEBgbaz6Hcn3//+99Gdna2w3rt2rUzQkJC7MtUrVrV4ee+++7L87rk9143DMP47LPPHOoPCAhw+L1WrVrGzp07C639l19+Mfz9/e3r574fJBk1atQwjh49mu+2C3Pw4EF7G3PmzCnyeunp6cZNN91kX9dqtRohISEO/y4MHz7cyMjIyLPuM8884/Da+/r62vcr92fFihUO68ydO9fh3PHy8jICAwMd1rmc+gGYj3AFwOmKGq78/f2NRo0aGcuXL7d/ANyzZ499uW+//dZ4+OGHjTVr1hjJycn26TExMcYzzzxjD0Xfffddnm0UJVz5+voaXl5exh133GH8/fffhmEYRnJysvHmm2/a237qqacKXL+wcBUcHGxYrVZj0qRJxunTpw3DMIz4+Hjj6aefttf1/vvv51l//vz59vkjRoywf7BMTU013n33XcPb29v+wbg4AeSdd94xJk+ebGzatMlIT083DMMwbDabceDAAeP+++83LBaL4ebmZmzZssX0ffvuu+8cPvTnvuYpKSnGW2+9ZXh6ehrBwcHF3rdFixbZ21+1alW+y+zevTvfGkvrvVbYvCNHjtg/SLds2dLYsGGDYRiGkZ2dbSxevNgIDw+3vx75rb9hwwZj/Pjxxs8//2zEx8fbp585c8aYPn26ve38wvKlQl+uwt7rmzdvtr8uXbt2Nf788097/d9//71RvXp1Q5JRv379PF9SXLj9kJAQ47rrrjN27dplGEZOwPnss8/sQfG2224rtMb8FDdc5X6xYbFYjKeeeso4d+6cYRiGcfbsWfuXGpKMxx57zGG9Q4cO2QPYgw8+aBw7dsw+Ly4uzvj111+NiRMnGps2bbJPT05Otu/jrbfeauzbt88+Lykpydi0aZPxyCOPGD/++ONl7z8A8xCuADhdUcNVYGCgceTIkWJvZ9q0aYYko3fv3nnmFSVcSTJGjRqVb9sPPvhggVdBihKuJBmTJ0/Ot+0bbrjBkGRcc801DtNtNpvRoEEDQ5LRp08fw2azFVp7cQLIpdx9992GJGPs2LF55pVk3wzDMJo2bWqv++KrKYZhGLNmzSrRvmVnZxvh4eGFHtdHH33UHuzzuypZkOK+1wqbN2HCBEOSUblyZePkyZN55v/111/28HKpEJSfL774wh5uLqeuCxX2Xu/fv7/9HLkwkObasmWL/SrUtGnTCtx+z549830/zJgxw5Bk+Pj4GJmZmZfYW0fFCVdHjx611ztp0qR8l8n9d8HDw8OIiYmxT//ss88MSUbDhg2LXOOGDRsMSYafn99l7x+AK4dnrgCUGbfddpvCw8OLvX5uL2/r1q1TdnZ2sdp48skn851+/fXXS8p5FiQlJeWy2/Xy8tLDDz9caNt//vmnw/Q//vjD3j34E088ke9zOqNGjVLt2rUvu56iyn1N16xZU+Ayxdm3P//8Uzt37pSU85pbrXn/u7rzzjtL1OW31Wq1Py/05ZdfKikpyWF+dna2Pv74Y0nSsGHD5O/vX+S2zXivXcgwDH322WeSpLvuuktVqlTJs0zz5s31r3/9q9jbyK15//79pvfaGRcXpyVLlkiSHnnkEfn6+uZZ5qqrrtINN9wgSZo/f36BbT3xxBP5vh9y30upqamKjo42o+xCffXVV8rKypK3t7cef/zxfJd58skn5eXlpczMTHunKJIUHBwsKaezlNzn+S4ld52MjAydOXOmRLUDKD2EKwBlRteuXS+5zMmTJzV58mR17txZlStXlru7u/1B+KZNm0rK6YygoM4nClOpUiU1aNAg33k1atSw/704bTdr1qzAD++5bV/8cPuWLVskSR4eHurSpUu+61osFvXo0eOy67nQgQMH9PDDD6tt27YKDg6Wm5ub/TUdOHCgJBX6EH1x9m3Tpk2SJHd3d3Xr1i3fda1Wa7E66bjQmDFjZLFYlJycbA8vuRYvXqzjx49Lyn9sq9J8r13s4MGD9teoV69eBS5X2Dwp58P8tGnT1KNHD1WpUkWenp72mi8MPGZ3irBlyxZ7ZxnXXHNNgcv16dNHUk64LqjDko4dO+Y7/cJzML+OIMyW+x5t3769AgMD810mJCRE7dq1c1heyulyPzQ0VMePH1fHjh315ptvavfu3fl2KJKrfv36aty4sTIzM9WxY0e9+OKL+uOPP0wJ7wDMQ3+yAMqM/L6tv9C6des0cOBAxcXF2af5+/vbexXMzs5WbGysJCk5OVmhoaGXtf2AgIAC513YPXdxerErSttZWVkO00+fPi1Jqly5sjw9PQtcvyRXd7755hsNHz5c6enp9mmBgYHy9vaWxWJRRkaGzp07V+i378XZt1OnTkmSQkND5eXlVeD6JbmSKUn16tVTVFSUVqxYoQ8++MAhRH3wwQeSpMaNG+cJr6X9XrtY7ushFX48C3s99u7dq969ezsEJ19fXwUHB9uvBOX2OFjUqylFdbn1Z2Vl6ezZs/kOKl7Q+6mk5+Dlyt2nS51fuft04WsQHBys+fPna8SIEdqxY4fuvfdeSTmDMHfv3l3Dhg3TTTfdJA8PD/s6bm5uWrBggYYOHaqDBw/q8ccf1+OPPy5fX1916dJFN9xwg0aNGpXvVUEAVw5XrgCUGW5ubgXOy8rK0vDhwxUXF6fWrVtr0aJFSkhIUGJiok6ePKkTJ044dBte2DfEZU1h3XaXxJkzZzR69Gilp6erV69eWrlypVJSUhQfH29/Tb/44otS2faVlBuo1q5dq71790rKCa4//PCDpH+6X89VVt9rY8aM0dGjRxUREaEvvvhCZ86cUXJysk6dOqUTJ044dGPuKjWXZ9dcc40OHjyojz76SKNGjVJkZKTi4+O1cOFC3XbbbbrqqqvydC3fqlUr7d69W1999ZXGjRun5s2bKzU1VcuWLdPEiRPVuHFj/fXXX07aIwAS4QpAObFu3TodPnxYbm5u+uGHHzRgwIA833Cb/RyJs4WFhUmSYmNjlZGRUeByxR37Jzc0hISEaOHCherRo4d8fHwclimt1zT3KmVp7duFbrzxRvvzLLlXq+bNm6fMzEy5u7tr5MiRDss747124VXbwva5oHlHjhzR2rVrJeU8z/Svf/1LlSpVclimNM+PC+sv7JbD3Hnu7u556nM1uft0qVsoc+fnd+Xdz89Pt912m+bOnau9e/fq6NGjevHFF+Xt7e1wRetCnp6euuGGG/TOO+/or7/+0unTpzVr1ixVqlRJR44c0ahRo0zYOwDFRbgCUC4cOXJEUk7gKOg2nWXLll3JkkpdmzZtJOXcApX7wflihmFo9erVxWo/9zVt1KhRgbcaldZrmvucSlZWln799dd8l7HZbFq5cmWJt+Xt7a0RI0ZIkj766CNlZ2drzpw5kmQfGPZCzniv1a1b1x42VqxYUeByv/zyS77Tc2uWcjqOyE9hNV/YgURxrmq1adPG3sby5csLXC63hlatWjncEueKLnyWKj4+Pt9l4uLiHJ7NupSaNWvq0Ucf1UMPPSRJ+vnnny+5TuXKlTV+/Hi9+OKLkqStW7fS4QXgRIQrAOVCUFCQpJxnRnKfG7nQ0aNHNWPGjCtdVqlq3bq1vYONF154Id8PvfPmzdPhw4eL1X7ua7p3716lpaXlmf/HH3/o008/LVbbl9KyZUs1adJEkjR16lTZbLY8y3zwwQemdbyQe2vg8ePH9dxzz9lvrbr4lkDJOe81i8WiYcOGSZJmzZplf57rQjt37nToke5CuTVL0rZt2/LMT0xM1P/+978Ct39hhw0XPmdWVMHBwerXr58kadq0afn2qLlt2zZ99dVXkqThw4df9jautBtvvFHu7u5KS0uzB5uL/d///Z/S09Pl4eGhG2+80T79wmcY85N7hfjCUFvUdS5eD8CVxdkHoFy4+uqr5efnJ8MwNGzYMPuzM9nZ2VqyZImioqJK7dkkZ7FYLHrmmWckSUuWLNGoUaMUExMjSUpLS9P777+v8ePHKyQkpFjt9+3bV1arVWfPntUtt9xiv+UsIyNDn3/+ufr27VtoZxUlNXXqVEk5V2pGjBhhD1JpaWmaNWuW7rnnHvvtfCXVpk0btW7dWpL03HPPSZKqV69u7w3xQs56r02aNEkBAQGKjY1Vnz597FdEDMPQ0qVLNWDAgAKvMDZp0sTeJf/tt9+uzZs32+etW7dOUVFRhfZq2LBhQ3unKbNnzy7W1av//e9/8vDw0L59+9SvXz97gLXZbFq0aJEGDhyorKws1a9fX+PHj7/s9s2SlJSk2NjYQn+ys7NVs2ZN3X///ZJyvtyYPHmyPXjGxcXpqaee0rRp0yRJDz74oKpXr27fxosvvqgBAwbo448/dviCID09XZ9//rl9vdzu8SVpwYIF6tq1q9555x0dOHDAPj33fZfbHXznzp2Lfc4DMIFTRtcCgAsUdRDhFStWFNrOzJkz7cvq/MCv3t7ehiQjNDTU+P777+3zDh486LBuUQYRzm9g1FwXDkJ6cdtFGUS4sEFwLzWA6wMPPGCfb7FYjJCQEPtgsr169TImTZpkSDL69etX4DYK8thjjzm8pkFBQfa269ata3zyyScF1mbGvv33v/912H5ISIh94NZu3brZ982MAZLfeOMNh209/vjjBS5bWu+1S70eP/zwg+Hl5WVfJiAgwPDx8TEkGdWrVzc++OCDAtdfuHCh/bWTZPj6+hq+vr72gWmXLVtW6Lk2duxYh3Vr165t1KlTx3jooYfsy1zqXFmwYIHh6elpbycwMND+ukkyatWqZezcufOyX5dcRf234mIXnr9F+dm6dathGIaRnp5uDBs2zD7darUaISEhhtVqtU8bPny4kZGR4bC9C//N0/mBjytVqmRYLBb7tCZNmhjHjx/P89rm/nh5eRmVK1d22FaNGjWMXbt2Xda+AzAXV64AlBt33XWXfvzxR0VFRcnf319ZWVmqWbOm7r33Xm3btk0tWrRwdoml4rXXXtPXX3+tqKgoBQQEKD09XU2aNNG0adO0ZMkSe7faxbnK88ILL+ijjz5Shw4d5OPjo8zMTDVo0EBPPPGEtm7d6jC2UGn43//+px9++EG9evVSYGCgfd9eeOEFLV++vNAu6C/XLbfcIm9vb/vv+d0SmMtZ77VBgwZpy5Ytuvnmm1WlShVlZGSoatWquueee7R161bVrVu3wHUHDx6s1atXa9CgQQoODlZWVpZCQ0M1ZswYbd68Wb179y5022+99ZamTJli37e///5bhw8fzvcWxYLcdNNN2rFjh8aPH6/69esrPT1d7u7uat26tZ555hlt377dfjtoWeDp6anPPvtMX375pQYMGKDKlSsrMTFRlStX1oABA/T111/r008/zfP82Lhx4/Tuu+9q+PDhat68uXx9fe2dx3Tr1k2vv/66tmzZomrVqtnXue666/TRRx9pzJgxatWqlYKCghQfH6+AgAB16NBBzz33nHbs2KHGjRtf6ZcBwAUshkF/qwBQnnXt2lVr167Vs88+q6eeesrZ5QAAUG5x5QoAyrFVq1bZexLs37+/k6sBAKB8I1wBQBl39913a+7cuTpx4oS9o4G4uDi98847uv766yVJvXr1KlJX0AAAoPi4LRAAyrjWrVvbu9f28vKSr6+v4uLi7EGradOmWrp0aYFjMgEAAHMQrgCgjPv+++/17bffasOGDTp58qTi4+MVGBioZs2a6YYbbtC4ceMK7KIbAACYh3AFAAAAACbgmSsAAAAAMIG7swtwVTabTTExMQoICJDFYnF2OQAAAACcxDAMJSYmqkaNGrJaC74+RbgqQExMjGrVquXsMgAAAAC4iCNHjig8PLzA+YSrAgQEBEjKeQEDAwOdXA0AAAAAZ0lISFCtWrXsGaEghKsC5N4KGBgYSLgCAAAAcMnHhejQAgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrlxdRoqUnSEln875MyPF2RUByA/nKuD6OE+BsqEMn6vuzi4AhchKk357XdrwjpQWJ3kHSx3HS90elNy9nVwcADvOVcD1cZ4CZUMZP1cJV64qIyXnjbXqxX+mpcX983uXeyULFx4BpzNs0to3OFcBV8Z5CpQNlzpXuz4gefo6o7IisxiGYTi7CFeUkJCgoKAgxcfHKzAw8MoXkJ0hTYvMeUNdzDtYenCn9HoLKeXMla4MQC7fytIDf0mvNuVcBVwV5ylQNhTlXH0kWnLzvNKVSSp6NuBrGleVFp//G0vKmZ4SK/lXvZIVAbiYf1UpOZZzFXBlnKdA2VCUczUt4UpWVCzcFuiqvINyEnpByT2gunTHsitcFIA83Dw4VwFXx3kKlA2XOle9nXA32WUiXLmq7Kych/cuvOc0V8fxOfM9/a58XQAcZaRwrgKujvMUKBuKcq466bbAoiJcuSpP35xeUaQy21sKUCFwrgKuj/MUKBvKwblKhxYFcHqHFrkyUiQ395x7TL0DpexMvl0DXBHnKuD6OE+BssEFz9WiZgOuXLm63O4m/UJz/nTxS6FAhcW5Crg+zlOgbCjD5yq9BQIAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJjAZcLVN998oz59+qhy5cry9vZW3bp1NXz4cB05cqRI69tsNr3xxhtq0aKFfHx8FBYWpuHDh+vAgQOlXDkAAAAASO7OLsAwDN1111169913Vb9+fd18880KCAhQTEyMVq1apcOHD6tWrVqXbGf8+PGaPXu2mjVrpvvuu08xMTH6/PPPtXTpUq1fv16RkZFXYG8AAAAAVFROD1czZszQu+++q4kTJ2rGjBlyc3NzmJ+VlXXJNlasWKHZs2ere/fu+vnnn+Xp6SlJGjFihAYOHKh77rlHS5YsKZX6AQAAAECSLIZhGM7aeGpqqmrWrKmQkBDt2bNH7u7Fy3ojRozQ/PnztWrVKnXv3t1hXs+ePbVy5UodPnxYtWvXLnKbCQkJCgoKUnx8vAIDA4tVFwAAAICyr6jZwKnPXC1dulTnzp3TkCFDlJ2dra+//lovvPCCZs2apX379hW5nZUrV8rPz09du3bNM69fv36SpFWrVplWNwAAAABczKm3BW7evFmS5ObmppYtW2rv3r32eVarVf/5z3/08ssvF9pGcnKyjh8/rubNm+e5pVCS/Vmr6OjoQttJT09Xenq6/feEhIQi7wcAAAAAOPXK1alTpyRJr776qoKCgrRx40YlJiZq9erVatiwoV555RXNnDmz0Dbi4+MlSUFBQfnOz71sl7tcQZ5//nkFBQXZf4rSiQYAAAAA5HJquLLZbJIkT09Pffvtt2rfvr38/f3VrVs3ffHFF7JarXrllVeuSC2TJk1SfHy8/aeoXcADAAAAgOTk2wJzrza1a9dONWrUcJjXvHlz1atXT/v27VNcXJyCg4MLbaOgK1O5t/cVdGUrl5eXl7y8vC6nfAAAAACwc+qVq0aNGklSgcEpd3pqamqBbfj5+al69eo6ePCgsrOz88zPfdaKca4AAAAAlCanhquePXtKknbt2pVnXmZmpvbt2yc/Pz+FhYUV2k6PHj2UnJys3377Lc+83PGtLu6iHQAAAADM5NRwVb9+ffXt21f79u3T7NmzHea98MILiouL09ChQ+3jX8XGxmr37t2KjY11WHbcuHGSpKeeekoZGRn26YsXL9bKlSvVt29f1alTp5T3BgAAAEBF5tRBhCVp//796tKli06dOqVBgwapcePG2rp1q3755RfVqVNH69evV7Vq1SRJU6ZM0TPPPKPJkydrypQpDu3ceeedmj17tpo1a6ZBgwbp+PHj+uyzz+Tv769169apYcOGl1UXgwgDAAAAkMrIIMJSztWrTZs2afTo0dq8ebNmzJih6Oho3X333dq4caM9WF3KO++8o+nTp0uSpk+frkWLFmno0KHauHHjZQcrAAAAALhcTr9y5aq4cgUAAABAKkNXrgAAAACgPCBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmMDp4SoiIkIWiyXfn6ioqCK1cejQoQLbsFgsmjJlSqnuAwAAAAC4O7sASQoKCtIDDzyQZ3pERMRltdOqVSsNGTIkz/SihjQAAAAAKC6XCFfBwcGmXF1q3bo1V6kAAAAAOIXTbwsEAAAAgPLAJa5cpaena+7cuYqJiVFgYKDat2+vjh07XnY7MTExeuuttxQfH6+qVasqKipK9evXL4WKAQAAAMCRxTAMw5kFRERE6PDhw3mmt2/fXvPnzy9SODp06JDq1q2bZ7rFYtEtt9yiWbNmyc/Pr9A20tPTlZ6ebv89ISFBtWrVUnx8vAIDA4uwJwAAAADKo4SEBAUFBV0yGzj9tsAxY8Zo+fLlOnnypJKTk7V161bddttt+v3339W7d28lJiZesg1fX1899dRT2rx5s+Li4nT27FktW7ZMHTp00Lx58zRy5MhLtvH8888rKCjI/lOrVi0zdg8AAABABeH0K1cFGTlypD7++GO98sorevDBB4vVRkpKitq0aaM9e/Zo8+bNatOmTYHLcuUKAAAAQH7KzJWrgowfP16S9NtvvxW7DV9fX912221FasfLy0uBgYEOPwAAAABQVC4brkJDQyVJycnJLtEOAAAAABTGZcPVhg0bJF3+QMKl1Q4AAAAAFMap4Wr37t1KSUnJd/pjjz0mSRoxYoR9enx8vHbv3q3jx487LL9161bl9+jY119/rQ8//FAhISEaMGCAydUDAAAAwD+cOs7VggUL9Oqrr6p79+6qU6eO/Pz8tHfvXi1atEiZmZmaNGmSunfvbl/+m2++0ZgxYzRq1CjNnTvXPv0///mP9u/fr86dOys8PFzZ2dnasmWL1qxZIy8vL82dO1dBQUFO2EMAAAAAFYVTw1XPnj21a9cubd26Vb/++qtSUlIUGhqqgQMHauLEierbt2+R2rn11lv11Vdfaf369YqNjZXNZlPNmjV1xx136KGHHlLjxo1LeU8AAAAAVHQu2xW7sxW1u0UAAAAA5VuZ74odAAAAAMoSwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmIBwBQAAAAAmIFwBAAAAgAkIVwAAAABgAsIVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYAKnh6uIiAhZLJZ8f6Kioi6rrU8++UQdOnSQn5+fQkJCNHjwYG3ZsqV0CgcAAACAC7g7uwBJCgoK0gMPPJBnekRERJHbmDp1qp588knVqVNHd911lxITE7VgwQJ16dJFy5cvV9euXc0rGAAAAAAuYjEMw3BmAbkB6tChQ8VuIzo6Wk2bNlW9evW0ceNGBQUFSZL++OMPderUSfXq1dP27dtltRb9Ql1CQoKCgoIUHx+vwMDAYtcGAAAAoGwrajZw+m2BZpgzZ46ysrL03//+1x6sJKl169YaPny4du3apTVr1jixQgAAAADlnUuEq/T0dM2dO1f/93//pzfffFMbNmy4rPVXrlwpSerbt2+eef369ZMkrVq1qsR1AgAAAEBBXOKZqxMnTmjMmDEO09q3b6/58+erfv36l1w/Ojpa/v7+qlatWp55kZGR9mUKk56ervT0dPvvCQkJRSkdAAAAACS5wJWrMWPGaPny5Tp58qSSk5O1detW3Xbbbfr999/Vu3dvJSYmXrKN+Ph4h9sBL5R7T2R8fHyhbTz//PMKCgqy/9SqVevydwYAAABAheX0cDV58mT16tVLVapUka+vr1q3bq2PPvpIt912mw4fPqz33nvvitQxadIkxcfH23+OHDlyRbYLAAAAoHxwergqyPjx4yVJv/322yWXze25Iz+5t/cVdGUrl5eXlwIDAx1+AAAAAKCoXDZchYaGSpKSk5MvuWxkZKSSkpJ04sSJPPNyn7XKffYKAAAAAEqDy4ar3B4DizKQcI8ePSRJS5cuzTNvyZIlDssAAAAAQGlwarjavXu3UlJS8p3+2GOPSZJGjBhhnx4fH6/du3fr+PHjDsuPGTNG7u7umjp1qsPtgX/88Yfmz5+vJk2a6Oqrry6lvQAAAAAAJ3fFvmDBAr366qvq3r276tSpIz8/P+3du1eLFi1SZmamJk2apO7du9uX/+abbzRmzBiNGjVKc+fOtU9v2LChpkyZoieffFKtWrXSjTfeqMTERC1YsECS9N5778lqddmLdAAAAADKAaeGq549e2rXrl3aunWrfv31V6WkpCg0NFQDBw7UxIkT8x0UuCD//e9/FRERoddff10zZ86Up6enunXrpueee05t2rQpxb0AAAAAAMliGIbh7CJcUUJCgr0XQnoOBAAAACquomYD7pUDAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADBBscLVkSNHdPToUfvvGzdu1AMPPKB3333XtMIAAAAAoCwpVrgaMWKEVqxYIUk6ceKE+vTpo40bN+q///2vnn32WVMLBAAAAICyoFjhavv27erQoYMk6fPPP1fz5s21du1affLJJ5o7d66Z9QEAAABAmVCscJWZmSkvLy9J0rJly3TddddJkho3bqzjx4+bVx0AAAAAlBHFClfNmjXTrFmz9Ouvv+rnn39W//79JUkxMTGqXLmyqQUCAAAAQFlQrHD14osv6p133lFUVJSGDx+uVq1aSZK+//57++2CAAAAAFCRWAzDMIqzYnZ2thISEhQSEmKfdujQIfn6+qpKlSqmFegsCQkJCgoKUnx8vAIDA51dDgAAAAAnKWo2KNaVq9TUVKWnp9uD1eHDh/X6669rz5495SJYAQAAAMDlKla4uv766/XRRx9JkuLi4tSxY0e98sorGjJkiGbOnGlqgQAAAABQFhQrXG3ZskXdunWTJH355ZeqWrWqDh8+rI8++kgzZswwtUAAAAAAKAuKFa5SUlIUEBAgSVq6dKluuOEGWa1WderUSYcPHza1QAAAAAAoC4oVrho0aKBvv/1WR44c0ZIlS9S3b19J0qlTp+j8AQAAAECFVKxw9fTTT+vhhx9WRESEOnTooM6dO0vKuYp11VVXmVogAAAAAJQFxe6K/cSJEzp+/LhatWolqzUno23cuFGBgYFq3LixqUU6A12xAwAAAJCKng3ci7uBatWqqVq1ajp69KgkKTw8nAGEAQAAAFRYxbot0Gaz6dlnn1VQUJDq1KmjOnXqKDg4WM8995xsNpvZNQIAAACAyyvWlav//ve/ev/99/XCCy+oa9eukqQ1a9ZoypQpSktL09SpU00tEgAAAABcXbGeuapRo4ZmzZql6667zmH6d999p4kTJ+rYsWOmFegsPHMFAAAAQCp6NijWbYFnz57Nt9OKxo0b6+zZs8VpEgAAAADKtGKFq1atWunNN9/MM/3NN99Uy5YtS1wUAAAAAJQ1xXrm6qWXXtKgQYO0bNky+xhX69at05EjR7Ro0SJTCwQAAACAsqBYV6569OihvXv3aujQoYqLi1NcXJxuuOEG7dixQx9//LHZNQIAAACAyyv2IML52bZtm9q0aaPs7GyzmnQaOrQAAAAAIJVyhxYAAAAAAEeEKwAAAAAwAeEKAAAAAExwWb0F3nDDDYXOj4uLK0ktAAAAAFBmXVa4CgoKuuT8kSNHlqggAAAAACiLLitczZkzp7TqAAAAAIAyjWeuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATEC4AgAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAE7hkuHrxxRdlsVhksVi0fv36Iq2zcuVK+zr5/cydO7d0iwYAAABQobk7u4CLbd++XZMnT5afn5+Sk5Mve/0ePXooKioqz/TWrVuXvDgAAAAAKIBLhavMzEyNGjVKrVu3VmRkpObNm3fZbURFRWnKlCnmFwcAAAAAhXCp2wKnTp2qHTt26IMPPpCbm5uzywEAAACAInOZK1dbtmzR1KlT9eyzz6pp06bFbic6Olqvv/66UlNTFR4erl69eqlmzZomVgoAAAAAeblEuEpPT9fIkSPVunVrPfrooyVq69NPP9Wnn35q/93d3V333nuvpk2bVujVsPT0dKWnp9t/T0hIKFEdAAAAACoWl7gt8Omnn1Z0dLTmzJlT7NsBw8LC9MILL2j79u1KSkrSyZMn9e2336pBgwZ67bXXLhnann/+eQUFBdl/atWqVaw6AAAAAFRMFsMwDGcWsG7dOl199dWaMmWKnnrqKfv00aNH68MPP9S6devUqVOnYrd/4sQJtWzZUufOndOxY8dUpUqVfJfL78pVrVq1FB8fr8DAwGJvHwAAAEDZlpCQoKCgoEtmA6deucrKytKoUaPUsmVLPf7446WyjWrVqun6669XVlaWNmzYUOByXl5eCgwMdPgBAAAAgKJy6jNXSUlJio6OliR5enrmu0znzp0lSd98842GDBlSrO2EhoZKUrHGzQIAAACAonBquPLy8tLYsWPznbd69WpFR0fruuuuU1hYmCIiIoq9ndwrViVpAwAAAAAK49Rw5ePjo9mzZ+c7b/To0YqOjtakSZMcnrmKjY1VbGysQkND7VekJGnz5s1q27ZtnnamT5+uFStWKDIyUu3btzd/JwAAAABALtIV++V488039cwzz2jy5MmaMmWKffqNN94oDw8PtWvXTuHh4UpOTtb69eu1detWBQcHa968eQxMDAAAAKDUlLlwVZAJEyZoyZIlWr16tc6cOSOr1ao6derogQce0EMPPaTw8HBnlwgAAACgHHN6V+yuqqjdLQIAAAAo38pEV+wAAAAAUF4QrgAAAADABIQrAAAAADAB4crFpWZkKSPLpjNJ6crIsiklI8vZJQEAAADIR7npLbA8Ss/M1qxVBzRn7UElpGYp0MddY7rU1cSo+vLyoFt5AAAAwJUQrlxUakaWZq06oOnLo+3TElKz7L+P71FPvp4cPgAAAMBVcFugi3KzWjVn7cF8581Ze1DuVg4dAAAA4Er4hO6iEtMylZCa//NVCalZSkjLvMIVAQAAACgM4cpFBXh7KNAn/9v+An3c5evppqk/7tTJhLQrXBkAAACA/BCuXFS2zaYxXermO2905witiY7Ve78eVI9pK/T84l2KS8m4whUCAAAAuBDhykX5eLprYlR93d870n4FK9DHXff3jtTdPRuoaqC32tYJUVqmTe+sOqBuL67QG8ujlZxOV+0AAACAM1gMwzCcXYQrSkhIUFBQkOLj4xUYGOi0OlIysuRutSoxLVMB3h7KstnsvQQahqFfdp/StCV7tPtEoiQp1N9Td/dsoBEda8vLne7aAQAAgJIqajYgXBXAVcJVUdhshhb+GaNXf96rw2dSJEk1g330wDWRuqFNuNysFidXCAAAAJRdhKsSKkvhKldmtk2fbzqiGcujdTIhXZLUoIq/HurTUP2bV5PFQsgCAAAALhfhqoTKYrjKlZaZrQ/XHtLMVfsVl5LTZXvL8CA90q+Rrm4QSsgCAAAALgPhqoTKcrjKlZCWqfdWH9D7aw4qJSNbktS5XmU90r+R2tQOcXJ1AAAAQNlAuCqh8hCucsUmpeutFfv0yfq/lZFtkyRd06SqHunXSI2qBTi5OgAAAMC1Ea5KqDyFq1xHz6VoxvJofbn5qGyGZLFIQ1rX1H+uaajalX2dXR4AAADgkghXJVQew1WufaeS9OrPe7TorxOSJHerRcM71Na9vRqoSqC3k6sDAAAAXAvhqoTKc7jK9dfReL20ZLd+jY6VJHl7WDW6S11N6FFfQb4eTq4OAAAAcA2EqxKqCOEq17r9Z/TSkt3a+necJCnA21139aivMV0j7AMWAwAAABUV4aqEKlK4kiTDMLR81ym9vHSPdp9IlCSF+nvp3l4NdHOHWvJyd3NyhQAAAIBzEK5KqKKFq1zZNkMLt8Xo1Z/36u+zKZKk8BAfPXBNQw29qqbcrIyRBQAAgIqFcFVCFTVc5crIsumzTUf0xvJonUpMlyQ1qOKvh/s2VL9m1RiIGAAAABUG4aqEKnq4ypWaka0P1x3SzJX7FZ+aKUlqFR6kR/o11tWRoU6uDgAAACh9hKsSIlw5ik/N1HurD+iD3w4qJSNbktSlfmU90q+Rrqod4uTqAAAAgNJDuCohwlX+Tiem660V+/Tphr+VkW2TJPVtWlUP92ukhlUDnFwdAAAAYD7CVQkRrgp39FyKXl8Wra+3HJXNkCwWaWjrmvpPn4aqVcnX2eUBAAAApiFclRDhqmiiTybqlaV79dOOE5IkDzeLhneorXt6NVCVAG8nVwcAAACUHOGqhAhXl2fbkTi9vHSPfo2OlST5eLhpTNcIje9eX0G+Hk6uDgAAACg+wlUJEa6KZ+3+WL300x79cSROkhTo7a7xPeprTNcI+Xq6O7c4AAAAoBgIVyVEuCo+wzD0886TennpHu09mSRJCvX30n29G+jm9rXl6W51coUAAABA0RGuSohwVXLZNkPfbzumV3/eqyNnUyVJ4SE++s81DTXkqppyszIQMQAAAFwf4aqECFfmyciy6bPf/9aMX/bpdGK6JKlhVX891LeR+jatKouFkAUAAADXRbgqIcKV+VIysvTh2sOauXKfEtKyJEmtawXr0X6N1KVBqJOrAwAAAPJHuCohwlXpiU/N1Lur9+uDNYeUmpktSbq6Qage6ddIrWoFO7c4AAAA4CKEqxIiXJW+U4lpeuuXffp049/KzM55G/ZrVlUP922kyKoBTq4OAAAAyEG4KiHC1ZVz5GyKXlu2V99sPSbDkKwWaehV4XrgmkjVquTr7PIAAABQwRGuSohwdeXtPZmoV5bu0ZIdJyVJHm4WjehQW/f0ilRYgJeTqwMAAEBFRbgqIcKV8/xxJE4vL9mjNftiJUk+Hm66/eoIjeteX0E+Hk6uDgAAABUN4aqECFfOt3ZfrF5cskfbjsRJkoJ8PHRXj/oa3SVCPp5uzi0OAAAAFQbhqoQIV67BMAwt3XlSLy/Zo+hTSZKksAAv3dergW5qX1ue7lYnVwgAAIDyjnBVQoQr15JtM/Tt1mN6bdleHT2XKkmqXclX/+kTqeta1ZSblYGIAQAAUDoIVyVEuHJNGVk2Lfj9b81Yvk+xSemSpEZVA/Rwv0a6pkkVWSyELAAAAJiLcFVChCvXlpKRpTm/HdI7q/YrIS1LknRV7WA90q+RutQPdXJ1AAAAKE8IVyVEuCob4lMyNWv1fs357aDSMm2SpG6RoXqkXyO1DA92bnEAAAAoFwhXJUS4KltOJaTpzRX7NH/j38rMznlL929WTQ/3a6gGVQKcXB0AAADKMsJVCRGuyqa/z6To9WV79c0fx2QYktUi3dAmXA9cE6nwEF9nlwcAAIAyiHBVQoSrsm3vyUS9vGSPlu48KUnydLNqRMfauqdXA4X6ezm5OgAAAJQlhKsSIlyVD1v/PqdpS/Zo7f4zkiRfTzfd3rWuxvWop0BvDydXBwAAgLKAcFVChKvyZU10rKYt2a1tR+MlSUE+HpoQVV+jOkfIx9PNydUBAADAlRGuSohwVf4YhqElO07o5aV7te9UkiSpSoCX7usdqZva15KHm9XJFQIAAMAVEa5KiHBVfmXbDH2z9Zhe+3mvjsWlSpJqV/LVg30a6rpWNWS1MhAxAAAA/kG4KiHCVfmXnpWt+Rv+1psr9ik2KUOS1LhagB7u20i9m1SRxULIAgAAAOGqxAhXFUdyepbmrj2kWav2KzEtS5LUpnawHunXWJ3rV3ZydQAAAHA2wlUJEa4qnriUDM1adUBz1x5UWqZNktQtMlSP9musFuFBTq4OAAAAzkK4KiHCVcV1KiFNM36J1oKNR5Rlyzk9Braopgf7NFKDKv5Org4AAABXWlGzgUt2j/biiy/KYrHIYrFo/fr1RV7PZrPpjTfeUIsWLeTj46OwsDANHz5cBw4cKMVqUd5UCfTW/4a00C8PRWnoVTVlsUiL/jqhvq+t0qNfbrN3ggEAAABcyOWuXG3fvl3t2rWTu7u7kpOTtW7dOnXq1KlI6955552aPXu2mjVrpkGDBikmJkaff/65/P39tX79ekVGRha5Dq5cIdfuEwl6ecleLdt1UpLk6WbVLZ1q6+6eDRTq7+Xk6gAAAFDayuRtgZmZmerUqZM8PDwUGRmpefPmFTlcrVixQr169VL37t31888/y9PTU5K0ePFiDRw4UH379tWSJUuKXAvhChfbfPicpi3ZrfUHzkqS/DzdNPbqurqjez0Fens4uToAAACUljJ5W+DUqVO1Y8cOffDBB3Jzc7usdd977z1J0nPPPWcPVpI0YMAARUVFaenSpfr7779NrRcVS9s6IZp/Zyd9PLaDWtQMUnJGtmb8sk/dX1qhd1fvV1pmtrNLBAAAgBO5TLjasmWLpk6dqsmTJ6tp06aXvf7KlSvl5+enrl275pnXr18/SdKqVatKXCcqNovFom6RYfr+nq6aeUsb1Q/zU1xKpv5v0W71mLZCn2w4rMxsm7PLBAAAgBO4RLhKT0/XyJEj1bp1az366KOXvX5ycrKOHz+uunXr5nvFK/dZq+jo6EJrSEhIcPgBCmKxWDSgRXUteaC7XvpXS9UM9tHJhHT995vt6vPqKn33xzHZbC5zxy0AAACuAJcIV08//bSio6M1Z86cy74dUJLi4+MlSUFB+Y9FlHtfZO5y+Xn++ecVFBRk/6lVq9Zl14GKx93NqmHtaumXh3to8rVNVdnPU4fOpOj+BX9o4IxftXzXSbnQY40AAAAoRU4PV+vWrdPLL7+sJ598Us2bN3daHZMmTVJ8fLz958iRI06rBWWPl7ubxnStq9WP9tRDfRoqwMtdu08kauyHm/TvWeu04cAZZ5cIAACAUubUcJWVlaVRo0apZcuWevzxx4vdTu4Vq4KuTOXe4lfQlS1J8vLyUmBgoMMPcLn8vNx1b+9IrX60p8b3qCcvd6s2HT6nm95dr1EfbNT2YwVfPQUAAEDZ5u7MjSclJdmfg7qwh78Lde7cWZL0zTffaMiQIfku4+fnp+rVq+vgwYPKzs7Oc2th7jYuZ5wroCRC/Dw1aUAT3d61rmYsj9Znvx/Rqr2ntWrvaQ1qWV0P9mmo+mH+zi4TAAAAJnJquPLy8tLYsWPznbd69WpFR0fruuuuU1hYmCIiIgptq0ePHlqwYIF+++03de/e3WFe7vhWF08HSlvVQG9NHdpCd3arp9eW7dX322L045/H9dP2E/pXm3Ddf02kagT7OLtMAAAAmMClBhG+0OjRo/Xhhx/mGUQ4NjZWsbGxCg0NVWhoqH06gwijLNh1PEGvLN2jZbtOSZI83a26rVMdTYyqr8r+Xk6uDgAAAPkpk4MIF8Wbb76pJk2a6M0333SY3rNnT91xxx1avXq12rRpo8cee0wjR47UkCFDVKlSJb3xxhtOqhj4R5PqgZo9qr2+mtBZHetWUkaWTe+vOajuL63Qqz/vVWJaprNLBAAAQDGVuXBVmHfeeUfTp0+XJE2fPl2LFi3S0KFDtXHjRjVs2NDJ1QH/aFunkhaM66QPb++g5jUDlZyRrRnLo9X9pRV6b/UBpWVmO7tEAAAAXCaXvS3Q2bgtEFeKYRhavP2EXl66RwdOJ0uSqgV6677ekfp3u3B5uJWr70AAAADKnKJmA8JVAQhXuNKysm36essxvb5sr2Li0yRJdUP99J8+DTW4RXVZrRYnVwgAAFAxEa5KiHAFZ0nLzNYnG/7WWyv26WxyhiSpafVAPdKvkaIahcliIWQBAABcSYSrEiJcwdmS0rP0wZqDem/1ASWmZ0mS2keE6NH+jdU+opKTqwMAAKg4CFclRLiCqziXnKGZq/brw7WHlJ5lkyRFNQrTw30bqXnNICdXBwAAUP4RrkqIcAVXcyI+TdOXR+vzTUeUbcs5bQe3rK4H+zRUvTB/J1cHAABQfhGuSohwBVd1KDZZr/68V99vi5EkuVkt+nfbcN1/TaSqB/k4uToAAIDyh3BVQoQruLqdMQl6eeke/bL7lCTJ092qkZ3qaGLPBqrk5+nk6gAAAMoPwlUJEa5QVmw6dFYvLdmjjQfPSpL8vdx1R7e6uqNbPfl7uTu5OgAAgLKPcFVChCuUJYZhaNXe05q2ZI92xCRIkir5eWpiVH3d2qmOvD3cnFwhAABA2UW4KiHCFcoim83Qou3H9erSvToQmyxJqh7krft7R+pfbcPl7mZ1coUAAABlD+GqhAhXKMuysm36astRvb4sWsfj0yRJ9UL99GDfhhrYvLqsVgYiBgAAKCrCVQkRrlAepGVma976w3p75X6dTc6QJDWrEaiH+zVSVMMwWSyELAAAgEshXJUQ4QrlSWJapj5Yc0jv/XpASelZkqQOEZX0aP9GahdRycnVAQAAuDbCVQkRrlAenU3O0MyV+/ThusPKyLJJkno2CtPD/RqpWY0gJ1cHAADgmghXJUS4Qnl2PD5VM5ZH6/NNR5Vty/kn4NpWNfRgn4aqG+rn5OoAAABcC+GqhAhXqAgOnE7Sa8uitXBbjCTJzWrRsHa1dH/vSFUL8nZydQAAAK6BcFVChCtUJDti4vXykj1asee0JMnL3apRXSI0oUd9hfh5Ork6AAAA5yJclRDhChXRxoNnNW3Jbv1+6Jwkyd/LXXd2q6ex3erK38vdydUBAAA4B+GqhAhXqKgMw9DKPaf10pI92nU8QZJU2c9TE3s20C0da8vbw83JFQIAAFxZhKsSIlyhorPZDP3413G9+vNeHYxNliTVCPLW/ddE6sY24XJ3szq5QgAAgCuDcFVChCsgR2a2TV9uPqrpy6J1IiFNklQvzE8P9WmkAc2ryWplIGIAAFC+Ea5KiHAFOErLzNa89Yf11op9OpeSKUlqXjNQD/dtpB4Nw2SxELIAAED5RLgqIcIVkL/EtEzN/vWgZv96QMkZ2ZKkDnUr6bH+jdS2TiUnVwcAAGA+wlUJEa6Awp1JStfbK/fr4/WHlZFlkyT1blxFD/drpCbVOWcAAED5QbgqIcIVUDQxcamasTxaX2w+qmybIYtFuq5VDT3Yp6HqVPZzdnkAAAAlRrgqIcIVcHn2n07Sqz/v1Y9/HpckuVstGta+lu7vHamqgd5Org4AAKD4CFclRLgCimf7sXhNW7JHq/aeliR5uVs1ukuE7upRXyF+nk6uDgAA4PIRrkqIcAWUzIYDZzRtyR5tOnxOkhTg5a47u9fT2Kvrys/L3cnVAQAAFB3hqoQIV0DJGYahFXtOadqSvdp1PEGSVNnPU3f3bKBbOtWWl7ubkysEAAC4NMJVCRGuAPPYbIZ++Ou4Xl26R4fOpEiSagb76P5rInXDVTXl7mZ1coUAAAAFI1yVEOEKMF9mtk1fbDqq6cv36mRCuiSpfpifHurbSAOaV2MgYgAA4JIIVyVEuAJKT1pmtj5ad0hvr9yvuJRMSVKLmkF6pF8jdYsMJWQBAACXQrgqIcIVUPoS0jI1e/UBzV5zUCkZ2ZKkTvUq6dH+jdWmdoiTqwMAAMhBuCohwhVw5cQmpevtFfs1b/1hZWTbJEnXNKmqh/s1VONqnH8AAMC5CFclRLgCrrxjcamavmyvvtx8VDZDslik61vV0H/6NFSdyn7OLg8AAFRQhKsSIlwBzrPvVJJe+3mvfvzruCTJ3WrRTe1r6b7ekaoa6O3k6gAAQEVDuCohwhXgfH8djde0pXu0eu9pSZK3h1WjukRoQo/6Cvb1dHJ1AACgoiBclRDhCnAd6w+c0Us/7daWv+MkSQHe7hrfvZ7GdK0rPy935xYHAADKPcJVCRGuANdiGIZ+2X1K05bs0e4TiZKkUH9P3dOzgYZ3rC0vdzcnVwgAAMorwlUJEa4A12SzGVr4Z4xe/XmvDp9JkSTVDPbRA9dE6oY24XKzMkYWAAAwF+GqhAhXgGvLzLbps9+PaMbyaJ1KTJckNajir4f7NlS/ZtUYiBgAAJiGcFVCxQlXmZmZys7OLuXKgPLNzc1NHh4eRV4+NSNbH607pLdX7ld8aqYkqWV4kB7p10hXNwglZAEAgBIjXJXQ5YSrhIQEnT4dq7S0tCtUHVC+eXt7Kyws9LKuGiekZeq91Qf0/pqDSsnI+ZKjc73KeqR/I7WpHVJapQIAgAqAcFVCRX0BExISdPToUXl4eMvPz19ubvRcBpREdnaWkpOTlJmZpvDw8Mu+LTc2KV1vrdinT9b/rYxsmySpT9OqerhvIzWqFlAaJQMAgHKOcFVCRX0B9+8/IJtNqly5CrcfASYxDENnzpySm5tUr169YrVx9FyKpi+L1ldbjspmSBaLNKR1Tf3nmoaqXdnX5IoBAEB5VtRsYL2CNZU7mZmZSktLk5+fP8EKMJHFYpGvr79SU9OUmZlZrDbCQ3w17d+ttPQ/3TWgeTUZhvTN1mPq/epKPfXtdp1K4DZeAABgLsJVCeR2XsGtgID53N1zzquSdhLToEqAZt7aVt/f01XdIkOVmW3o4/WH1X3aCr34027FpxQvvAEAAFyMcAWgQmgZHqyPx3bU/Ds76arawUrLtGnmyv26+qVf9NaKfUrJyHJ2iQAAoIwjXAGoUDrXr6yvJ3TReyPbqVHVACWmZWnakj3q/tJKfbj2kDKybM4uEQAAlFGEKwAVjsViUZ+mVbXo/m567aZWqlXJR7FJ6Zr8/Q71emWlvtx8VNk2+voBAACXh3CFMqdTpzaaMOHOErWxefMmderURu+9N8ukqlAWuVktGnpVuJY/GKXnhjRXlQAvHT2Xqoe/2Kb+r6/WT9tPiA5VAQBAUdETA4qlU6c2l7X8+vVbSqmS8mPIkEE6e/aMVq9e7+xSKhxPd6tu61RH/2oTrg/XHdLMlfsVfSpJd83brFa1gvVov0bq2iDU2WUCAAAXR7hCsYwdOy7PtM8++1RJSUn5zjPTggVfydvbu0RtNGvWTAsWfKXg4GBzikK54OPpprt61NfwDrX13uoDen/NQW07EqdbZm9Q1waV9Ui/xmpdK9jZZQIAABfFIMIFKMpAYWlpadq//4BCQ6vJ09OrVOuxWHKeEzEMQ656xIYMGaQTJ45zlaqYuHLlKCMjXbGxJ1S/fr0Sh+niOp2YrrdW7NMnGw4rMzvnxOvbtKoe7tdIDasGOKUmAABw5RV1EGGuXLk4q9Uii7ubvL08lJCaqUAfD6WlZ8rIypatDDxwHxMToxtuGKyBA6/VbbeN0qxZb2nr1i1KSIjX11//oBo1amjlyl+0fPnP2rVrh06fjpW7u7saNGigm266Rb169c7TZqdObXTVVW01c+Z79mnPPjtZixYt1NdfL9Svv67W119/oZiYY6pcubIGD75et99+p6zWfx4x3Lx5k+6+e5zGjh2nO++8yz59yJBBkqRPP/1Cs2a9pV9++Vnx8fGqXbuOxo4dp169rsl3H996a7p+/32DMjMz1bhxE40bN0GbNv2u999/V2+99a7atm1n5suq1NRUzZs3V8uW/azjx2Pk7e2t5s1batSo29WqVWuHZdPT0/Xll59r8eIfdPz4cWVnZyk4OETNmjXX6NFjFRnZUJJks9m0cOF3+u67r3X06BGlp6crMDBIDRs20ogRt5m+D2VBWICXplzXTGOvrqvXl0Xrm61HtXTnSf2866SGXlVT/7mmoWpV8pUkpWZkyc1qVWJapgK8PZRls8nXk39iAQCoSPif34VZrRZ5+Xhp5qp9mrP2kBJSsxTo464xXepqQo/6Sk9NLxMBS5KOHj2iO+4Yrfr1G2jQoGsVHx8vDw8PSdLMmW/K3d1dLVtepdDQUJ07d05r1qzSE088ogcffFTDht1c5O288cbr2rp1s7p27aaOHTtr9eoVmj37HWVmZmrChHuK1EZ2dpbuv3+iEhISFBXVW+npafr55yX6738f0+uvv6mOHTvblz116pTGjRut2NhYderURY0aNdLhw4d1330T1bZt+8t7kYooPT1dd989Xjt3blejRo11000jdPbsGS1b9rM2bFinZ5/9P/Xu3ce+/LPPPq3ly39WgwaRGjz4Wnl4eOrUqZPavHmTdu7cYQ9Xb7/9hubN+1Dh4eHq27e/fH39dPr0KW3b9od+/31DhQxXuWpV8tUrw1rprh719MrSvfppxwl9veWYFm6L0X29InVH93qateqA5qw96HCeToyqLy8PN2eXDwAArhCnhqu0tDQ98cQT2rRpk/bt26ezZ88qODhY9evX1x133KFbb73V/gG8MCtXrlTPnj0LnD9nzhyNHj3axMqLxjAMpWUWf8wcH7+cYDV9+T77tITULE1fHi1JGt25jlLT0ovdvreHVRaLpdjrX44///xDY8feqTvvnJBn3quvzlDNmuEO01JSUnTnnaP17rtv67rrrpe3t0+RtrNnz27Nm/eZQkPDJEm3336H/v3vIfrii890xx3ji/R+On36tJo0aaa3337Pvnzfvv11770TNH/+PIdw9fbbMxQbG6u77rpbo0ePtU9fuPBbTZ36bJFqvlzz5n2onTu3q1+/AZoy5X/2Yzhs2HDdcccovfDC/9SpUxf5+fkpKSlRv/yyTI0bN9H7738kN7d/PuhnZ2crJSXF/vv333+rsLAwzZv3WZ7XOz4+vlT2payJrBqgWbe11bYjcZq2ZI/W7ItV4+oBenvFPr3xS/7n6fge9biCBQBABeHU//GTkpI0c+ZMdejQQYMGDVJYWJjOnTunxYsX6/bbb9eCBQu0ePFih9u5CtOjRw9FRUXlmd66dWtzCy8CwzA05pOt2nYsoVjrV/Lz1JrHemrO2kP5zp+z9qDG96in3q9t0NnkjGJto3XNQH1wy1VXJGBVrhyq0aPvyHfexcFKknx9fTVo0HWaMeNV7dy5U23atC3Sdm6//Q57sJKk4OAQdesWpUWLFurw4UNq0CCySO088MBDDkGsffuOqlatunbu3GmflpGRoV9+WaaQkEoaMeI2h/UHD75e8+Z9pMOHDxVpe5dj0aIf5O7urrvvvs/h2DVq1FgDBw7Wd999o9WrV2jAgMH25/Q8Pb3ynEdubm4KCHB8bsjd3UNWa94rLUFBQabvR1nWqlaw5t3RURsPnFGL8GA99MW2fJebs/ag7u7Z4ApXBwAAnMWp4apSpUqKj4+Xp6enw/SsrCz16dNHS5cu1eLFizVo0KAitRcVFaUpU6aUQqXFU5LIEubvpTNJGUpIzcp3fkJqls4mZyjM36vY4epKioyMLPCq0dmzZ/XRR3O0bt1vOnHihNLT0xzmx8aeLvJ2GjVqkmdalSpVJElJSYlFaiMgIEA1atTMp52q2r79T/vvhw8fUkZGhtq1a5rnPWyxWNSiRUvTw1VycpKOHTuqiIi6qlKlap75bdu213fffaO9e/dqwADJz89fXbpcrbVr12jUqBHq1esatWnTTk2bNpW7u+Px6NOnr7766guNGPFv9enTT23btlPz5i2d1plEWdChXmWdSUov9Dw9lZimBz77Q9k2Q/VC/VUvzE/1Qv1UL8xfdSr7ypvbBgEAKDecGq6sVmueD6WS5O7urqFDh2rlypXat29fPmu6PovFog9uuarYtwVaLRZVCvRWoI97vh/cAn3cVSXAWx/ecpVsxew+8EreFlipUuV8p8fHx+v222/ViRMn1LJla7Vv31EBAQGyWq2Kjt6r1atXKiOj6OHRz88/z7TcW+Gys4t2LPJrI7cdm+2fNpKTkyVJISEh+S5f0D6XRO42C2q7cuVQh+Uk6f/+70XNnfuBli79SbNmvSUpZx8HD75WEybcY78F8D//eUQ1atTUDz98rzlzZmvOnNny8vJS7959dN99/1FwcP77WdEFeHsUep5W8vPUgdPJOpucoa1/xznMt1ikmsE+qhfmfz5w+dkDWLVAb1mtV+b8BAAA5nDJBwFsNpt++uknSVLz5s2LvF50dLRef/11paamKjw8XL169VLNmnmvQFwpFotFPp7F/1Y6LT1TY7rUtT+7caExXeoqLT1TXh5Fu2XS+fL/kLhw4bc6ceKExo2bqNtvd7xt8KOP5mj16pVXoLbi8fPzkySdO3cu3/lnz54ptW0W1Hbu9NzlJMnb20d33XW37rrrbsXEHNPmzb/rm2++0mefzVd6eroef/xJSTlfatxyy0jdcstInT59Wlu3btYPP3yvRYt+0JkzsZo+/W3T96c8yLbZCj1PbTZD88Z21IHYJB08nawDsck6cDpJB04nKzE9S0fPperouVSt3ut4hdbHw00R9sD1T/CqG+anQO9LPzsIAACuPJcIVxkZGfq///s/GYahM2fOaPny5dq9e7fGjBmj3r3zdsVdkE8//VSffvqp/Xd3d3fde++9mjZtmsOD/PlJT09Xevo/nUMkJBTvWSkzGVnZmtCjviTl6YVsQlR9pacUvzMLV3Hs2FFJUvfuPfLM++OPrVe6nMtSp06EPD09tXv3LmVkZDhchTUMQ3/99WchaxePn5+/atYM19GjR3Tq1Cn7LY+5tmzZJElq2LBhvuvXqFFTNWrUVJ8+/TVw4DX69dfVevzxvMuFhYWpb9/+uuaavho2bKh+/32j0tLSuEUwHz6e7poYlf95mttbYNMaHmpaw3FMDMMwFJuUoQOnk3Qw9oLQFZusv8+kKDUzW7uOJ2jX8bz/FoX6e+UJXfXC/FSrkq883MrKFy4AAJQ/LhOunnnmGfvvFotFDz/8sJ5//vkirR8WFqYXXnhBgwcPVkREhJKTk7Vu3To9/vjjeu2112SxWPTKK68U2sbzzz/vUIMrsNkMpaema2yXOrq7ZwP7+Dlp6ZlKTyk73bAXplq16pKkbdv+cOhsYsmSxVq7do2zyioST09P9ezZW0uWLNaCBZ9q5MjR9nmLFv1QKp1ZSNLAgYP13nuzNHPmG3r66Wftt3ZGR+/Vjz8ulL+/v7p3z+k989y5czp79ozq13fsVCExMVEZGRkKCgqWlHMO7t69Sy1btnJYLjU1VampqXJ3dy9yxzIVkZeHm8b3qOdwnmbZbIV2w26xWBQW4KWwAC91rOd4m2dmtk1HzqbkhK7TyToQm6T9p5N1MDZZpxPTFZuU87Px4FmH9dytFtWu5Kt6YX6qe/65rnqhfqob5qcwf68rdhswAAAVlUuEK39/fxmGIZvNppiYGC1cuFBPPPGE1q1bp0WLFhU6CrIkNWvWTM2aNbP/7ufnp+uvv14dO3ZUy5YtNWPGDD322GN5vuW/0KRJk/Tggw/af09ISFCtWrVKvnMlZLMZUkaWUjKz5G6xKCUpS8V8xMolDRgwSB9/PFevvvqStmzZpGrVqik6OlqbNm1UVFQvrVz5i7NLLNTEiffq99836u23Z2jr1s1q2LCR/v77sH777Vd16tRF69evvaznZrKysvTss5MLnP/008/o1ltH6bff1mjx4h916NBBtWvXQefOndWyZUuVnZ2tSZOest8WePr0KY0cOVyRkQ3VoEGkwsKqKD4+TqtXr1JWVpZuuSWnl8P09HSNGzdGtWvXUePGTVS1ajWlpqZozZpfdeZMrG655bZ8n4/EP3K7W6/s7yVJ8lTxw6iHmzUnGIX5q/dFfbQkpGXq4PmgdeB0kvbHJtt/T83MzrkCFpucp80AL3fH0JX791D/Et2+DAAA/uES4SqX1WpVeHi4JkyYoNDQUA0bNkxTp07Viy++WKz2qlWrpuuvv16zZ8/Whg0bdO211xa4rJeXl7y8vIpbeqkzjJzbiMqbKlWqaubM2Xrzzdf1++8blJWVrUaNGmv69Ld08uRJlw9XVatW0+zZc/XWWzO0YcM6bd26WY0bN9H06W9p+fJlkgruICM/NptNixYtLHD+008/Iy8vL7311jv6+OO5WrZsqRYs+ETe3t666qq2GjXqdrVufZV9+erVa+iOO8Zr8+bf9fvvGxQfH6/g4ODzgw8PV+fOXSVJPj7euvvu+7Rp00b98cdWnTt3VgEBgapTp44mTrxXffr0K+YrBLMFenuoVa1gtaoV7DDdZjN0IiHtn9CVG8Bik3T0XKoS07O07Wi8th3NO2ZZjSBv1b3g9sK6oX6qH+avGsE+cqNTDQAAisxiuOgn9twPgR06dNCGDRuK3c6kSZP0wgsvaP78+br55puLvF5CQoKCgoIUHx9f4JWztLQ07d9/QKGh1eTp6brBDM4xbtzt2r79Ty1btlq+vr7OLqfMychIV2zsCdWvX49nvUooLTNbf59NcQxd55/vikvJLHA9T3erIir7/tOFfJj/+eDlp2BfrmQCACqOomQDycWuXF0oJiZGkgocG6mocoNZRERESUsC8hUbe9ph4GJJWrz4R/355x/q2LETwQpO5+3hpoZVA9SwakCeeeeSM+zPdB04nayDsTk9GR4+k6KMLJv2nkzS3pNJedar5Od5/rZCx9BVu7KvvNy5zRAAUDE5NVzt3LlTEREReT58pqSk2J9/GjhwoH16bGysYmNjFRoaqtDQUPv0zZs3q23btnnanz59ulasWKHIyEi1b9++lPYCFd2IEcPUsGEj1a1bT25uVu3du1dbtmySr6+f7r33P84uDyhUiJ+n2vpVUts6lRymZ9sMHTuXqv3nw1Zu6DpwOlknEtJ0NjlDZ5MztPmw41AEVosUHuLr0HV8/fMBrGognWoAAMo3p4arzz//XK+++qquvvpqRUREKDAwUMeOHdPixYt15swZdevWTf/5zz8fTt98800988wzmjx5sqZMmWKffuONN8rDw0Pt2rVTeHi4kpOTtX79em3dulXBwcGaN2/eJbtiB4pr6NAbtWbNau3evVOpqWkKCQlW374DdPvtdygioq6zywOKxc1qUe3Kvqpd2Vc9GznOS07Psncff/B8b4Y5wStJyRk5tyD+fTZFK/c4jt3l6+lm71Aj90pXbgDz93LZGykAACgyp/5vNnjwYMXExGjt2rVat26dkpKSFBQUpJYtW+rmm2/W7bffLnf3S5c4YcIELVmyRKtXr9aZM2dktVpVp04dPfDAA3rooYcUHh5+BfYGFdWECfdowoR7nF0GcMX4ebmrec0gNa8Z5DDdMAydTkzP81zXgdNJOnIuVSkZ2doRk6AdMXnH7qoS4GV/ruvC8bvCQ3zkzthdAIAywmU7tHA2OrQAnIsOLcqXjCybvVONC8fvOhibrNikjALX83DLHbvrgtB1/spXZT9PbjMEAFwRZb5DCwBA+eHpblWDKv5qUCXv0ATxKZn2oHXggtsMD8YmKz3Lpv2nk7X/dN6xuwK93fMNXXVD/eRdyADOAACUFsIVAMCpgnw9dFXtEF1VO8Rhus1mKCY+9Z/QZb/NMFkx8alKSMvSH0fi9MeROIf1LBapRpDP+VsL/wld9cL8VCPI57IG9gYA4HIQrgAALslqtSg8xFfhIb7qFuk43EFaZrYOnbkgdJ1Otj/flZCWpWNxqToWl6pfo2Md1vNyt9qD1oWDJtcL81eQT8mG/gAAgHAFAChzvD3c1LhaoBpXc7zv3TAMnUnO+KdDjQtC199nU5SeZdPuE4nafSIxT5uh/rljdzmGrtqVfOXpTqcaAIBLI1wBAMoNi8WiUH8vhfp7qX2E49hdWdk2HT2X+k/X8RcEsFOJ6YpNylBsUoZ+P+Q4dpeb1aJaIT7257vqnr/qVT/MT2EBjN0FAPgH4QoAUCG4u1kVEeqniFA/9WrsOC8pPctxzK7zwetgbLJSMrJ16EyKDp1J0S8Xtenv5W6/zTD3Sle9851q+DF2FwBUOPzLDwCo8Py93NUiPEgtwvOO3XUyIV0HTidp/0WDJh89l6Kk9Cz9dSxefx2Lz9NmtUDv870Y+qnu+VsN64f6q2aIj9zoVAMAyiXCFQAABbBYLKoW5K1qQd7q0iDUYV56Vrb+PpOSZ9Dkg7HJOpucoRMJaTqRkKa1+884rOfpZlWdyr6Ooev83yv5eV7J3QMAmIxwBZf1ww/f63//m6Inn5yiwYOvs08fMmSQJOnbb38sUTtmeu+9WXr//Xf11lvvqm3bdqWyDQCuxcvdTZFVAxRZNSDPvLiUDMfQdf7vB88kKyPLpuhTSYo+lSTppMN6wb4e528rdAxddSr7MnYXAJQBhCsUy9NPP6GlS3/Ss8/+n/r27V/gcsnJSRo4sK88PNz1ww9L5e3tfQWrNM/mzZt0993jNHbsON15513OLueScsPec889rz59+jm7HKDCCfb1VNs6nmpbx3HsrmyboZi4VIfONA7EJung6WTFxKcpLiVTW/6O05a/4xzWs1ik8BCfnNAVmhO6csfvqhbozdhdAOAiCFdlhMWSc3uKYRgyDGdXI1177fVauvQnLVz4XaHhaunSn5SenqaBA/9lWrB6881ZprRjpn//+yb16dNP1apVc3YpAFyYm9WiWpV8VauSr3o0dBy7KyUjK+fq1gWDJuf+PTE9S0fOpurI2VSt3nvaYT0fDzfVPd+LYf2LBk0O8GbsLgC4kghXLs5qtcjXI1vunl5SWrzkHaSsjHSlZLrJZnNeymrXroNq1KipzZt/14kTx1WtWvV8l1u48HtJ0nXXDTFt2+HhtUxryyzBwSEKDg659IIAUABfT3c1qxGkZjXydqpxOin9fGcajqHr77MpSs3M1s7jCdp5PCFPm2EBXqqbe6Ur9J/QVauSrzzcGLsLAMxGuHJhVqtFgb5Wac3rsmx4R0qLk7yD5d5xvAKvflAJKTanBSyLxaLBg6/Tu+/O1A8/fK877hifZ5kDB/Zr587tatAgUk2aNFVSUqK+/vorrVu3RkeO/K24uDgFBwerffuOGjt2XJFDU0HPXMXHx2vWrDe1cuUKpaSkqF69eho16vYC21m48FutXr1K0dF7dfbsGXl7e6tJk6YaOXKM2rZtb18u9xY7SXr//Xftf5ekr7/+QTVq1Cj0matff12l+fM/0Z49u5WVlalatWpr4MBrNWzYzXJ3/+cUjImJ0Q03DNbAgddqzJixevPN6dqyZZMyMzPVvHlL3X//g4qMbFik1+hyFbVGSdq8+Xd9/PGH2rdvr+Lj4+XvH6DatWtrwIBBGjLkRvtyu3fv0ocffqCdO3fo7Nkz8vPzU/XqNdS9e5TGjLmjVPYDKI8sFouqBHirSoC3Otar7DAvM9umI2dT/rm9MDZZ+0/nBK/YpHSdTsz52XjwrMN67laLalfyPd+b4fnQdf6qV6i/J2N3AUAxEa5Kk2FIWanFXt3X10Na87Ysq178Z2JanCyrXpQhybf9RCWlZxa/PnefnPsNi2nQoGs1e/Y7+vHHhRo7dlye/4x/+CHnqtW11w6RJB06dFDvvTdTbdu2U48ePeXt7aPDhw9p6dKf9Ntva/Thh5+oevUaxaolLS1VEyfeqf3796lFi5a66qq2OnnyhJ588nF17Ngp33VefvlFNWgQqfbtOyokJESnT5/SqlUrde+9E/TCCy+re/coSVKbNu10/PhxLVq0UFdd1VZt2rS1txEQkPdB9gt9+uk8zZjxqgIDg9S3b3/5+Pjo119XacaMV7Vt21a98MLLeV6348djdMcdo1WvXj0NHny9jh07qtWrV+ruu8dp/vyvVLly5QK2VjyXU+Nvv/2qhx9+QAEBAerWrYdCQ0N17lyc9u3bq8WLf7SHq71792jcuDGyWq3q3j1K1apVV2Jiog4dOqDvvvuacAWYxMPNmjO2Vpi/pKoO8xLSMu1dxx88naz95692HYxNUlqmLecqWGyytOuUw3oB3u72oJV7pSv3qpePJ51qAEBhCFelxTAU8MX1cj++qXjr+1aWHvhL2vBOvrMtG96RR9f7FfJ2GynlTL7LXEpW9fZK/Pe3xQ5YVatWU4cOnbR+/Vpt2rRR7dt3/KftrCz99NMieXp6qn//gZKkiIi6+uGHpQoKcrzlZfPm33XvvRM0Z877euKJp4pVy8cff6j9+/fp+uuHatKkf9oYMGCQHnjgnnzXmT//S9WoUdNhWmzsaY0Zc6veeON1e7jKvRK1aNFCtWnTtsgdWhw9ekRvvTVDISGVNHfuPFWtmvM81l133a17771Lq1at0E8//agBAwY7rLd162ZNnHifRo4cbZ/2zjtva86c2frxx+81cuSYIm2/NGpcuPA7GYaht956N89VtPj4OPvfFy/+URkZGXrppVftr2N+ywEoPYHeHmpVK1itagU7TLfZDJ1ISLNf7bpw0ORjcalKTMvStqPx2nY079hdNYK8z4c5x0GTawQzdhcASISrUlaC/2j8q0rJsTm3AuYnLU5Kic1ZrpjhygzXXTdE69ev1cKF3zuEq99++1Vnz55R79597GHK3z//qzxt27ZX3br19PvvG4pdx+LFP8rDw0Pjxk1wmN6pUxe1a9dBmzZtzLPOxcFKkkJDwxQV1VtffLFAx4/HFPtKmpTTmUd2dpZGjLjVHlokydPTU3fffb/GjRujH39cmCdc1ahRU7feOtJh2rXXDtGcObO1c+eOYtdjZo1eXl552goKCs4zrajLAbhyrFaLagT7qEawj66OdBy7Ky0zW4fPpNjH7LowgMWnZiomPk0x8Wlasy/WYT1Pd6vqVvZzDF1hObcaBvsydheAioNwVVoslpyrQsW8LdBisSgoIFAW7+D8A5Z3sAz/6or/90IZxe0+sIS3BUpS9+49FBISolWrVigpKdEeoBYu/E5S3o4sNm/epM8++1Q7dmxXXFycsrOz7PM8PIrXq1VycpJiYo6pbt16qlw5NM/81q2vyjdcHTt2VB9+OEebN/+u06dPKSMjw2F+bOzpEoWrPXt2S8q5rfBiLVq0lJeXl/bu3ZtnXmRkQ1mtjg+aV6lSRZKUlJRY7HrMqLFPn35aufIX3XHHKPXt21/t2nVQ69ZX5enMo3fvPvrss0/12GMP6Zpr+qpDh05q3bqNfT8AuCZvDzc1qhagRtXyfhl2NjnDMXSd//vh82N37TmZqD0n8/4bVcnP8/zYXY6hq3ZlX3m5c5shgPKFcFWaLBbJw7dYqxqSsjLS5d5xvOMzV7nzO45XVka6DHefEhZZMu7uHurff5Dmz5+nJUt+0o03/ltnzsRq3bq1qlatmsPVrOXLf9aTTz4uHx9fderUWdWrVz/fPbtFP/64UCdOHC9WDcnJyZKkkJBK+c6vVCnvM0pHjvytsWNHKjk5WW3atNPVV3eTn5+/LBaLtmzZrK1bNysjowTPs11QV6VKeeuyWCwKCamk06dP55nn5+efZ1pupxLZ2bYS1VTSGnv37iMPDw/Nnz9P33zzlb788nNZLBa1bdtO9933oBo2bCRJat68hd5++13NnfuBli79yf78XdOmzXT33fc5dBgCoGyo5OepSn6V1C7C8d+LrGybjsWlOtxemDto8omENJ1NztDZ5AxtOnzOYT2rRapVyfd8Zxr/hK56Yf6qGuhFpxpABZaakSU3q1WJaZkK8PZQls0mX8+yEVvKRpUVVEqmmwKvflCG5NBboNFxvHT1g0pJsSknhjnXddcN0fz587Rw4be68cZ/a/HiH5WdnaVBg65zuAIze/Y78vT00ty5n6h27doObSxbtrTY2/fz85MknTt3Nt/5Z8/mvW1ywYJPlJCQoMmTn9OAAYMc5r344lRt3bq52PVcXNfZs2fzXAEzDEPnzp21L+Msxamxe/code8epeTkZP355x9aufIXLVz4nR544B599tnX9k4+Wrduo9dfb6O0tDTt2LFda9as1tdff6EHH7xfn376uWrWDL8yOwmgVLm7WVWnsp/qVPZTz4vmJafnjN11ceg6cDpJyRk5tyAePpOilXscv2jy83RT3TA/+6DJ9k41wvzk78VHF6A8S8/M1qxVBzRn7UElpGYp0MddY7rU1cSo+vLycP2r3fwL5cJsNkMJKTb5drxX7t0e/mecq/R0pTixG/aL1a1bT82bt9D27X8pOnqvfvjhe3tX7Rc6duyo6tatlydYxcae1rFjR4u9fT8/f9WoUVNHjx7RmTOxeW4N/OOPrXnWyd3exZ0tGIahP//clmd5t/PjwdhsRb9y1KhRY61atUJbtmxSs2bNHebt2PGX0tPT1aJFyyK3VxpKUqOfn586d+6qzp27ymazaeHC77Rjx1/q1KmLw3Le3t5q27ad2rZtp4CAAL377kxt3LheQ4f+q9T2C4Br8PNyV/OaQWpeM+/YXacS0x2e6coNXUfOpSo5I1vbjyVo+7G8Y3dVDfRy6EwjN3iFh/jI/RJjd5Xlb8OBiiA1I0uzVh3Q9OXR9mkJqVn238f3qOfy56xrVwfZbIaS0q2yZGTKYvGTkZQpw7DKFa5YXejaa4do+/a/NG3aCzp06KA6dOiU50pItWrVdfToUZ05c8benXh6erpeeul5ZWVl5ddskQ0YMFDvv/+e3n13pkNvgRs2rMv3eavcQY+3bftDXbp0tU//6KM52r9/X57lAwNzPhicPHmyyDX17dtf77//nubP/0T9+w9SWFiYJCkzM1NvvTVDUk539s50uTVu3bpZLVu2lpub4zdHZ8/mXDX09MzpwOKvv7apYcPGeTq0yL2KmLscgIrJYrGoaqC3qgZ6q3N9x1u3M7Js+vvsP51qHLwggJ1JztDJhHSdTEjX+gOOdyt4uOWO3eV4i2G9UD9V8vNURpatTH8bjpxQbhiSzTBk6PyfhgqY9s+yNkMy5LjshesaOr+M8c+fF7Z1qe04rJvfdhxqv6jG/LYjQzab7PN00X7Ychp0aMt2/vl720XbkXI+S+a2deG6/+x3bv3/rPvPflywHeXzuhZpP/LZjvTPa31+HX8vd02/+SrNWXsw3+M/Z+1B3d2zQWm+xUxBuCojct+Qruqaa/rq9ddf1p9//iFJuvba6/Ms8+9/36RXXnlJo0YNV8+e1yg7O1sbN66XZCgysqGio/N27lBUt946WitXrtB3332jAwcO6Kqr2ujkyRNavvxnde16tX77bY3D8kOH/ks//PC9Jk16xN6j4fbtf2nv3t35Ll+nToTCwsK0bNkSeXp6qEqVqpIsGjbspgJ7QQwPr6W7775PM2a8qltvvUm9e/eRj4+31qz5VYcPH1L37lHq339Qvuua5euvv9C6dWvznXfddUPUuvVVl1Xjq69OU2zsabVs2VrVq9eQxWLRtm1/aOfO7WrevIVatWotKadr/M2bN6l166tUo0ZNeXp6as+e3dq0aaNq1gxXVNTFNw8BQA5Pd6saVPFXgyp5nz+NT8m8oPv4pPNXu3KueqVn2bT/dM4gyhf7YFQ7bT0Spzd++efLs9xvww0ZurFNuLb+HVeqH2odPoi72Idao7Dt5LvtC7ZzcVsO+1uU/chtq4D9uKANlG+NqgYoNildCan5f+GekJqlxLRMVfZ37S9oCVcwhZ+fn3r37qMffvhegYFB6tEj74fnf/3rJrm7u+uLLz7T999/I3//AHXpcrUmTrxXTzzxaIm27+Pjo7fffk8zZ76hVatWaO/e3apbt57+978XlJSUlCcsNWrUWNOnv6133nlbK1f+Ijc3q1q0aKV33vlAv/66Ks/ybm5uev75l/XWWzO0dOkSpaTk/Ofdv//AAsOVJI0YcavCw2tp/vx5+umnRcrKylStWrV1330Patiwm0v9ge2tW7do69Yt+c5r06atWre+6rJqHDlyjFau/EV79uzShg3r5O7ururVa+juu+/TjTcOs1/RuuGGf8nf3187dmw/v31DVatW06hRt2v48Fvy7bQDAC4lyNdDV9UO0VW1HXsotdkMxcSn2nsx/Oc5r2SlZmarU/3KeuDzP/Jtc+7aQ7qrR309+8NOnU3OyHcZlH0Wi2S1WGS1SBZZZLH8M82i839acq6qWi/688L51vP/J1qtjusq3/Zz28hdP3f5wtt3WDe/2mSR1Zp3O7n1WOxtOa6b73aUT43n182dp4vat54f08560f7povYvXDe3rQtfK8sFr6Mkebu7qUqglwJ93PMNWIE+7grwLl7P0leSxXDlyyFOlJCQoKCgIMXHxyswMDDfZdLS0rR//wGFhlbjNifAZBkZ6YqNPaH69eud71USAC5fWma2EtOy1H7qsgKXWft4L81YvlfH4tIkXfih8fwHxAs+GFry+4CY77ScD8C6+MOrctu94EPshR94lf8H4tw2LBd9eM3zQV45H37zfpguygd5x+1c+AH40h/kL6rRXvc/QebCUFD4fl9Uoy6o8cL9tua/ruWi40XPk2VHfs9c5bq/d6RTn7kqSjaQuHIFAADKMW8PN1ktlkK/DQ/199ILN7ZyQnUALuTj6a6JUfUlqcw+H0m4AgAA5Vq2zaYxXerm+234mC51lWWzyVOF9zQI4Mrw8nDT+B71dHfPBg49e5aFYCURrgAAQDlXHr4NByqS3Fv/cjuvKEtffhCuAABAuVfWvw0HUDYQrgAAQIVQlr8NB1A28K8KAAAAAJiAcAUAAAAAJiBclUDugKnZ2fmPJA2g+LKycs6r3PMMAADA1RGuSsDDw0Pe3t5KTk4SYzED5jEMQykpSfLx8ZaHh+uPxg4AACDRoUWJhYWF6ujRozpz5pR8ff3l7s5LCpREVlaWUlKSlJmZpqpVw51dDgAAQJGRBEooMDBQ4eHhio2NVVxcrLPLAcoFHx9vVa0arsDAQGeXAgAAUGSEKxMEBgYqMDBQmZmZys7OdnY5QJnm5ubGrYAAAKBMIlyZyMPDgw+FAAAAQAVFhxYAAAAAYALCFQAAAACYgHAFAAAAACYgXAEAAACACQhXAAAAAGACwhUAAAAAmICu2AtgGIYkKSEhwcmVAAAAAHCm3EyQmxEKQrgqQGJioiSpVq1aTq4EAAAAgCtITExUUFBQgfMtxqXiVwVls9kUExOjgIAAWSwWp9aSkJCgWrVq6ciRIwoMDHRqLTAHx7R84riWPxzT8odjWj5xXMsfVzumhmEoMTFRNWrUkNVa8JNVXLkqgNVqVXh4uLPLcBAYGOgSby6Yh2NaPnFcyx+OafnDMS2fOK7ljysd08KuWOWiQwsAAAAAMAHhCgAAAABMQLgqA7y8vDR58mR5eXk5uxSYhGNaPnFcyx+OafnDMS2fOK7lT1k9pnRoAQAAAAAm4MoVAAAAAJiAcAUAAAAAJiBcAQAAAIAJCFcAAAAAYALC1RU2b948jR8/Xu3atZOXl5csFovmzp172e3YbDa98cYbatGihXx8fBQWFqbhw4frwIED5heNSzLjuK5cuVIWi6XAn+K8T1B8x44d0+uvv66+ffuqdu3a8vT0VLVq1XTjjTdqw4YNl9UW56trMOuYcq66lrS0ND344IPq3r27atSoIW9vb1WrVk1du3bVnDlzlJmZWeS2OFddg1nHlHPV9b344ov247F+/foir+fK5yq9BV5hEREROnz4sEJDQ+Xn56fDhw9rzpw5Gj169GW1c+edd2r27Nlq1qyZBg0apJiYGH3++efy9/fX+vXrFRkZWTo7gHyZcVxXrlypnj17qkePHoqKisozf8iQIWrdurVpNaNwjz/+uF588UXVr19fUVFRCgsLU3R0tL799lsZhqFPP/1UN910U5Ha4nx1DWYdU85V1xIbG6tatWqpQ4cOatiwocLCwnTu3DktXrxYhw8fVt++fbV48WJZrZf+Pplz1TWYdUw5V13b9u3b1a5dO7m7uys5OVnr1q1Tp06dirSuS5+rBq6on3/+2Th06JBhGIbx/PPPG5KMOXPmXFYbv/zyiyHJ6N69u5Genm6fvmjRIkOS0bdvXzNLRhGYcVxXrFhhSDImT55sfoG4bF999ZWxcuXKPNNXr15teHh4GCEhIUZaWtol2+F8dR1mHVPOVdeSnZ3tcG7lyszMNKKiogxJxg8//HDJdjhXXYdZx5Rz1XVlZGQYbdq0MTp27GjceuuthiRj3bp1RVrX1c9Vbgu8wq655hrVqVOnRG289957kqTnnntOnp6e9ukDBgxQVFSUli5dqr///rtE28DlMeO4wrXccMMN6tGjR57p3bp1U8+ePXXu3Dn99ddfl2yH89V1mHVM4VqsVqvDuZXL3d1dQ4cOlSTt27fvku1wrroOs44pXNfUqVO1Y8cOffDBB3Jzc7usdV39XCVclUErV66Un5+funbtmmdev379JEmrVq260mXBJNHR0Xr99df1/PPP6+OPP9axY8ecXRIu4uHhISnnP/pL4XwtGy7nmObiXHVtNptNP/30kySpefPml1yec9X1Xe4xzcW56lq2bNmiqVOnavLkyWratOllr+/q52rR/xeBS0hOTtbx48fVvHnzfJN+7j2m0dHRV7o0mOTTTz/Vp59+av/d3d1d9957r6ZNm3bZ3+7AfH///beWLVum6tWrq0WLFoUuy/laNlzOMb0Q56prycjI0P/93//JMAydOXNGy5cv1+7duzVmzBj17t270HU5V11TSY7phThXXUd6erpGjhyp1q1b69FHH73s9cvCuUq4KmPi4+MlSUFBQfnODwwMdFgOZUdYWJheeOEFDR48WBEREfaHOx9//HG99tprslgseuWVV5xdZoWWmZmp2267Tenp6XrxxRcv+Z8y56vru9xjKnGuuqqMjAw988wz9t8tFosefvhhPf/885dcl3PVNZXkmEqcq67o6aefVnR0tDZv3lysYFsWzlVuCwRcRLNmzfTYY4+pWbNm8vPzU5UqVXT99ddrxYoVCgsL04wZM3Tq1Clnl1lh2Ww2jR49WqtXr9add96p2267zdkloYSKe0w5V12Tv7+/DMNQdna2jhw5orfeekuzZ89WVFSUEhISnF0eiqGkx5Rz1bWsW7dOL7/8sp588snLuq2zrCFclTG5Sb2gRJ77j01BiR5lT7Vq1XT99dcrKyvrssdXgjlsNptuv/12ffrpp7r11ls1a9asIq3H+eq6intMC8O56hqsVqvCw8M1YcIEvfvuu/rtt980derUQtfhXHVtxTmmheFcvfKysrI0atQotWzZUo8//nix2ykL5yq3BZYxfn5+ql69ug4ePKjs7Ow8l1Rz7zFlLI7yJTQ0VFLOvca4smw2m8aMGaOPPvpIw4cP19y5c4s0Xo7E+eqqSnJML4Vz1bX07dtXUs4D8IXhXC07inpML4Vz9cpKSkqyn0f59QQpSZ07d5YkffPNNxoyZEi+y5SFc5UrV2VQjx49lJycrN9++y3PvCVLlkiSunfvfqXLQinK/WYtIiLCuYVUMBd+CL/pppv08ccfX/Y94pyvrsWMY1oYzlXXEhMTI+mf3iALw7laNlzOMS0M5+qV5eXlpbFjx+b7kxuErrvuOo0dO/aSx8Tlz1WnjrJVwV1qsNnTp08bu3btMk6fPu0w3dUHT6vointcN23alO/yr7/+uiHJiIyMNLKysswuFwXIzs42Ro0aZUgy/v3vfxuZmZmFLs/56vrMOqacq65lx44dRnJycp7pycnJRv/+/Q1JxtSpU+3TOVddn1nHlHO1bMj9d/niQYTL6rlqMQzDuNKBriKbPXu21qxZI0n666+/tGXLFnXt2lUNGjSQJF199dW64447JElTpkzRM888o8mTJ2vKlCkO7dx5552aPXu2mjVrpkGDBun48eP67LPP5O/vr3Xr1qlhw4ZXdL8qOjOOa0REhDw8PNSuXTuFh4crOTlZ69ev19atWxUcHKwlS5aoQ4cOV3zfKqrc4+Tv76/7778/3/GPhgwZotatWzssz/nqusw6ppyrrmXKlCl69dVXdfXVVysiIkKBgYE6duyYFi9erDNnzqhbt25asmSJfHx87Mtzrro2s44p52rZMHr0aH344Ydat26dOnXqZJ9eVs9Vnrm6wtasWaMPP/zQYdpvv/3mcGkz90N4Yd555x21aNFC7777rqZPny5/f38NHTpUU6dOVf369U2vG4Uz47hOmDBBS5Ys0erVq3XmzBlZrVbVqVNHDzzwgB566CGFh4eXSu3I36FDhyTl3Cde0IPTERER9g/iheF8dQ1mHVPOVdcyePBgxcTEaO3atVq3bp2SkpIUFBSkli1b6uabb9btt99e5MGhOVddg1nHlHO1/HLlc5UrVwAAAABgAjq0AAAAAAATEK4AAAAAwASEKwAAAAAwAeEKAAAAAExAuAIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAMJnFYtG3337r7DIAAFcY4QoAUK6MHj1aFoslz0///v2dXRoAoJxzd3YBAACYrX///pozZ47DNC8vLydVAwCoKLhyBQAod7y8vFStWjWHn5CQEEk5t+zNnDlTAwYMkI+Pj+rVq6cvv/zSYf2//vpLvXr1ko+PjypXrqxx48YpKSnJYZkPPvhAzZo1k5eXl6pXr6577rnHYX5sbKyGDh0qX19fRUZG6vvvvy/dnQYAOB3hCgBQ4Tz11FO68cYbtW3bNt1yyy26+eabtWvXLklScnKy+vXrp5CQEP3+++/64osvtGzZMofwNHPmTN19990aN26c/vrrL33//fdq0KCBwzaeeeYZDRs2TH/++acGDhyoW265RWfPnr2i+wkAuLIshmEYzi4CAACzjB49WvPmzZO3t7fD9CeeeEJPPPGELBaL7rrrLs2cOdM+r1OnTmrTpo3efvttvffee3rsscd05MgR+fn5SZIWLVqka6+9VjExMapatapq1qypMWPG6H//+1++NVgsFj355JN67rnnJOUENn9/fy1evJhnvwCgHOOZKwBAudOzZ0+H8CRJlSpVsv+9c+fODvM6d+6sP/74Q5K0a9cutWrVyh6sJKlr166y2Wzas2ePLBaLYmJi1Lt370JraNmypf3vfn5+CgwM1KlTp4q7SwCAMoBwBQAod/z8/PLcpmcWHx+fIi3n4eHh8LvFYpHNZiuNkgAALoJnrgAAFc769evz/N6kSRNJUpMmTbRt2zYlJyfb5//222+yWq1q1KiRAgICFBERoeXLl1/RmgEAro8rVwCAcic9PV0nTpxwmObu7q7Q0FBJ0hdffKF27drp6quv1ieffKKNGzfq/ffflyTdcsstmjx5skaNGqUpU6bo9OnTuvfee3XbbbepatWqkqQpU6borrvuUpUqVTRgwAAlJibqt99+07333ntldxQA4FIIVwCAcuenn35S9erVHaY1atRIu3fvlpTTk9+CBQs0ceJEVa9eXfPnz1fTpk0lSb6+vlqyZInuv/9+tW/fXr6+vrrxxhv16quv2tsaNWqU0tLS9Nprr+nhhx9WaGio/vWvf125HQQAuCR6CwQAVCgWi0XffPONhgwZ4uxSAADlDM9cAQAAAIAJCFcAAAAAYAKeuQIAVCjcDQ8AKC1cuQIAAAAAExCuAAAAAMAEhCsAAAAAMAHhCgAAAABMQLgCAAAAABMQrgAAAADABIQrAAAAADAB4QoAAAAATPD/UhkyTMomH/kAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["test_data = MyDataset(test_path, MAX_SEQ_LEN,'test') \n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n"],"metadata":{"id":"ngvdJlOC82ay","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a737a1fb-3d4d-4aa0-bc08-df844be7e498","executionInfo":{"status":"ok","timestamp":1680248084142,"user_tz":420,"elapsed":14806,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," test  dataset preview .....\n","*******************************************\n","Input :: toxic        :: so maybe you should be more retarded\n","Input :: masked toxic :: so maybe you should be more <mask>\n","Input :: non toxic    :: so maybe you should be more backward\n","encoded length toxic : {'input_ids': [0, 2527, 2085, 47, 197, 28, 55, 47304, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length masked toxic:  {'input_ids': [0, 2527, 2085, 47, 197, 28, 55, 50264, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","encoded length non toxic:  {'input_ids': [0, 2527, 2085, 47, 197, 28, 55, 18173, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","*******************************************\n","total number of test  data processed :  199\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import SmoothingFunction\n","import evaluate\n","\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load('bleu')\n","\n","\n","# Define a smoothing function for Rouge-L\n","smoothie = SmoothingFunction().method4\n","\n","def model_evaluate(model, data_loader):\n","    model.eval()\n","    total_loss = 0\n","    total_accuracy = 0\n","    total_precision = 0\n","    total_recall = 0\n","    total_f1 = 0\n","    # Calculate the evaluation metrics\n","    total_correct = 0\n","    total_predicted = 0\n","    total_gold = 0\n","    total_batches = 0\n","\n","    total_rouge1 = 0\n","    total_rouge2 = 0\n","    total_rougel = 0\n","    total_rougelsum = 0\n","    total_gen_len = 0\n","\n","    golden_texts=[]\n","    predicted_generated_text=[]\n","    bleu_scores = []\n","    rouge = Rouge()\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader):\n","            toxic_src = batch['toxic_ids'].cuda()\n","            non_toxic_tgt = batch['non_toxic_ids'].cuda()\n","            masked_toxic_src= batch['masked_toxic_ids'].cuda()\n","            \n","            generated_ids = model.decoder.generate(\n","                input_ids=masked_toxic_src.cuda(),\n","                max_length=get_max_length(masked_toxic_src.cuda()),\n","                num_beams=10,\n","                early_stopping=True,\n","                top_k=50, \n","                length_penalty=1,\n","                repetition_penalty=1.8,\n","                no_repeat_ngram_size=1,\n","                top_p = 0.95,\n","                temperature=0.1,\n","                decoder_start_token_id=bart_config.decoder_start_token_id\n","            )\n","\n","            predicted_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","            predicted_generated_text.extend(predicted_text)\n","\n","            gold_text = tokenizer.batch_decode(non_toxic_tgt[:, 1:], skip_special_tokens=True)\n","            golden_texts.extend(gold_text)\n","\n","            #calculating cross entropy loss\n","            outputs=bart_model(input_ids=toxic_src, masked_input_ids=masked_toxic_src)\n","            loss = loss_fn(outputs, non_toxic_tgt.cuda())\n","            \n","            total_loss += loss.item()\n","            \n","            # print('per batch analysis',len(predicted_generated_text),len(golden_texts))\n","            for i, (predicted_sent, gold_sent) in enumerate(zip(predicted_generated_text, golden_texts)):\n","                # Calculate the number of correct tokens\n","                \n","                correct_tokens = sum([1 for p, g in zip(predicted_sent, gold_sent) if p == g])\n","                total_correct += correct_tokens\n","                \n","                # Calculate the number of predicted and gold tokens\n","                predicted_tokens = len(predicted_sent)\n","                total_predicted += predicted_tokens\n","                \n","                gold_tokens = len(gold_sent.split())\n","                total_gold += gold_tokens\n","               \n","            # Calculate average generated length\n","            total_gen_len += sum([len(sent.split()) for sent in predicted_text])\n","            total_batches += 1*len(predicted_text)\n","\n","\n","    print('number of records in test',total_batches)     \n","\n","    # Calculate average metrics for the entire dataset\n","    avg_loss = total_loss / total_batches\n","    avg_accuracy = total_correct / total_predicted if total_predicted > 0 else 0\n","    avg_precision = total_correct / total_predicted if total_predicted > 0 else 0\n","    avg_recall = total_correct / total_gold if total_gold > 0 else 0\n","    avg_f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if avg_precision + avg_recall > 0 else 0\n","\n","    print(\"Loss: {:.4f}\".format(avg_loss))\n","    print(\"Accuracy: {:.4f}\".format(avg_accuracy))\n","    print(\"Precision: {:.4f}\".format(avg_precision))\n","    print(\"Recall: {:.4f}\".format(avg_recall))\n","    print(\"F1 Score: {:.4f}\".format(avg_f1))\n","\n","    return predicted_generated_text,golden_texts\n","\n","predicted_generated_text,golden_texts=model_evaluate(bart_model, test_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1OhZ3518pDx","outputId":"be19bab7-a5c6-4fa9-85d6-e404f556bc08","executionInfo":{"status":"ok","timestamp":1680248139378,"user_tz":420,"elapsed":31375,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.27s/it]"]},{"output_type":"stream","name":"stdout","text":["number of records in test 208\n","Loss: 0.3844\n","Accuracy: 0.2284\n","Precision: 0.2284\n","Recall: 1.9190\n","F1 Score: 0.4082\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["rouge.compute(predictions=predicted_generated_text,references=golden_texts)"],"metadata":{"id":"X15MsWAyE66A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7fb29de7-3d3a-41de-a3c4-4825d68e344f","executionInfo":{"status":"ok","timestamp":1680248145954,"user_tz":420,"elapsed":255,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rouge1': 0.47148343839932005,\n"," 'rouge2': 0.35644777602667,\n"," 'rougeL': 0.45849824067840883,\n"," 'rougeLsum': 0.45955642351319326}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["print(bleu.compute(predictions=predicted_generated_text,references=golden_texts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g0oQhefLxoQ","outputId":"ff3ffd2f-3d60-4998-9571-117a668b2e3a","executionInfo":{"status":"ok","timestamp":1680248150478,"user_tz":420,"elapsed":3,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bleu': 0.2744019267561383, 'precisions': [0.39691100759990194, 0.30147248772926893, 0.24324324324324326, 0.19479015918958031], 'brevity_penalty': 1.0, 'length_ratio': 1.7529007305543618, 'translation_length': 4079, 'reference_length': 2327}\n"]}]},{"cell_type":"code","source":["# import gc\n","# gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3EN3hR0oh0K","outputId":"2ce3016a-5962-49db-dba3-93489e98691d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3132"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["df_test=pd.read_csv(test_path,sep=\",\", header=None) \n","\n","for i in range(len(predicted_generated_text[:5])):\n","  print(' Original text   :: ',df_test[1][i])\n","  print(' Gold text       :: ',df_test[2][i])\n","  print(' Translated text :: ',predicted_generated_text[i])\n","\n","# Create a new DataFrame with the generated texts\n","df_gen = pd.DataFrame({'bart_tuning_output': predicted_generated_text}) \n","\n","# Add the generated_text column to the df_test dataframe\n","df_bart_output = pd.concat([df_test, df_gen], axis=1)\n","\n","# Save the updated dataframe as a CSV file\n","df_bart_output=df_bart_output.drop([0],axis=1)\n","df_bart_output=df_bart_output[:-1]\n","df_bart_output.to_csv('/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output2.csv',sep='\\t',index=False,header=['toxic_text','gold_text','bart_tuning_output'])"],"metadata":{"id":"kM6-ak9I7vBM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7ae573a-11c4-420c-ce14-a76dca1766d2","executionInfo":{"status":"ok","timestamp":1680248169911,"user_tz":420,"elapsed":604,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original text   ::  so maybe you should be more retarded\n"," Gold text       ::  so maybe you should be more backward\n"," Translated text ::  so maybe you should be more aware of your own body language and gender.advertisement is it bad enough?\n"," Original text   ::  theres a megathread for vaccine or covid related topics don t talk about that shit here idiot\n"," Gold text       ::  theres actually a megathread for vaccine or covid related topics don t talk about that stuff here\n"," Translated text ::  theres a megathread for vaccine or covid related topics don t talk about that stuff here idiot\n"," Original text   ::  the fuck you are on drugs\n"," Gold text       ::  uh you are not being realistic\n"," Translated text ::  the question is why you are doing this and what reason to do it ifyou say that because he thinks\n"," Original text   ::  nta dump his ass tablemanners are no rocket science treating other people like human beings is no rocket science his still a child\n"," Gold text       ::  you should leave him tablemanners are no rocket science treating other people like human beings is no rocket science his still a child\n"," Translated text ::  nta dump his money on the tablemanners are no rocket science treating other people like human beings is\n"," Original text   ::  youre soft as baby shit\n"," Gold text       ::  youre really soft\n"," Translated text ::  youre soft as baby sissy is your favorite thing to eat? are you eating like a human being\n"]}]},{"cell_type":"code","source":["output_file = '/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output2.csv'\n","sample=pd.read_csv(output_file, sep=\"\\t\")\n","sample[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zDx3X9eBsnXb","outputId":"0a585d8b-7244-4187-cfe1-9779281ec3ac","executionInfo":{"status":"ok","timestamp":1680248206182,"user_tz":420,"elapsed":11,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          toxic_text  \\\n","0               so maybe you should be more retarded   \n","1  theres a megathread for vaccine or covid relat...   \n","2                          the fuck you are on drugs   \n","3  nta dump his ass tablemanners are no rocket sc...   \n","4                            youre soft as baby shit   \n","\n","                                           gold_text  \\\n","0               so maybe you should be more backward   \n","1  theres actually a megathread for vaccine or co...   \n","2                     uh you are not being realistic   \n","3  you should leave him tablemanners are no rocke...   \n","4                                  youre really soft   \n","\n","                                  bart_tuning_output  \n","0  so maybe you should be more aware of your own ...  \n","1  theres a megathread for vaccine or covid relat...  \n","2  the question is why you are doing this and wha...  \n","3  nta dump his money on the tablemanners are no ...  \n","4  youre soft as baby sissy is your favorite thin...  "],"text/html":["\n","  <div id=\"df-80bc3365-2421-4bdf-bcbc-ac07796e1d94\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_text</th>\n","      <th>gold_text</th>\n","      <th>bart_tuning_output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>so maybe you should be more retarded</td>\n","      <td>so maybe you should be more backward</td>\n","      <td>so maybe you should be more aware of your own ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>theres a megathread for vaccine or covid relat...</td>\n","      <td>theres actually a megathread for vaccine or co...</td>\n","      <td>theres a megathread for vaccine or covid relat...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the fuck you are on drugs</td>\n","      <td>uh you are not being realistic</td>\n","      <td>the question is why you are doing this and wha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nta dump his ass tablemanners are no rocket sc...</td>\n","      <td>you should leave him tablemanners are no rocke...</td>\n","      <td>nta dump his money on the tablemanners are no ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>youre soft as baby shit</td>\n","      <td>youre really soft</td>\n","      <td>youre soft as baby sissy is your favorite thin...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bc3365-2421-4bdf-bcbc-ac07796e1d94')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80bc3365-2421-4bdf-bcbc-ac07796e1d94 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80bc3365-2421-4bdf-bcbc-ac07796e1d94');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/notebooks')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/models')"],"metadata":{"id":"Rz8VIRl7e0eL","executionInfo":{"status":"ok","timestamp":1680248214578,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from DistilBertClassification import BertClassificationML, NonToxicScoreDataLoader, NonToxicScore\n","\n","# Load DistilBERT Classification Model to calculate NonToxicScore\n","score_model = BertClassificationML()\n","score_model = score_model.to(device)\n","\n","# Load training weights\n","pretrained_weights = torch.load('/content/drive/MyDrive/Colab Notebooks/models/DistilBertToxicClassification5.pth')\n","score_model.load_state_dict(pretrained_weights )"],"metadata":{"id":"nW_yJ19qgZmI","colab":{"base_uri":"https://localhost:8080/","height":172,"referenced_widgets":["5a85d456ad2c4922a6a85082e7f13b39","c9f43818642f4b4d9a43750ceb5f3b7a","b9b21819e8594e2c87c88051e8bbaf4c","db3fff18c5ac4294827581338516cd2a","8866525e08e24fe3b2a392f78eec9f6d","1110fb65584543beb0790558499fb802","5fdc2cfc12764553b3f7d61f82d49426","854fb9675a5c4627b2d0c030a9bbd87d","48c0fb2896cf4d189e86679c833d62be","eab709f77ffe4729afd316d79ba3223d","4e24b670a9fc43cc81d9ad937bd845d1","7a6387a19927485fa500e563bee38d12","f19a0258479847cdb00b334f576b1cd7","71a250c82da24664aa9a883240d8a5bb","4d1bd08bbf3e4aebbf84eafb421c9a81","12c3a3a4df9a412e8e353947e384eda5","2438543f137f4d888ffd32ad043725a5","2adc6192e9bd43b7b8a7f920a66eef1d","b792879288064ac6a2b94eeb848e2b6b","e559a582df4546f4ad8c09485b12b310","35e7618f7e5b434aa41f30d97ce90151","6cf9df75e1054cdbaa7600da4437becc"]},"outputId":"e85de86e-c8f1-4ee0-8fc4-32c23de31713","executionInfo":{"status":"ok","timestamp":1680248228897,"user_tz":420,"elapsed":9722,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a85d456ad2c4922a6a85082e7f13b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6387a19927485fa500e563bee38d12"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["output_file = '/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output2.csv'\n","output_col = 'bart_tuning_output'\n","\n","# Create Data Loader\n","score_loader = NonToxicScoreDataLoader(output_file, output_col)\n","\n","# Calculate NonToxicScore\n","bart_NonToxicScores, avg_score = NonToxicScore(score_loader, score_model)"],"metadata":{"id":"WVzkmqLJNG3h","colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["b943a4dbe6624241906cff3329a6ef33","7cfa1f97771944eda60c78366880254e","aac02b1443fb42b7a64d0cde8ac0bc1f","cf96eac868544b7082bea5748267cdc9","851330b0c2044c3cb56b513706798cad","643106cb50b44addafe839513a03cb8c","c7e9cc5e7a7747a9995b995fa2ad7b2d","0ee15caf963b41819083a5376725b5ed","9c63a07927534fe4ae5c9a4bf19e143e","a467312fbc0c4004a761c9c34d7ece08","d559ba85a61145dab17c44bc984cec58","4cdead3d122f408192279bc00bf31a63","9fa8577e0c7944e49aa0465df279cd78","4b9e4c0b0130495c9647ab4b94d2753d","5a4fcbb1574547af8aee898d919f5511","efd51aeae02d47a0b2099753b9d72289","4e711c1e6a6342f6b265a831e1a30fd8","6167de24fe1f47aa98c2049b33861e43","56d49450c8804ed88cbc5bb1642e730e","4e76f10a4eee446cbae5d281b9e990af","d511470ec35841f8ba9b7da6978ebfcd","e944559679e443799a621ce558a4280c"]},"outputId":"bd682fb8-4647-4f17-dd3d-b39ffec75563","executionInfo":{"status":"ok","timestamp":1680248244368,"user_tz":420,"elapsed":2058,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}}},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b943a4dbe6624241906cff3329a6ef33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cdead3d122f408192279bc00bf31a63"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'NonToxicScore': 0.29424230108523497}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"708a2e28684c43ecb270073464fd3240":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e408840d4d345b09a141a98c510214b","IPY_MODEL_fb99a1f42a18459cb2ae7bfbd5ff8f6a","IPY_MODEL_6f32f5662d354c7bbbaa43a05078ffa3"],"layout":"IPY_MODEL_fa56fd27e7f140abbb7a63aa7121a876"}},"9e408840d4d345b09a141a98c510214b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2e1f6b527f146ad8187ccbf9ebaa616","placeholder":"â€‹","style":"IPY_MODEL_f0c8916eb79444d68490b7240cc18b27","value":"Downloading (â€¦)olve/main/vocab.json: 100%"}},"fb99a1f42a18459cb2ae7bfbd5ff8f6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3df7f790dda4feab0b229e80576c1b5","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8825cec597a45d8b4613b3fadf03918","value":898823}},"6f32f5662d354c7bbbaa43a05078ffa3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fdafd22af8247aabcb64015eac9a6f6","placeholder":"â€‹","style":"IPY_MODEL_920755c5b5da4c939ff9a27bad1b1148","value":" 899k/899k [00:00&lt;00:00, 4.51MB/s]"}},"fa56fd27e7f140abbb7a63aa7121a876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2e1f6b527f146ad8187ccbf9ebaa616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0c8916eb79444d68490b7240cc18b27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3df7f790dda4feab0b229e80576c1b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8825cec597a45d8b4613b3fadf03918":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fdafd22af8247aabcb64015eac9a6f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"920755c5b5da4c939ff9a27bad1b1148":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"384309c83eb9438190d1f2822727f397":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_514899b3089043c096ffc89a63fb678c","IPY_MODEL_12c1a12908fc4b74bba26a4a03c9369a","IPY_MODEL_27cd2b573790413992779985729b0712"],"layout":"IPY_MODEL_ead22d8741d547aca6c66f479f19d176"}},"514899b3089043c096ffc89a63fb678c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f44002026094d74a65c163c5933b1d6","placeholder":"â€‹","style":"IPY_MODEL_6ae74445a37a477aa561a9aa54aef66f","value":"Downloading (â€¦)olve/main/merges.txt: 100%"}},"12c1a12908fc4b74bba26a4a03c9369a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51151a25b9004e4680a1561870870f9b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e225a4570304433d9a9f6800a7eba381","value":456318}},"27cd2b573790413992779985729b0712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b117a937c411475a966b4cb711df08fb","placeholder":"â€‹","style":"IPY_MODEL_630922d35fcd4ed8a50727acf03e0634","value":" 456k/456k [00:00&lt;00:00, 2.94MB/s]"}},"ead22d8741d547aca6c66f479f19d176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f44002026094d74a65c163c5933b1d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ae74445a37a477aa561a9aa54aef66f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51151a25b9004e4680a1561870870f9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e225a4570304433d9a9f6800a7eba381":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b117a937c411475a966b4cb711df08fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"630922d35fcd4ed8a50727acf03e0634":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07ede60c080249f9b360c3cedcac9a50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24e5c95bbe6b45be893160970cf015c6","IPY_MODEL_311b0a44d44d4e6fae006cf820970071","IPY_MODEL_ec6b399f6a494b44bae1ebdc6b1fe88c"],"layout":"IPY_MODEL_0b89f9fda6ff455abcd8f4cf0c702974"}},"24e5c95bbe6b45be893160970cf015c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec4148a8e0cc472b8bfe3a72a87cc207","placeholder":"â€‹","style":"IPY_MODEL_e7ac50164034429e9d4847836948002c","value":"Downloading (â€¦)lve/main/config.json: 100%"}},"311b0a44d44d4e6fae006cf820970071":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4678e2c7df974891803d9471274be006","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6abe1eefe6824a81a4685cd9285f35ef","value":1716}},"ec6b399f6a494b44bae1ebdc6b1fe88c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c0c703253e4444f9f401e0c20b7e8d6","placeholder":"â€‹","style":"IPY_MODEL_3f8409b6e50c4803aa21d62f39f832fa","value":" 1.72k/1.72k [00:00&lt;00:00, 32.2kB/s]"}},"0b89f9fda6ff455abcd8f4cf0c702974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec4148a8e0cc472b8bfe3a72a87cc207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ac50164034429e9d4847836948002c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4678e2c7df974891803d9471274be006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6abe1eefe6824a81a4685cd9285f35ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c0c703253e4444f9f401e0c20b7e8d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f8409b6e50c4803aa21d62f39f832fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f379afd91f4045ab96e204156dddb4bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29b1c12140134e1c9ee9d80057375f29","IPY_MODEL_031caaf7a2eb49e483e02a325aba7b90","IPY_MODEL_0b3d28bf760f45f98d7289ba1ccab7e9"],"layout":"IPY_MODEL_c148d170c2a9433aa94e85da10409846"}},"29b1c12140134e1c9ee9d80057375f29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_907666e2df4d46f39d7808520a9ef220","placeholder":"â€‹","style":"IPY_MODEL_415de31dbd2048848ab58b86e920f469","value":"Downloading pytorch_model.bin: 100%"}},"031caaf7a2eb49e483e02a325aba7b90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f5a266ee36448d18ec7a64fb81f735c","max":557771387,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1b0226f06a74a78ad6a9aa8578f7dae","value":557771387}},"0b3d28bf760f45f98d7289ba1ccab7e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccb3af07f82c45f583a657d9d06cba53","placeholder":"â€‹","style":"IPY_MODEL_c106a577911a41fc9d8fe9ce05c6c9ee","value":" 558M/558M [00:05&lt;00:00, 99.0MB/s]"}},"c148d170c2a9433aa94e85da10409846":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"907666e2df4d46f39d7808520a9ef220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"415de31dbd2048848ab58b86e920f469":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f5a266ee36448d18ec7a64fb81f735c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1b0226f06a74a78ad6a9aa8578f7dae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccb3af07f82c45f583a657d9d06cba53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c106a577911a41fc9d8fe9ce05c6c9ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a85d456ad2c4922a6a85082e7f13b39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9f43818642f4b4d9a43750ceb5f3b7a","IPY_MODEL_b9b21819e8594e2c87c88051e8bbaf4c","IPY_MODEL_db3fff18c5ac4294827581338516cd2a"],"layout":"IPY_MODEL_8866525e08e24fe3b2a392f78eec9f6d"}},"c9f43818642f4b4d9a43750ceb5f3b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1110fb65584543beb0790558499fb802","placeholder":"â€‹","style":"IPY_MODEL_5fdc2cfc12764553b3f7d61f82d49426","value":"Downloading (â€¦)lve/main/config.json: 100%"}},"b9b21819e8594e2c87c88051e8bbaf4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_854fb9675a5c4627b2d0c030a9bbd87d","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48c0fb2896cf4d189e86679c833d62be","value":483}},"db3fff18c5ac4294827581338516cd2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eab709f77ffe4729afd316d79ba3223d","placeholder":"â€‹","style":"IPY_MODEL_4e24b670a9fc43cc81d9ad937bd845d1","value":" 483/483 [00:00&lt;00:00, 17.4kB/s]"}},"8866525e08e24fe3b2a392f78eec9f6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1110fb65584543beb0790558499fb802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fdc2cfc12764553b3f7d61f82d49426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"854fb9675a5c4627b2d0c030a9bbd87d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c0fb2896cf4d189e86679c833d62be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eab709f77ffe4729afd316d79ba3223d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e24b670a9fc43cc81d9ad937bd845d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a6387a19927485fa500e563bee38d12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f19a0258479847cdb00b334f576b1cd7","IPY_MODEL_71a250c82da24664aa9a883240d8a5bb","IPY_MODEL_4d1bd08bbf3e4aebbf84eafb421c9a81"],"layout":"IPY_MODEL_12c3a3a4df9a412e8e353947e384eda5"}},"f19a0258479847cdb00b334f576b1cd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2438543f137f4d888ffd32ad043725a5","placeholder":"â€‹","style":"IPY_MODEL_2adc6192e9bd43b7b8a7f920a66eef1d","value":"Downloading pytorch_model.bin: 100%"}},"71a250c82da24664aa9a883240d8a5bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b792879288064ac6a2b94eeb848e2b6b","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e559a582df4546f4ad8c09485b12b310","value":267967963}},"4d1bd08bbf3e4aebbf84eafb421c9a81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35e7618f7e5b434aa41f30d97ce90151","placeholder":"â€‹","style":"IPY_MODEL_6cf9df75e1054cdbaa7600da4437becc","value":" 268M/268M [00:03&lt;00:00, 112MB/s]"}},"12c3a3a4df9a412e8e353947e384eda5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2438543f137f4d888ffd32ad043725a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2adc6192e9bd43b7b8a7f920a66eef1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b792879288064ac6a2b94eeb848e2b6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e559a582df4546f4ad8c09485b12b310":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35e7618f7e5b434aa41f30d97ce90151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cf9df75e1054cdbaa7600da4437becc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b943a4dbe6624241906cff3329a6ef33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7cfa1f97771944eda60c78366880254e","IPY_MODEL_aac02b1443fb42b7a64d0cde8ac0bc1f","IPY_MODEL_cf96eac868544b7082bea5748267cdc9"],"layout":"IPY_MODEL_851330b0c2044c3cb56b513706798cad"}},"7cfa1f97771944eda60c78366880254e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_643106cb50b44addafe839513a03cb8c","placeholder":"â€‹","style":"IPY_MODEL_c7e9cc5e7a7747a9995b995fa2ad7b2d","value":"Downloading (â€¦)solve/main/vocab.txt: 100%"}},"aac02b1443fb42b7a64d0cde8ac0bc1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ee15caf963b41819083a5376725b5ed","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c63a07927534fe4ae5c9a4bf19e143e","value":231508}},"cf96eac868544b7082bea5748267cdc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a467312fbc0c4004a761c9c34d7ece08","placeholder":"â€‹","style":"IPY_MODEL_d559ba85a61145dab17c44bc984cec58","value":" 232k/232k [00:00&lt;00:00, 1.89MB/s]"}},"851330b0c2044c3cb56b513706798cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643106cb50b44addafe839513a03cb8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7e9cc5e7a7747a9995b995fa2ad7b2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ee15caf963b41819083a5376725b5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c63a07927534fe4ae5c9a4bf19e143e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a467312fbc0c4004a761c9c34d7ece08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d559ba85a61145dab17c44bc984cec58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cdead3d122f408192279bc00bf31a63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fa8577e0c7944e49aa0465df279cd78","IPY_MODEL_4b9e4c0b0130495c9647ab4b94d2753d","IPY_MODEL_5a4fcbb1574547af8aee898d919f5511"],"layout":"IPY_MODEL_efd51aeae02d47a0b2099753b9d72289"}},"9fa8577e0c7944e49aa0465df279cd78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e711c1e6a6342f6b265a831e1a30fd8","placeholder":"â€‹","style":"IPY_MODEL_6167de24fe1f47aa98c2049b33861e43","value":"Downloading (â€¦)okenizer_config.json: 100%"}},"4b9e4c0b0130495c9647ab4b94d2753d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56d49450c8804ed88cbc5bb1642e730e","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e76f10a4eee446cbae5d281b9e990af","value":28}},"5a4fcbb1574547af8aee898d919f5511":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d511470ec35841f8ba9b7da6978ebfcd","placeholder":"â€‹","style":"IPY_MODEL_e944559679e443799a621ce558a4280c","value":" 28.0/28.0 [00:00&lt;00:00, 1.61kB/s]"}},"efd51aeae02d47a0b2099753b9d72289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e711c1e6a6342f6b265a831e1a30fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6167de24fe1f47aa98c2049b33861e43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56d49450c8804ed88cbc5bb1642e730e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e76f10a4eee446cbae5d281b9e990af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d511470ec35841f8ba9b7da6978ebfcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e944559679e443799a621ce558a4280c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}