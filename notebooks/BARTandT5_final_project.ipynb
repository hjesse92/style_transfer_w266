{"cells":[{"cell_type":"markdown","metadata":{"id":"so-yur1S9mS4"},"source":["## 1. Setup\n","\n","### 1.1. Libraries and Helper Functions\n","\n","This notebook requires the TensorFlow dataset and other prerequisites that you must download. "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13976,"status":"ok","timestamp":1678244689446,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"8uQnMctL9mS5","outputId":"2fdc1ed4-7848-485e-81d2-b007807542de"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#@title Installs\n","\n","# !pip install pydot --quiet\n","# !pip install gensim==3.8.3 --quiet\n","# !pip install tensorflow-datasets --quiet\n","# !pip install -U tensorflow-text==2.8.2 --quiet\n","!pip install transformers --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3052,"status":"ok","timestamp":1678244692474,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"7CALja8vLcZ9"},"outputs":[],"source":["import torch\n","\n","# Check if a GPU is available, otherwise use CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1678244692477,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"3cbELEg_S5iX","outputId":"e67ebc98-5510-4be4-81ee-55d6f698252a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}],"source":["device"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25843,"status":"ok","timestamp":1678244718284,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"zdxTNXwDv2J7","outputId":"ee6f0629-f8cf-4df2-9cf3-0dc94ed95fbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install tqdm boto3 requests regex sentencepiece sacremoses --quiet"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":68,"status":"ok","timestamp":1678244718285,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"Q8b9aykE9mS8"},"outputs":[],"source":["#@title Imports\n","\n","# import numpy as np\n","# import tensorflow as tf\n","# from tensorflow import keras\n","\n","# from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","# from tensorflow.keras.models import Model\n","# import tensorflow.keras.backend as K\n","# import tensorflow_datasets as tfds\n","# import tensorflow_text as tf_text\n","\n","# from transformers import BertTokenizer, TFBertModel\n","\n","\n","# import sklearn as sk\n","# import os\n","# import nltk\n","# from nltk.data import find\n","\n","# import matplotlib.pyplot as plt\n","\n","# import re\n","\n","# #This continues to work with gensim 3.8.3.  It doesn't yet work with 4.x.  \n","# #Make sure your pip install command specifies gensim==3.8.3\n","# import gensim\n"]},{"cell_type":"markdown","metadata":{"id":"ESElm33U9mS9"},"source":["Below is a helper function to plot histories."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":66,"status":"ok","timestamp":1678244718286,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"YKWj6pPM9mS-"},"outputs":[],"source":["#@title Plotting Function\n","\n","# # 4-window plot. Small modification from matplotlib examples.\n","\n","# def make_plot(axs,\n","#               model_history1, \n","#               model_history2, \n","#               model_1_name='model 1',\n","#               model_2_name='model 2',\n","#               ):\n","#     box = dict(facecolor='yellow', pad=5, alpha=0.2)\n","\n","#     for i, metric in enumerate(['loss', 'accuracy']):\n","#         # small adjustment to account for the 2 accuracy measures in the Weighted Averging Model with Attention\n","#         if 'classification_%s' % metric in model_history2.history:\n","#             metric2 = 'classification_%s' % metric\n","#         else:\n","#             metric2 = metric\n","        \n","#         y_lim_lower1 = np.min(model_history1.history[metric])\n","#         y_lim_lower2 = np.min(model_history2.history[metric2])\n","#         y_lim_lower = min(y_lim_lower1, y_lim_lower2) * 0.9\n","\n","#         y_lim_upper1 = np.max(model_history1.history[metric])\n","#         y_lim_upper2 = np.max(model_history2.history[metric2])\n","#         y_lim_upper = max(y_lim_upper1, y_lim_upper2) * 1.1\n","\n","#         for j, model_history in enumerate([model_history1, model_history2]):\n","#             model_name = [model_1_name, model_2_name][j]\n","#             model_metric = [metric, metric2][j]\n","#             ax1 = axs[i, j]\n","#             ax1.plot(model_history.history[model_metric])\n","#             ax1.plot(model_history.history['val_%s' % model_metric])\n","#             ax1.set_title('%s - %s' % (metric, model_name))\n","#             ax1.set_ylabel(metric, bbox=box)\n","#             ax1.set_ylim(y_lim_lower, y_lim_upper)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33607,"status":"ok","timestamp":1678244751828,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"YnqrYaGuxo3M","outputId":"30cfb4d6-959d-4a64-c302-466ea7f0b9a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1406,"status":"ok","timestamp":1678244753218,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"SCThYsKtyrOn","outputId":"3dd5a020-ab75-416f-cf1f-06f9f808ec95"},"outputs":[{"output_type":"stream","name":"stdout","text":["bias_data  __MACOSX\n"]}],"source":["import pandas as pd\n","\n","!ls \"/content/drive/MyDrive/Colab Notebooks/bias_data\""]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1678244753219,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"sONd1NAi0WYu"},"outputs":[],"source":["train_path='/content/drive/MyDrive/Colab Notebooks/bias_data/bias_data/WNC/biased.word.train'\n","dev_path='/content/drive/MyDrive/Colab Notebooks/bias_data/bias_data/WNC/biased.word.dev'\n","test_path='/content/drive/MyDrive/Colab Notebooks/bias_data/bias_data/WNC/biased.word.test'"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5277,"status":"ok","timestamp":1678244758485,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"xrPt0eb-tn6_"},"outputs":[],"source":["train = pd.read_csv(train_path, sep='\\t', header=None)\n","dev = pd.read_csv(dev_path, sep='\\t', header=None)\n","test = pd.read_csv(test_path, sep='\\t', header=None)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1678244758486,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"dczlqbF7ztI3","outputId":"618b6865-58fe-414c-8cd0-55d1e5e30538"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train length: 53803\n","Dev length: 700\n","Test length: 1000\n"]}],"source":["print(\"Train length: {}\".format(len(train)))\n","print(\"Dev length: {}\".format(len(dev)))\n","print(\"Test length: {}\".format(len(test)))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":658},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1678244758487,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"e0AyoPKAo3bi","outputId":"6dc1aec3-64bf-4891-a81d-ec6be71518e6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["               0                                                  1  \\\n","0      165188319  ch ##lor ##of ##or ##m \" the molecular life ##...   \n","1      123204846  the free software gnu class ##path project is ...   \n","2      706783956  other campaign ##ers , especially the controve...   \n","3      612378448  vocalist rob half ##ord ' s performance is con...   \n","4      876796337  the proud general is a chinese animated featur...   \n","...          ...                                                ...   \n","53798  341593940  the national lawyers guild is a progressive / ...   \n","53799  640510650  a plan to red ##eve ##lo ##p the old tiger sta...   \n","53800  162719260  instrumental ##ly , life ##son is regarded as ...   \n","53801   62331672  fly ##nt joined the us army in 1958 at only fi...   \n","53802   93333495  today , mtv ##2 airs some music videos , other...   \n","\n","                                                       2  \\\n","0      ch ##lor ##of ##or ##m \" the molecular life ##...   \n","1      the free software gnu class ##path project is ...   \n","2      other campaign ##ers , especially the british ...   \n","3      vocalist rob half ##ord ' s performance is con...   \n","4      the proud general is a chinese animated featur...   \n","...                                                  ...   \n","53798  the national lawyers guild is a progressive ba...   \n","53799  a plan to red ##eve ##lo ##p the old tiger sta...   \n","53800  instrumental ##ly , life ##son is regarded as ...   \n","53801  fly ##nt joined the us army in 1958 at only fi...   \n","53802  today , mtv ##2 airs a selection music videos ...   \n","\n","                                                       3  \\\n","0      chloroform \"the molecular lifesaver\" an articl...   \n","1      the free software gnu classpath project is onl...   \n","2      other campaigners, especially the controversia...   \n","3      vocalist rob halford's performance is consider...   \n","4      the proud general is a chinese animated featur...   \n","...                                                  ...   \n","53798  the national lawyers guild is a progressive /l...   \n","53799  a plan to redevelop the old tiger stadium site...   \n","53800  instrumentally, lifeson is regarded as a virtu...   \n","53801  flynt joined the us army in 1958 at only fifte...   \n","53802  today, mtv2 airs some music videos, other musi...   \n","\n","                                                       4  \\\n","0      chloroform \"the molecular lifesaver\" an articl...   \n","1      the free software gnu classpath project is par...   \n","2      other campaigners, especially the british acti...   \n","3      vocalist rob halford's performance is consider...   \n","4      the proud general is a chinese animated featur...   \n","...                                                  ...   \n","53798  the national lawyers guild is a progressive ba...   \n","53799  a plan to redevelop the old tiger stadium site...   \n","53800  instrumentally, lifeson is regarded as a guita...   \n","53801  flynt joined the us army in 1958 at only fifte...   \n","53802  today, mtv2 airs a selection music videos, oth...   \n","\n","                                                       5  \\\n","0      NOUN NOUN NOUN NOUN NOUN PUNCT DET ADJ NOUN NO...   \n","1      DET ADJ NOUN NOUN NOUN NOUN NOUN VERB ADV ADV ...   \n","2      ADJ NOUN NOUN PUNCT ADV DET ADJ ADJ NOUN ADJ N...   \n","3      ADJ X NOUN NOUN PUNCT PART NOUN VERB VERB NUM ...   \n","4      DET ADJ NOUN VERB DET ADJ VERB NOUN NOUN VERB ...   \n","...                                                  ...   \n","53798  DET ADJ NOUN ADJ VERB DET ADJ SYM ADJ PUNCT NO...   \n","53799  DET NOUN PART VERB VERB VERB VERB DET ADJ NOUN...   \n","53800  ADV ADV PUNCT NOUN NOUN VERB VERB ADP DET ADJ ...   \n","53801  NOUN NOUN VERB DET PRON NOUN ADP NUM ADP ADV N...   \n","53802  NOUN PUNCT NOUN NOUN NOUN DET NOUN NOUN PUNCT ...   \n","\n","                                                       6  \n","0      ROOT ROOT ROOT ROOT ROOT punct det amod dobj d...  \n","1      det amod nmod compound compound compound nsubj...  \n","2      amod nsubj nsubj punct advmod det amod amod am...  \n","3      amod amod poss poss punct case nsubjpass auxpa...  \n","4      det amod nsubj ROOT det amod amod attr attr ac...  \n","...                                                  ...  \n","53798  det amod compound nsubj ROOT det amod punct am...  \n","53799  det nsubj aux acl acl acl acl det amod compoun...  \n","53800  advmod advmod punct nsubjpass nsubjpass auxpas...  \n","53801  nsubj nsubj ROOT det compound dobj prep pobj p...  \n","53802  npadvmod punct nsubj nsubj ROOT det compound d...  \n","\n","[53803 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-ef43f1c1-156b-426c-b50a-4b8e94d64b02\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>165188319</td>\n","      <td>ch ##lor ##of ##or ##m \" the molecular life ##...</td>\n","      <td>ch ##lor ##of ##or ##m \" the molecular life ##...</td>\n","      <td>chloroform \"the molecular lifesaver\" an articl...</td>\n","      <td>chloroform \"the molecular lifesaver\" an articl...</td>\n","      <td>NOUN NOUN NOUN NOUN NOUN PUNCT DET ADJ NOUN NO...</td>\n","      <td>ROOT ROOT ROOT ROOT ROOT punct det amod dobj d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>123204846</td>\n","      <td>the free software gnu class ##path project is ...</td>\n","      <td>the free software gnu class ##path project is ...</td>\n","      <td>the free software gnu classpath project is onl...</td>\n","      <td>the free software gnu classpath project is par...</td>\n","      <td>DET ADJ NOUN NOUN NOUN NOUN NOUN VERB ADV ADV ...</td>\n","      <td>det amod nmod compound compound compound nsubj...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>706783956</td>\n","      <td>other campaign ##ers , especially the controve...</td>\n","      <td>other campaign ##ers , especially the british ...</td>\n","      <td>other campaigners, especially the controversia...</td>\n","      <td>other campaigners, especially the british acti...</td>\n","      <td>ADJ NOUN NOUN PUNCT ADV DET ADJ ADJ NOUN ADJ N...</td>\n","      <td>amod nsubj nsubj punct advmod det amod amod am...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>612378448</td>\n","      <td>vocalist rob half ##ord ' s performance is con...</td>\n","      <td>vocalist rob half ##ord ' s performance is con...</td>\n","      <td>vocalist rob halford's performance is consider...</td>\n","      <td>vocalist rob halford's performance is consider...</td>\n","      <td>ADJ X NOUN NOUN PUNCT PART NOUN VERB VERB NUM ...</td>\n","      <td>amod amod poss poss punct case nsubjpass auxpa...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>876796337</td>\n","      <td>the proud general is a chinese animated featur...</td>\n","      <td>the proud general is a chinese animated featur...</td>\n","      <td>the proud general is a chinese animated featur...</td>\n","      <td>the proud general is a chinese animated featur...</td>\n","      <td>DET ADJ NOUN VERB DET ADJ VERB NOUN NOUN VERB ...</td>\n","      <td>det amod nsubj ROOT det amod amod attr attr ac...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53798</th>\n","      <td>341593940</td>\n","      <td>the national lawyers guild is a progressive / ...</td>\n","      <td>the national lawyers guild is a progressive ba...</td>\n","      <td>the national lawyers guild is a progressive /l...</td>\n","      <td>the national lawyers guild is a progressive ba...</td>\n","      <td>DET ADJ NOUN ADJ VERB DET ADJ SYM ADJ PUNCT NO...</td>\n","      <td>det amod compound nsubj ROOT det amod punct am...</td>\n","    </tr>\n","    <tr>\n","      <th>53799</th>\n","      <td>640510650</td>\n","      <td>a plan to red ##eve ##lo ##p the old tiger sta...</td>\n","      <td>a plan to red ##eve ##lo ##p the old tiger sta...</td>\n","      <td>a plan to redevelop the old tiger stadium site...</td>\n","      <td>a plan to redevelop the old tiger stadium site...</td>\n","      <td>DET NOUN PART VERB VERB VERB VERB DET ADJ NOUN...</td>\n","      <td>det nsubj aux acl acl acl acl det amod compoun...</td>\n","    </tr>\n","    <tr>\n","      <th>53800</th>\n","      <td>162719260</td>\n","      <td>instrumental ##ly , life ##son is regarded as ...</td>\n","      <td>instrumental ##ly , life ##son is regarded as ...</td>\n","      <td>instrumentally, lifeson is regarded as a virtu...</td>\n","      <td>instrumentally, lifeson is regarded as a guita...</td>\n","      <td>ADV ADV PUNCT NOUN NOUN VERB VERB ADP DET ADJ ...</td>\n","      <td>advmod advmod punct nsubjpass nsubjpass auxpas...</td>\n","    </tr>\n","    <tr>\n","      <th>53801</th>\n","      <td>62331672</td>\n","      <td>fly ##nt joined the us army in 1958 at only fi...</td>\n","      <td>fly ##nt joined the us army in 1958 at only fi...</td>\n","      <td>flynt joined the us army in 1958 at only fifte...</td>\n","      <td>flynt joined the us army in 1958 at only fifte...</td>\n","      <td>NOUN NOUN VERB DET PRON NOUN ADP NUM ADP ADV N...</td>\n","      <td>nsubj nsubj ROOT det compound dobj prep pobj p...</td>\n","    </tr>\n","    <tr>\n","      <th>53802</th>\n","      <td>93333495</td>\n","      <td>today , mtv ##2 airs some music videos , other...</td>\n","      <td>today , mtv ##2 airs a selection music videos ...</td>\n","      <td>today, mtv2 airs some music videos, other musi...</td>\n","      <td>today, mtv2 airs a selection music videos, oth...</td>\n","      <td>NOUN PUNCT NOUN NOUN NOUN DET NOUN NOUN PUNCT ...</td>\n","      <td>npadvmod punct nsubj nsubj ROOT det compound d...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>53803 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef43f1c1-156b-426c-b50a-4b8e94d64b02')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ef43f1c1-156b-426c-b50a-4b8e94d64b02 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ef43f1c1-156b-426c-b50a-4b8e94d64b02');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["display(train)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1678244758489,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"krvZoyyDz4P5"},"outputs":[],"source":["def read_process_data(train_path, dev_path):\n","    train = pd.read_csv(train_path, sep='\\t', header=None)\n","    dev = pd.read_csv(dev_path, sep = '\\t', header=None)\n","    \n","    print(\"Train length: {}\".format(len(train)))\n","    print(\"Dev length: {}\".format(len(dev)))\n","    \n","    #Rename columns\n","    train.columns = ['id', 'annot_old', 'annot_new', 'biased', 'unbiased', 'tags', 'roots']\n","    dev.columns = ['id', 'annot_old', 'annot_new', 'biased', 'unbiased', 'tags', 'roots']\n","    \n","    #Process and recombine training data: \n","    train_biased, dev_biased = pd.DataFrame(train.biased), pd.DataFrame(dev.biased)\n","    train_unbiased, dev_unbiased = pd.DataFrame(train.unbiased), pd.DataFrame(dev.unbiased)\n","    \n","    \n","    train_biased['label'], dev_biased['label'] = [1]*len(train_biased), [1]*len(dev_biased)\n","    train_unbiased['label'], dev_unbiased['label'] = [0]*len(train_unbiased), [0]*len(dev_unbiased)\n","\n","    #Fix colnames\n","    train_biased.columns, dev_biased.columns = ['text', 'label'], ['text', 'label']\n","    train_unbiased.columns, dev_unbiased.columns = ['text', 'label'], ['text', 'label']\n","    #Combine\n","    train_all, dev_all = pd.concat([train_biased, train_unbiased]), pd.concat([dev_biased, dev_unbiased])\n","    \n","    return train_all, dev_all"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2322,"status":"ok","timestamp":1678244760784,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"AAhbhcn2z_rz","outputId":"55cfc051-8a43-493b-8737-1ba9d773b8a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train length: 53803\n","Dev length: 700\n"]}],"source":["train, dev = read_process_data(train_path, dev_path)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1678244760787,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"ZVm_sJtH1CN6","outputId":"101d243b-dc5c-46d9-90fe-0947fe4041e2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                    text  label\n","0      chloroform \"the molecular lifesaver\" an articl...      1\n","1      the free software gnu classpath project is onl...      1\n","2      other campaigners, especially the controversia...      1\n","3      vocalist rob halford's performance is consider...      1\n","4      the proud general is a chinese animated featur...      1\n","...                                                  ...    ...\n","53798  the national lawyers guild is a progressive ba...      0\n","53799  a plan to redevelop the old tiger stadium site...      0\n","53800  instrumentally, lifeson is regarded as a guita...      0\n","53801  flynt joined the us army in 1958 at only fifte...      0\n","53802  today, mtv2 airs a selection music videos, oth...      0\n","\n","[107606 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3c35635a-0a3e-4593-9008-fde832468e00\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>chloroform \"the molecular lifesaver\" an articl...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the free software gnu classpath project is onl...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>other campaigners, especially the controversia...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vocalist rob halford's performance is consider...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>the proud general is a chinese animated featur...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>53798</th>\n","      <td>the national lawyers guild is a progressive ba...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>53799</th>\n","      <td>a plan to redevelop the old tiger stadium site...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>53800</th>\n","      <td>instrumentally, lifeson is regarded as a guita...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>53801</th>\n","      <td>flynt joined the us army in 1958 at only fifte...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>53802</th>\n","      <td>today, mtv2 airs a selection music videos, oth...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>107606 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c35635a-0a3e-4593-9008-fde832468e00')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c35635a-0a3e-4593-9008-fde832468e00 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c35635a-0a3e-4593-9008-fde832468e00');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["display(train)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1678244760792,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"niEwhBdNFnxW","outputId":"2a6531f9-f249-4860-b88c-e902b4d2b403"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1374"]},"metadata":{},"execution_count":16}],"source":["train['text'].str.len().max()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":482,"status":"ok","timestamp":1678244761236,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"E2MqDpHEGNyi","outputId":"1bcf8ede-5cfb-4ac8-9886-dc90d5885f22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":17}],"source":["train['text'].str.len().min()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1678244761238,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"pBfPJTp0Tg6T","outputId":"875c38bc-d2ae-4819-b02d-e88e2fdeda7d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["162.60397189747783"]},"metadata":{},"execution_count":18}],"source":["train['text'].str.len().mean()"]},{"cell_type":"code","source":["display(dev)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"T9czbY31t-91","executionInfo":{"status":"ok","timestamp":1678244761242,"user_tz":480,"elapsed":31,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"outputId":"c53334ae-6c1b-46b7-93e6-53f5b1692abf"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                                  text  label\n","0    in addition to sponsoring palestinian terror a...      1\n","1    the game is currently played in 47 countries w...      1\n","2    no part of the valley lies in the area current...      1\n","3    scholars perceived that it was discordant with...      1\n","4    since the chinese civil war in 1949, taiwan ha...      1\n","..                                                 ...    ...\n","695  in 2008 five pharmaceutical companies received...      0\n","696  the palm, a steakhouse restaurant chain origin...      0\n","697                      d.c. united's early successes      0\n","698  on 29 june 2007 price gave birth to her third ...      0\n","699  on 7 april, reuters reported that soldiers loy...      0\n","\n","[1400 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d30a81ce-57a0-429a-ba58-18e197ca21d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>in addition to sponsoring palestinian terror a...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the game is currently played in 47 countries w...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>no part of the valley lies in the area current...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>scholars perceived that it was discordant with...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>since the chinese civil war in 1949, taiwan ha...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>695</th>\n","      <td>in 2008 five pharmaceutical companies received...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>696</th>\n","      <td>the palm, a steakhouse restaurant chain origin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>697</th>\n","      <td>d.c. united's early successes</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>on 29 june 2007 price gave birth to her third ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>on 7 april, reuters reported that soldiers loy...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1400 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d30a81ce-57a0-429a-ba58-18e197ca21d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d30a81ce-57a0-429a-ba58-18e197ca21d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d30a81ce-57a0-429a-ba58-18e197ca21d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["The Wikipedia neutrality corpus is a collection of text samples from Wikipedia that have been labeled as either neutral or non-neutral. Exploratory Data Analysis (EDA) can provide insights into the characteristics of the corpus, such as the distribution of neutral and non-neutral samples, the length of the samples, and the most common words and phrases in each class. Here are some EDA techniques that we will apply to the Wikipedia neutrality corpus:\n","\n","Data Cleaning: The first step in any EDA process is to clean the data. This might involve removing any extraneous metadata or formatting, and standardizing the text to a consistent format. It is also important to remove any samples that are incomplete or have missing labels.\n","\n","Distribution of Labels: One important aspect of the corpus is the distribution of neutral and non-neutral samples. It is important to understand the balance of the corpus, as this can impact the performance of any machine learning models trained on it.\n","\n","Word Frequencies: To understand the characteristics of the text in the corpus, it is useful to examine the most frequent words and phrases in each class. This can provide insights into the language and terminology used in neutral and non-neutral text.\n","\n","Text Length: The length of the text samples can also provide useful insights into the corpus. For example, it might be interesting to compare the average length of neutral and non-neutral samples, or to look for patterns in the distribution of text lengths.\n"],"metadata":{"id":"9yXUsvE9VlTr"}},{"cell_type":"code","source":["# Work in progress\n","# import torch\n","# import torchtext\n","\n","# def text_word_frequency(data_path):\n","#   with open(data_path, 'r') as f:\n","#             for line in f:\n","#                 line = line.strip()\n","#                 if line:\n","#                     # print(line)\n","#                     parts = line.split('\\t')\n","#                     text = parts[0]\n","#                   # # Load the text data\n","#                   # text = \"This is a sample text. This text can be used to demonstrate word frequency.\"\n","#                   tokens = text.lower().split()\n","\n","#                   # Create a Torchtext vocabulary from the text\n","#                   vocab = torchtext.vocab.Vocab(\n","#                       counter=torchtext.vocab.Counter(tokens),\n","#                       specials=['<pad>', '<unk>']\n","#                   )\n","\n","#                   # Create a tensor of token indices for the text\n","#                   token_indices = torch.tensor([vocab[token] for token in tokens])\n","\n","#                   # Count the frequency of each word\n","#                   word_frequencies = torch.bincount(token_indices)\n","\n","#                   # Print the most common words and their frequency\n","#                   for i in torch.argsort(word_frequencies, descending=True)[:10]:\n","#                       print(vocab.itos[i], word_frequencies[i].item())"],"metadata":{"id":"dKL_Meh6WQvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oeRVnvQ10d1K"},"source":["Below code is implementation of BART (Bidirectional and Auto-Regressive Transformer) model for sequence-to-sequence (seq2seq) tasks using PyTorch. The BART model is a variant of the Transformer model and is pre-trained on a large corpus of text data using a denoising autoencoder objective. It is capable of generating high-quality text with coherent sentence structures.\n","\n","The code defines a PyTorch Dataset class MyDataset that reads the input and target text sequences from a text file and tokenizes them using the BART tokenizer. It then defines the collate_fn function to pad the sequences in each batch to the same length. The code then defines the BartEncoderDecoder class, which is the main model class that uses the BART encoder and decoder architecture.\n","\n","The code instantiates the BART tokenizer and the BartEncoderDecoder model, and loads the training and validation data using the MyDataset class. It also defines the optimizer and loss function. The code then runs the training loop for a specified number of epochs, during which it trains the model on the training set and evaluates it on the validation set.\n","\n","During training, the code iterates over the batches of training data and performs forward and backward passes through the model to compute the loss and update the model parameters using the Adam optimizer. The code also implements gradient accumulation by accumulating the gradients over a specified number of batches to reduce the memory requirements during training. After training on all the batches, the code computes the average loss over the entire training set and evaluates the model on the validation set.\n","\n","During validation, the code iterates over the batches of validation data and generates the predicted text sequences using the generate method of the BART decoder. It then computes the loss between the predicted and target sequences and accumulates the loss over all the batches to compute the average loss over the entire validation set. Finally, the code prints the average training and validation loss for each epoch."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6807,"status":"ok","timestamp":1678244768025,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"},"user_tz":480},"id":"6olz1mhT-ovf"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import Adam\n","from transformers import BartTokenizer, BartConfig, BartForConditionalGeneration,BartModel\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","# the MyDataset class takes three arguments:\n","\n","# data_path: The path to the training data file.\n","# tokenizer: The tokenizer used to preprocess the input data.\n","# max_seq_len: The maximum sequence length allowed for the input sequences.\n","# In the __init__ method, the training data is loaded from the specified file, and each line of text is stored in a list.\n","\n","# In the __len__ method, the length of the dataset is returned (i.e., the number of lines in the training data file).\n","\n","# In the __getitem__ method, an individual training example is retrieved based on the specified index. The input text is tokenized using the specified tokenizer and truncated to the specified maximum sequence length, and the resulting token ids are converted to a PyTorch tensor and returned as the training example.\n","\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path, tokenizer, max_seq_len):\n","        self.tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len\n","\n","        self.source_ids = []\n","        self.target_ids = []\n","\n","        with open(data_path, 'r') as f:\n","            for line in f:\n","                line = line.strip()\n","                if line:\n","                    # print(line)\n","                    parts = line.split('\\t')\n","                    source_seq = parts[0]\n","                    target_seq = parts[1]\n","\n","                    #source_seq, target_seq = line.split('\\t')\n","                    source_ids = tokenizer.encode(\n","                        source_seq, add_special_tokens=True, truncation=True,\n","                        max_length=max_seq_len\n","                    )\n","                    target_ids = tokenizer.encode(\n","                        target_seq, add_special_tokens=True, truncation=True,\n","                        max_length=max_seq_len\n","                    )\n","                    self.source_ids.append(source_ids)\n","                    self.target_ids.append(target_ids)\n","\n","    def __len__(self):\n","        return len(self.source_ids)\n","\n","    def __getitem__(self, index):\n","        source_ids = self.source_ids[index]\n","        target_ids = self.target_ids[index]\n","\n","        # Create a PyTorch tensor from the tokenized sequences\n","        source_ids = torch.tensor(source_ids)\n","        target_ids = torch.tensor(target_ids)\n","\n","        return {'source_ids': source_ids, 'target_ids': target_ids}\n","\n","    def collate_fn(self, batch):\n","        # Pad sequences in batch to have the same length\n","        source_ids = pad_sequence([item['source_ids'] for item in batch], batch_first=True, padding_value=self.tokenizer.pad_token_id)\n","        target_ids = pad_sequence([item['target_ids'] for item in batch], batch_first=True, padding_value=self.tokenizer.pad_token_id)\n","\n","        return {'source_ids': source_ids, 'target_ids': target_ids}\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":516,"referenced_widgets":["f13f9f22b20a4dacabda267b46bf2863","dd8dbe9412eb4dba8b7bdc63b075fb75","e15ea526a56a4d69b4d1dee84ad2ef00","2baaa200432749e38146a7f84a98a50c","fd70ca7b96994a2d8dddad129c33cc91","6016500cd59042d286ce00e6218d14f6","0b1f439a8cad4b529422358a4cd80241","1ef3a004161b4f18815cdfac7cd1a427","4b5d692d0f4441d1a96edb3226a02f82","1e0505300bf74cd997b695c86557e67b","b77da4d519104f88938128f0ad985c81","094e9c45efe541738222081973869bdc","e5a571d4f2044dd9aa5819f0343cf815","5c1599cc23344cc1a69ccd33d564a0ce","dbc85bb0110a417a9b4cac788ef2c53f","1f9fbaf0f74949cf816c2142005cce29","1b1b7dddf85840e78195d9a398a8f535","b9e887924b094fa09c33b0f4ecce749b","9ed068d1f4454ac2b54a107b9d8afa05","6a25d045dde241cc93eb4d6fa8e8fdef","ccdda58676f6447aabada206e6c8f943","a2ba1066d3e2474f8ae8ed403a5faa2e","d2f774e33e31458ca36c38abc5679a54","caddc1d4ed0e46f991891517593cab86","4da5c64e863649bf8d4153aa7d38adcc","8885ebe47f564f96a3e2f525321ae9d0","9d4abe59ee4d46a3ad19bba91407608a","701ecae6379849e3bc76ce80b333577f","470ff62e1fb24fc686dfac8a15dd0820","e225894b3af642c590a10761961f92ca","e3fab536bfba4964975cf2a6857525d4","3ee3651c7537413b84f77e6beaa7d113","b1b69be5c28243beb8c97a4b40c98a61","f499f681469f4545b2ba2b8576b367a9","1a2b38ad64c84879b940b79f0583c86e","7be02108c73e4c7c9f7e9038a6203d6d","fa4d6a89605b4d7e8e11097604348508","ce1272a7039a4075bae46382c9ca9dcc","7e7a378374ba47fa80f4668c1c8f17a6","2f87cc3eb14a42d1b53a29f20641f34a","a3defad5a35543db90b0f6ff84caa1b2","5b6e95513c22417c8d35777a3b6be79f","f33f39c71a904b8cad865c41385b4872","4e7f9a3b98fc4749af66d5d3a34f854a"]},"id":"TYQd-fO70q4z","executionInfo":{"status":"error","timestamp":1678253266486,"user_tz":480,"elapsed":131180,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"outputId":"29f6a28f-6881-4c9b-fc4f-45193204350f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f13f9f22b20a4dacabda267b46bf2863","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"094e9c45efe541738222081973869bdc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2f774e33e31458ca36c38abc5679a54","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f499f681469f4545b2ba2b8576b367a9","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-bcd66b925c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mGRADIENT_ACCUMULATION_STEPS\u001b[0m  \u001b[0;31m# divide loss by number of steps to average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mGRADIENT_ACCUMULATION_STEPS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Define hyperparameters\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 10\n","LEARNING_RATE = 1e-4\n","MAX_SEQ_LEN = 128\n","D_MODEL = 768\n","NUM_HEADS = 12\n","NUM_ENCODER_LAYERS = 6\n","NUM_DECODER_LAYERS = 6\n","DIM_FEEDFORWARD = 3072\n","DROPOUT = 0.1\n","GRADIENT_ACCUMULATION_STEPS = 4  # accumulate gradients over 4 batches\n","# Instantiate BART tokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n","\n","# Define BART encoder-decoder model\n","class BartEncoderDecoder(nn.Module):\n","    def __init__(self, bart_config):\n","        super().__init__()\n","        self.encoder = BartModel(bart_config)\n","        self.decoder = BartForConditionalGeneration(bart_config)\n","\n","    def forward(self, input_ids, decoder_input_ids):\n","        encoder_outputs = self.encoder(input_ids=input_ids)\n","        decoder_outputs = self.decoder(input_ids=decoder_input_ids,encoder_outputs=encoder_outputs)\n","        return decoder_outputs\n","\n","# Instantiate BART encoder-decoder model\n","bart_config = BartConfig(d_model=D_MODEL, encoder_layers=NUM_ENCODER_LAYERS, decoder_layers=NUM_DECODER_LAYERS, \n","                         encoder_attention_heads=NUM_HEADS, decoder_attention_heads=NUM_HEADS,\n","                         encoder_ffn_dim=DIM_FEEDFORWARD, decoder_ffn_dim=DIM_FEEDFORWARD, dropout=DROPOUT)\n","bart_model = BartEncoderDecoder(bart_config).cuda() # move the model to CUDA\n","\n","# Load training and validation data\n","train_data = MyDataset(train_path, tokenizer, MAX_SEQ_LEN)\n","val_data = MyDataset(dev_path, tokenizer, MAX_SEQ_LEN)\n","\n","# Instantiate data loaders\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,collate_fn=train_data.collate_fn)\n","val_loader = DataLoader(val_data, batch_size=BATCH_SIZE,collate_fn=val_data.collate_fn)\n","\n","# Instantiate optimizer and loss function\n","optimizer = Adam(bart_model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss().cuda() # move the loss function to CUDA\n","\n","# Training loop\n","for epoch in range(NUM_EPOCHS):\n","    # Train the model\n","    bart_model.train()\n","    train_loss = 0\n","    for i, batch in enumerate(train_loader):\n","        src = batch['source_ids'].cuda()#to(device)\n","        tgt = batch['target_ids'].cuda() #to(device)\n","        optimizer.zero_grad()\n","        outputs = bart_model(input_ids=src, decoder_input_ids=tgt[:, :-1].cuda()) #.to(device)\n","        output_shape = outputs.logits.shape\n","        # print(output_shape)\n","        outputs = outputs[0].view(-1, tokenizer.vocab_size)\n","        loss = criterion(outputs.reshape(-1, tokenizer.vocab_size), tgt[:, 1:].reshape(-1))\n","        loss /= GRADIENT_ACCUMULATION_STEPS  # divide loss by number of steps to average gradients\n","        loss.backward()\n","        if (i + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        train_loss += loss.item()\n","        # loss = criterion(outputs.logits.reshape(-1, tokenizer.vocab_size), tgt[:, 1:].reshape(-1))\n","        # loss.backward()\n","        # optimizer.step()\n","        # train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","\n"]},{"cell_type":"code","source":["    # Evaluate the model on the validation set\n","    bart_model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            src = batch['source_ids'].cuda()#.to(device)\n","            tgt = batch['target_ids'].cuda()#.to(device)\n","            \n","            outputs = bart_model.decoder.generate(input_ids=src, max_length=MAX_SEQ_LEN, num_beams=5)\n","            generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","            gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n","            print(outputs.shape)\n","            outputs = outputs[0].view(-1, outputs.shape[-1]).float()\n","            print(outputs.shape)\n","            outputs = F.log_softmax(outputs, dim=-1)\n","            # tgt = tgt[:, 1:].reshape(-1)\n","            # tgt = tgt[:, 1:].flatten()\n","            # tgt = tgt.flatten()#[:, 1:].reshape(-1)\n","            print(tgt.shape)\n","            # print((outputs.squeeze(0)).shape)\n","            loss = criterion(outputs.reshape(-1, outputs.shape[-1]), tgt[:, 1:]) #.reshape(-1)\n","            # loss = criterion(outputs.squeeze(0), tgt) #tgt[:, 1:].reshape(-1,1)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","\n","    # Print training and validation\n","    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"dxv_oIOPkAPE","executionInfo":{"status":"error","timestamp":1678172059886,"user_tz":480,"elapsed":4341,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"outputId":"fa607688-c132-4416-e52b-afaf54dddcf8"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 128])\n","torch.Size([1, 128])\n","torch.Size([16, 79])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-d322b2846bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print((outputs.squeeze(0)).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# loss = criterion(outputs.squeeze(0), tgt) #tgt[:, 1:].reshape(-1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (1248)."]}]},{"cell_type":"code","source":["# bart_model.eval()\n","# val_loss = 0\n","# with torch.no_grad():\n","#     for batch in val_loader:\n","#         src = batch['source_ids'].cuda()\n","#         tgt = batch['target_ids'].cuda()\n","\n","#         outputs = bart_model.decoder.generate(input_ids=src, max_length=MAX_SEQ_LEN, num_beams=5)\n","#         generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","#         gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n","\n","#         # Reshape the tensors to match\n","#         outputs = outputs[0].view(-1, outputs.shape[-1]).float()\n","#         outputs = F.log_softmax(outputs, dim=-1)\n","#         tgt = tgt[:, 1:].flatten()\n","\n","#         outputs = F.log_softmax(outputs, dim=-1)\n","#         loss = criterion(outputs, tgt)\n","#         val_loss += loss.item()\n","\n","# val_loss /= len(val_loader)\n","\n","# # Print training and validation\n","# print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"vh8_N-p8knFM","executionInfo":{"status":"error","timestamp":1678170261123,"user_tz":480,"elapsed":7634,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"outputId":"5e9c0616-5b52-4a8d-b3c0-a2772e34b36b"},"execution_count":40,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-2f71fb57c2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (1248)."]}]},{"cell_type":"code","source":["# # Evaluate the model on the validation set\n","# bart_model.eval()\n","# val_loss = 0\n","# with torch.no_grad():\n","#     for batch in val_loader:\n","#         src = batch['source_ids'].cuda()\n","#         tgt = batch['target_ids'].cuda()\n","\n","#         # print(src)\n","#         # print(tgt)\n","#         outputs = bart_model.decoder.generate(input_ids=src, max_length=MAX_SEQ_LEN, num_beams=5)\n","#         generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","#         gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n","\n","#         # Reshape the tensors to match\n","#         outputs = outputs[:, :tgt.shape[1]-1].reshape(-1, outputs.shape[-1])\n","#         tgt = tgt[:, 1:].reshape(-1)\n","        \n","#         print(outputs.shape)\n","#         print(tgt.shape)\n","\n","#         outputs = F.log_softmax(outputs, dim=-1)\n","#         loss = criterion(outputs, tgt)\n","#         val_loss += loss.item()\n","\n","# val_loss /= len(val_loader)\n","\n","# # Print training and validation\n","# print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":648},"id":"3lFg6mUaq4Xg","executionInfo":{"status":"error","timestamp":1678169182094,"user_tz":480,"elapsed":8613,"user":{"displayName":"Shivangi Pandey","userId":"03692652119201342747"}},"outputId":"115ff683-e465-4048-f024-455776dc88d6"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0, 24133,  5479,   698,     2,     1],\n","        [    0, 35868,  3118,  3414,     2,     1],\n","        [    0,   245, 24990, 37664,  2890,     2],\n","        [    0,  6232,  2890, 11670,  3118,     2],\n","        [    0, 29187,  1366,  5677,   612,     2],\n","        [    0, 11343, 41258,   466,  3416,     2],\n","        [    0, 38613,  4718,  1244,  3761,     2],\n","        [    0,  3367, 34248,  3706,  3083,     2],\n","        [    0, 40944,  1366,  4531,  1549,     2],\n","        [    0, 38714,  3414,  1646,  4429,     2],\n","        [    0,  4718, 12636,   406, 36192,     2],\n","        [    0, 40093,  5606,  1646,  2481,     2],\n","        [    0,   398, 35992,  5352,   996,     2],\n","        [    0,   996,   844,  3248, 40690,     2],\n","        [    0, 33333,  3546,  4563,  4718,     2],\n","        [    0, 31412,  2481,  6617,  1646,     2]], device='cuda:0')\n","tensor([[    0,   179,  1285,  ...,     1,     1,     1],\n","        [    0,   627,   177,  ...,     1,     1,     1],\n","        [    0,  2362,   233,  ...,     1,     1,     1],\n","        ...,\n","        [    0,   102,  1792,  ...,     1,     1,     1],\n","        [    0,   627,  7166,  ...,     1,     1,     1],\n","        [    0, 20094,  4832,  ...,     1,     1,     1]], device='cuda:0')\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-e9a9be8a5db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Reshape the tensors to match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 128]' is invalid for input of size 1248"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/datasci-w266/2023-spring-main/blob/master/assignment/a2/Text_classification.ipynb","timestamp":1675132484783}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f13f9f22b20a4dacabda267b46bf2863":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd8dbe9412eb4dba8b7bdc63b075fb75","IPY_MODEL_e15ea526a56a4d69b4d1dee84ad2ef00","IPY_MODEL_2baaa200432749e38146a7f84a98a50c"],"layout":"IPY_MODEL_fd70ca7b96994a2d8dddad129c33cc91"}},"dd8dbe9412eb4dba8b7bdc63b075fb75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6016500cd59042d286ce00e6218d14f6","placeholder":"​","style":"IPY_MODEL_0b1f439a8cad4b529422358a4cd80241","value":"Downloading (…)olve/main/vocab.json: 100%"}},"e15ea526a56a4d69b4d1dee84ad2ef00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef3a004161b4f18815cdfac7cd1a427","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b5d692d0f4441d1a96edb3226a02f82","value":898822}},"2baaa200432749e38146a7f84a98a50c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0505300bf74cd997b695c86557e67b","placeholder":"​","style":"IPY_MODEL_b77da4d519104f88938128f0ad985c81","value":" 899k/899k [00:01&lt;00:00, 815kB/s]"}},"fd70ca7b96994a2d8dddad129c33cc91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6016500cd59042d286ce00e6218d14f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b1f439a8cad4b529422358a4cd80241":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef3a004161b4f18815cdfac7cd1a427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b5d692d0f4441d1a96edb3226a02f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e0505300bf74cd997b695c86557e67b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b77da4d519104f88938128f0ad985c81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"094e9c45efe541738222081973869bdc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5a571d4f2044dd9aa5819f0343cf815","IPY_MODEL_5c1599cc23344cc1a69ccd33d564a0ce","IPY_MODEL_dbc85bb0110a417a9b4cac788ef2c53f"],"layout":"IPY_MODEL_1f9fbaf0f74949cf816c2142005cce29"}},"e5a571d4f2044dd9aa5819f0343cf815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b1b7dddf85840e78195d9a398a8f535","placeholder":"​","style":"IPY_MODEL_b9e887924b094fa09c33b0f4ecce749b","value":"Downloading (…)olve/main/merges.txt: 100%"}},"5c1599cc23344cc1a69ccd33d564a0ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ed068d1f4454ac2b54a107b9d8afa05","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a25d045dde241cc93eb4d6fa8e8fdef","value":456318}},"dbc85bb0110a417a9b4cac788ef2c53f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccdda58676f6447aabada206e6c8f943","placeholder":"​","style":"IPY_MODEL_a2ba1066d3e2474f8ae8ed403a5faa2e","value":" 456k/456k [00:00&lt;00:00, 515kB/s]"}},"1f9fbaf0f74949cf816c2142005cce29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b1b7dddf85840e78195d9a398a8f535":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e887924b094fa09c33b0f4ecce749b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ed068d1f4454ac2b54a107b9d8afa05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a25d045dde241cc93eb4d6fa8e8fdef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccdda58676f6447aabada206e6c8f943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ba1066d3e2474f8ae8ed403a5faa2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2f774e33e31458ca36c38abc5679a54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caddc1d4ed0e46f991891517593cab86","IPY_MODEL_4da5c64e863649bf8d4153aa7d38adcc","IPY_MODEL_8885ebe47f564f96a3e2f525321ae9d0"],"layout":"IPY_MODEL_9d4abe59ee4d46a3ad19bba91407608a"}},"caddc1d4ed0e46f991891517593cab86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_701ecae6379849e3bc76ce80b333577f","placeholder":"​","style":"IPY_MODEL_470ff62e1fb24fc686dfac8a15dd0820","value":"Downloading (…)okenizer_config.json: 100%"}},"4da5c64e863649bf8d4153aa7d38adcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e225894b3af642c590a10761961f92ca","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3fab536bfba4964975cf2a6857525d4","value":26}},"8885ebe47f564f96a3e2f525321ae9d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee3651c7537413b84f77e6beaa7d113","placeholder":"​","style":"IPY_MODEL_b1b69be5c28243beb8c97a4b40c98a61","value":" 26.0/26.0 [00:00&lt;00:00, 957B/s]"}},"9d4abe59ee4d46a3ad19bba91407608a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701ecae6379849e3bc76ce80b333577f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470ff62e1fb24fc686dfac8a15dd0820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e225894b3af642c590a10761961f92ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3fab536bfba4964975cf2a6857525d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ee3651c7537413b84f77e6beaa7d113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b69be5c28243beb8c97a4b40c98a61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f499f681469f4545b2ba2b8576b367a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a2b38ad64c84879b940b79f0583c86e","IPY_MODEL_7be02108c73e4c7c9f7e9038a6203d6d","IPY_MODEL_fa4d6a89605b4d7e8e11097604348508"],"layout":"IPY_MODEL_ce1272a7039a4075bae46382c9ca9dcc"}},"1a2b38ad64c84879b940b79f0583c86e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e7a378374ba47fa80f4668c1c8f17a6","placeholder":"​","style":"IPY_MODEL_2f87cc3eb14a42d1b53a29f20641f34a","value":"Downloading (…)lve/main/config.json: 100%"}},"7be02108c73e4c7c9f7e9038a6203d6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3defad5a35543db90b0f6ff84caa1b2","max":1628,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b6e95513c22417c8d35777a3b6be79f","value":1628}},"fa4d6a89605b4d7e8e11097604348508":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f33f39c71a904b8cad865c41385b4872","placeholder":"​","style":"IPY_MODEL_4e7f9a3b98fc4749af66d5d3a34f854a","value":" 1.63k/1.63k [00:00&lt;00:00, 55.0kB/s]"}},"ce1272a7039a4075bae46382c9ca9dcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7a378374ba47fa80f4668c1c8f17a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f87cc3eb14a42d1b53a29f20641f34a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3defad5a35543db90b0f6ff84caa1b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b6e95513c22417c8d35777a3b6be79f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f33f39c71a904b8cad865c41385b4872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e7f9a3b98fc4749af66d5d3a34f854a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}