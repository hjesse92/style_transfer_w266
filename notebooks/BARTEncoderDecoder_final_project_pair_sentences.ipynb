{"cells":[{"cell_type":"markdown","metadata":{"id":"so-yur1S9mS4"},"source":["## 1. Setup\n","\n","### 1.1. Libraries and Helper Functions\n","\n","This notebook requires the TensorFlow dataset and other prerequisites that you must download. "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uQnMctL9mS5","outputId":"091f9ca3-60c9-45d4-e123-0dc3f96c95a3","executionInfo":{"status":"ok","timestamp":1679267274868,"user_tz":420,"elapsed":35376,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["#@title Installs\n","!pip install transformers --quiet\n","!pip install tqdm boto3 requests regex sentencepiece sacremoses evaluate --quiet\n","!pip install rouge --quiet"]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"j0jokLO9GqZp"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"7CALja8vLcZ9","executionInfo":{"status":"ok","timestamp":1679267291833,"user_tz":420,"elapsed":8166,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"outputs":[],"source":["import torch\n","import pandas as pd\n","from tqdm import tqdm\n","# upload external file before import\n","from google.colab import files\n","\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from transformers import DistilBertTokenizer, DistilBertModel\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from rouge import Rouge \n","from nltk.translate.bleu_score import sentence_bleu\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import time\n","import datetime\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cbELEg_S5iX","outputId":"833335ab-14ec-4472-fdff-15c00f9cd64a","executionInfo":{"status":"ok","timestamp":1679267298179,"user_tz":420,"elapsed":1183,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":4}],"source":["# Check if a GPU is available, otherwise use CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","source":["def format_time(seconds):\n","    return str(datetime.timedelta(seconds=int(round(seconds))))"],"metadata":{"id":"bPOLNWdswB85","executionInfo":{"status":"ok","timestamp":1679267298182,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnqrYaGuxo3M","outputId":"9da98e5f-6735-4ca0-87c0-fd0c8ae8231a","executionInfo":{"status":"ok","timestamp":1679267330969,"user_tz":420,"elapsed":29946,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCThYsKtyrOn","outputId":"869fb92a-7e52-4664-9525-f62c9df22c9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["clean_dev.csv\tclean_train.csv   original-test.tsv   test.csv\n","clean_test.csv\toriginal-dev.tsv  original-train.tsv  train.csv\n"]}],"source":["!ls \"/content/drive/MyDrive/Colab Notebooks/data\""]},{"cell_type":"code","source":["train_path='/content/drive/MyDrive/Colab Notebooks/data/original-train.tsv'\n","dev_path='/content/drive/MyDrive/Colab Notebooks/data/original-dev.tsv'\n","test_path='/content/drive/MyDrive/Colab Notebooks/data/original-test.tsv'"],"metadata":{"id":"gMBfqnnShB06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train=pd.read_csv(train_path,sep=\"\\t\", header=0) \n","display(train[1:])"],"metadata":{"id":"7mzdBizMi1gj","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"984a0244-5cda-40db-c902-1609607c0a25"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                         offensive-text  \\\n","1     Ok, this makes no sense. This will create vigi...   \n","2     so fucking true. the amount of up and coming r...   \n","3     Go f yourself Republican scum who put us here ...   \n","4          Dumb fucking take. People want to do things.   \n","5                                             Fuck no 😂   \n","...                                                 ...   \n","1579  The View! And this crap hits my front page!? l...   \n","1580                                     That’s racist.   \n","1581     Cultural Marxism isn't a thing you weird fuck.   \n","1582  LOL, anyone that questions the Democrat progra...   \n","1583  How about you guys actually read the bill, if ...   \n","\n","                                 style-transferred-text  \n","1     Ok, this makes no sense. This will create vigi...  \n","2     so true. the amount of up and coming rappers t...  \n","3     Republicans put us in this situation. I would ...  \n","4     That's not a smart take. People want to do thi...  \n","5                                                    no  \n","...                                                 ...  \n","1579  This must be mostly bots but still, it's stran...  \n","1580                          Those actions are racist.  \n","1581                    Cultural Marxism isn't a thing.  \n","1582  LOL, anyone that questions the Democrat progra...  \n","1583            I wish everyone actually read the bill.  \n","\n","[1583 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-88b9a999-0723-4f76-a798-c1c4048c9377\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Ok, this makes no sense. This will create vigi...</td>\n","      <td>Ok, this makes no sense. This will create vigi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>so fucking true. the amount of up and coming r...</td>\n","      <td>so true. the amount of up and coming rappers t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go f yourself Republican scum who put us here ...</td>\n","      <td>Republicans put us in this situation. I would ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dumb fucking take. People want to do things.</td>\n","      <td>That's not a smart take. People want to do thi...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Fuck no 😂</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1579</th>\n","      <td>The View! And this crap hits my front page!? l...</td>\n","      <td>This must be mostly bots but still, it's stran...</td>\n","    </tr>\n","    <tr>\n","      <th>1580</th>\n","      <td>That’s racist.</td>\n","      <td>Those actions are racist.</td>\n","    </tr>\n","    <tr>\n","      <th>1581</th>\n","      <td>Cultural Marxism isn't a thing you weird fuck.</td>\n","      <td>Cultural Marxism isn't a thing.</td>\n","    </tr>\n","    <tr>\n","      <th>1582</th>\n","      <td>LOL, anyone that questions the Democrat progra...</td>\n","      <td>LOL, anyone that questions the Democrat progra...</td>\n","    </tr>\n","    <tr>\n","      <th>1583</th>\n","      <td>How about you guys actually read the bill, if ...</td>\n","      <td>I wish everyone actually read the bill.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1583 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88b9a999-0723-4f76-a798-c1c4048c9377')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-88b9a999-0723-4f76-a798-c1c4048c9377 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-88b9a999-0723-4f76-a798-c1c4048c9377');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niEwhBdNFnxW","outputId":"e5321aa1-6ff8-4aba-9b08-a63b6a69f53d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["238"]},"metadata":{},"execution_count":8}],"source":["train['offensive-text'].str.len().max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2MqDpHEGNyi","outputId":"730d9f87-a511-465f-edba-40f40fa23460"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":9}],"source":["train['offensive-text'].str.len().min()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBfPJTp0Tg6T","outputId":"e27e4ed8-20fe-4924-d62d-7272a1b208bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["69.85353535353535"]},"metadata":{},"execution_count":10}],"source":["train['offensive-text'].str.len().mean()"]},{"cell_type":"code","source":["train[train['style-transferred-text']=='']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"id":"i8Qz4GMUDCV3","outputId":"8204df17-de4c-464f-8a87-3864ee9a522e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [offensive-text, style-transferred-text]\n","Index: []"],"text/html":["\n","  <div id=\"df-de4d9940-1353-478b-a621-e55ad3f3ae94\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de4d9940-1353-478b-a621-e55ad3f3ae94')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-de4d9940-1353-478b-a621-e55ad3f3ae94 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-de4d9940-1353-478b-a621-e55ad3f3ae94');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["test=pd.read_csv(test_path,sep=\"\\t\", header=0) \n","display(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"GZEMCYhu89Rx","outputId":"7dbdc4c5-8ff5-4520-aabb-15a88fba01f2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                        offensive-text  \\\n","0                So maybe you should be more retarded.   \n","1    THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...   \n","2                        the fuck.... you are on drugs   \n","3    NTA.   Dump his ass. Tablemanners are no rocke...   \n","4                              Youre soft as baby shit   \n","..                                                 ...   \n","194  NTA, Jes-us your brother is dumb. How long did...   \n","195  Formula one…nascar….shit it exactly the same e...   \n","196  BRB, gonna go call the mods pathetic egotistic...   \n","197                       CUCKOLD Carlson is a problem   \n","198                I think you need to check your head   \n","\n","                                style-transferred-text  \n","0                 So maybe you should be more backward  \n","1    THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...  \n","2                  uh..... you are not being realistic  \n","3    You should leave him. Tablemanners are no rock...  \n","4                                    Youre really soft  \n","..                                                 ...  \n","194  NTA, your brother is not thinking straight. Ho...  \n","195  Formula one…nascar….it exactly the same except...  \n","196                       BRB, gonna go call the mods.  \n","197                             Carlson is the problem  \n","198                 I think you need to check yourself  \n","\n","[199 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f16f8e08-0fb7-4dc4-90c8-216bc5a2a3fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>So maybe you should be more retarded.</td>\n","      <td>So maybe you should be more backward</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...</td>\n","      <td>THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the fuck.... you are on drugs</td>\n","      <td>uh..... you are not being realistic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NTA.   Dump his ass. Tablemanners are no rocke...</td>\n","      <td>You should leave him. Tablemanners are no rock...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Youre soft as baby shit</td>\n","      <td>Youre really soft</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>NTA, Jes-us your brother is dumb. How long did...</td>\n","      <td>NTA, your brother is not thinking straight. Ho...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Formula one…nascar….shit it exactly the same e...</td>\n","      <td>Formula one…nascar….it exactly the same except...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>BRB, gonna go call the mods pathetic egotistic...</td>\n","      <td>BRB, gonna go call the mods.</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>CUCKOLD Carlson is a problem</td>\n","      <td>Carlson is the problem</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>I think you need to check your head</td>\n","      <td>I think you need to check yourself</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>199 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f16f8e08-0fb7-4dc4-90c8-216bc5a2a3fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f16f8e08-0fb7-4dc4-90c8-216bc5a2a3fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f16f8e08-0fb7-4dc4-90c8-216bc5a2a3fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["dev=pd.read_csv(dev_path,sep=\"\\t\", header=0) \n","display(dev)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"rJ-0TJFCChu5","outputId":"48a078b1-5465-48a0-8c6d-e615138bb7c4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                        offensive-text  \\\n","0    Anyone who thinks canceling a pipeline and han...   \n","1    My favorite part is that you’re still madly re...   \n","2    But did you try it? Lol. That and medical mari...   \n","3    By the downvotes, I see there are a bunch of u...   \n","4                         CUCKOLD Carlson is a problem   \n","..                                                 ...   \n","193                             Karma whore right here   \n","194  Anyone who is still huffing paint thinner by c...   \n","195         And you have never made a stupid decision?   \n","196  You couldn't maybe just think about this for a...   \n","197  Where the fuck are the mods? Seriously this is...   \n","\n","                                style-transferred-text  \n","0    Anyone who thinks canceling a pipeline and han...  \n","1     My favorite part is that you are still replying.  \n","2    Have you tried it? That helped my cousin's tin...  \n","3    By the downvotes, I see there are a bunch of T...  \n","4                               Carlson is the problem  \n","..                                                 ...  \n","193                       Hunting for karma right here  \n","194  Anyone who is still huffing paint thinner by c...  \n","195          And you have never made a wrong decision?  \n","196  You couldn't maybe just come up with the answe...  \n","197  Where are the mods? Seriously this is the most...  \n","\n","[198 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-abf7dd4e-d114-4bf9-a0ba-0ae7f4292f1d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Anyone who thinks canceling a pipeline and han...</td>\n","      <td>Anyone who thinks canceling a pipeline and han...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>My favorite part is that you’re still madly re...</td>\n","      <td>My favorite part is that you are still replying.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>But did you try it? Lol. That and medical mari...</td>\n","      <td>Have you tried it? That helped my cousin's tin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>By the downvotes, I see there are a bunch of u...</td>\n","      <td>By the downvotes, I see there are a bunch of T...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CUCKOLD Carlson is a problem</td>\n","      <td>Carlson is the problem</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>Karma whore right here</td>\n","      <td>Hunting for karma right here</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>Anyone who is still huffing paint thinner by c...</td>\n","      <td>Anyone who is still huffing paint thinner by c...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>And you have never made a stupid decision?</td>\n","      <td>And you have never made a wrong decision?</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>You couldn't maybe just think about this for a...</td>\n","      <td>You couldn't maybe just come up with the answe...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>Where the fuck are the mods? Seriously this is...</td>\n","      <td>Where are the mods? Seriously this is the most...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>198 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abf7dd4e-d114-4bf9-a0ba-0ae7f4292f1d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-abf7dd4e-d114-4bf9-a0ba-0ae7f4292f1d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-abf7dd4e-d114-4bf9-a0ba-0ae7f4292f1d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["import string\n","import regex as re\n","def read_process_data(df):\n","    # SPECIAL_CHARS_PATTERN = re.compile(r\"(\\*)|(\\=\\=)|(\\~)|(\\=)|(\\.\\.\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\|)|()|()|(\\%)|($)|(\\>)|(\\<)|(\\{)|(\\})\")\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.lower()\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n","\n","    df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \") #\\n|\\r|\\r\\n|\n","\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.lower()\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \")\n","  \n","    df['offensive-text']=df['offensive-text'].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n","    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n","\n","    print('The null count :: ',df.isnull().sum())\n","    return df"],"metadata":{"id":"5d13W9myt0w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x=read_process_data(train)\n","display(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"h1sOu0-tufhH","outputId":"c6f1e80a-1717-4ca6-84ee-49d927ed65b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The null count ::  offensive-text            0\n","style-transferred-text    0\n","dtype: int64\n"]},{"output_type":"display_data","data":{"text/plain":["                                         offensive-text  \\\n","0                     pussy nobody asked for your input   \n","1     ok this makes no sense this will create vigila...   \n","2     so fucking true the amount of up and coming ra...   \n","3     go f yourself republican scum who put us here ...   \n","4            dumb fucking take people want to do things   \n","...                                                 ...   \n","1579  the view and this crap hits my front page lmfa...   \n","1580                                       thats racist   \n","1581      cultural marxism isn t a thing you weird fuck   \n","1582  lol anyone that questions the democrat program...   \n","1583  how about you guys actually read the bill if y...   \n","\n","                                 style-transferred-text  \n","0                           nobody asked for your input  \n","1     ok this makes no sense this will create vigila...  \n","2     so true the amount of up and coming rappers th...  \n","3     republicans put us in this situation i would w...  \n","4      that s not a smart take people want to do things  \n","...                                                 ...  \n","1579  this must be mostly bots but still it s strang...  \n","1580                           those actions are racist  \n","1581                     cultural marxism isn t a thing  \n","1582  lol anyone that questions the democrat program...  \n","1583             i wish everyone actually read the bill  \n","\n","[1584 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-c5b29bb8-f320-4990-987c-9eb9be6ab4d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>offensive-text</th>\n","      <th>style-transferred-text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>pussy nobody asked for your input</td>\n","      <td>nobody asked for your input</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ok this makes no sense this will create vigila...</td>\n","      <td>ok this makes no sense this will create vigila...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>so fucking true the amount of up and coming ra...</td>\n","      <td>so true the amount of up and coming rappers th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>go f yourself republican scum who put us here ...</td>\n","      <td>republicans put us in this situation i would w...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dumb fucking take people want to do things</td>\n","      <td>that s not a smart take people want to do things</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1579</th>\n","      <td>the view and this crap hits my front page lmfa...</td>\n","      <td>this must be mostly bots but still it s strang...</td>\n","    </tr>\n","    <tr>\n","      <th>1580</th>\n","      <td>thats racist</td>\n","      <td>those actions are racist</td>\n","    </tr>\n","    <tr>\n","      <th>1581</th>\n","      <td>cultural marxism isn t a thing you weird fuck</td>\n","      <td>cultural marxism isn t a thing</td>\n","    </tr>\n","    <tr>\n","      <th>1582</th>\n","      <td>lol anyone that questions the democrat program...</td>\n","      <td>lol anyone that questions the democrat program...</td>\n","    </tr>\n","    <tr>\n","      <th>1583</th>\n","      <td>how about you guys actually read the bill if y...</td>\n","      <td>i wish everyone actually read the bill</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1584 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b29bb8-f320-4990-987c-9eb9be6ab4d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c5b29bb8-f320-4990-987c-9eb9be6ab4d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c5b29bb8-f320-4990-987c-9eb9be6ab4d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["x.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_train.csv', header = False)\n"],"metadata":{"id":"tp8w26y7z9eY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x=read_process_data(test)\n","x.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_test.csv', header = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zll66uRT0wF3","outputId":"b8b23e45-9c6d-4c7e-b481-8644d7fe295d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The null count ::  offensive-text            0\n","style-transferred-text    0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["x=read_process_data(dev)\n","x.to_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_dev.csv', header = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTTtWGLt1VbD","outputId":"20633ee9-9bc1-4477-ddb6-170238cb30ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The null count ::  offensive-text            0\n","style-transferred-text    0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["train_path='/content/drive/MyDrive/Colab Notebooks/data/clean_train.csv'\n","dev_path='/content/drive/MyDrive/Colab Notebooks/data/clean_dev.csv'\n","test_path='/content/drive/MyDrive/Colab Notebooks/data/clean_test.csv'"],"metadata":{"id":"94gfhdG80nt5","executionInfo":{"status":"ok","timestamp":1679267330970,"user_tz":420,"elapsed":10,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oeRVnvQ10d1K"},"source":["Below code is implementation of BART (Bidirectional and Auto-Regressive Transformer) model for sequence-to-sequence (seq2seq) tasks using PyTorch. The BART model is a variant of the Transformer model and is pre-trained on a large corpus of text data using a denoising autoencoder objective. It is capable of generating high-quality text with coherent sentence structures.\n","\n","The code defines a PyTorch Dataset class MyDataset that reads the input and target text sequences from a text file and tokenizes them using the BART tokenizer. It then defines the collate_fn function to pad the sequences in each batch to the same length. The code then defines the BartEncoderDecoder class, which is the main model class that uses the BART encoder and decoder architecture.\n","\n","The code instantiates the BART tokenizer and the BartEncoderDecoder model, and loads the training and validation data using the MyDataset class. It also defines the optimizer and loss function. The code then runs the training loop for a specified number of epochs, during which it trains the model on the training set and evaluates it on the validation set.\n","\n","During training, the code iterates over the batches of training data and performs forward and backward passes through the model to compute the loss and update the model parameters using the Adam optimizer. The code also implements gradient accumulation by accumulating the gradients over a specified number of batches to reduce the memory requirements during training. After training on all the batches, the code computes the average loss over the entire training set and evaluates the model on the validation set.\n","\n","During validation, the code iterates over the batches of validation data and generates the predicted text sequences using the generate method of the BART decoder. It then computes the loss between the predicted and target sequences and accumulates the loss over all the batches to compute the average loss over the entire validation set. Finally, the code prints the average training and validation loss for each epoch."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6olz1mhT-ovf","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["b69be31f5fb149439a24993a439a9d38","ab11d7e884244bddb0788d8756ce2738","2a65bcddc1814b21979aa81aab403791","18bb04646fda4b15966aa55319c3e68d","6407a563ae7548fa864fb25c3c4150b6","ff35596ab5694974927e3423c3b949ae","519f4fb921f84db6b00aff550f0f8ef5","eb9f5fe70f0545608868629eace167cc","1ef965c9468f474daac37eb05070c25a","fe67ed2807164a46987206140fe1ce2d","13b5b78fbd7e4891a7bd12b75959d68e","abd7eb5376f743acb4561d68f03ab182","e038632b529b42528e0d4133acaa93ab","a05189dbb05b4a299bff1cbc866ef971","4cf84d9d3d3c41e18e0124ba1dcab703","b8932123fe5844eeae163fd56c2000e9","8a9e8c2ed54340269589531e8b358589","9d21fe3f1f8d45ed99c14942744e248e","2075efe3dbc84d74b952098924b9ef77","43bccf112aa44ca29629059ac7ad15f5","c580c5cd4717476e88af0764163aafcd","68bd169a0d1046acab4026a691b6bb86","8753ca26301a4528bb4d5151a7f84c85","3bf35c62d4fd466b977e55abafd9d4bb","937e475849034a8aba7316f8f93442ed","2da161b715b74d01ba43de99e24e1a26","f85824f59e4849f788892a83313c0d49","5c84b56ae7cf4e0a802095b58b6778dd","56201afcc93c46d58c8eabf5992ea97c","f7cdecdcb3ce42409beceeefbc2176bf","776dccd4f64f4ee896282f0ded9ce3c5","02b0c5850cb34d9ba379ee1be617562e","bc7d0f3ae3f84ab09f43c99ff38632a8","51c317efff0445179f80feb67fc1c3bc","387a81cc4f9641cb915c7f535fbe8237","ca7c7964dc8947b09d43faae4f669567","daafdd68bcde439aaeca4af2cf6650db","bcd6ef30bb2e45e4a06d25b7d41699d8","5ff802333c1b42e2960b84a3fa241cdc","09a56244a41a4cb8819cd2f5dcb3fa65","0728ff82b36a4e37804cb78f206e303a","e4dec7f9dcc04b638efc94011f908426","2ead1ad0b47e4f3cb5ba69000745ca8e","dc2e4ac6df04464cbde84ac31dd14c15"]},"executionInfo":{"status":"ok","timestamp":1679267351207,"user_tz":420,"elapsed":12243,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}},"outputId":"9f534f46-a586-4764-8eb4-4ad17f69ebc5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b69be31f5fb149439a24993a439a9d38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd7eb5376f743acb4561d68f03ab182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8753ca26301a4528bb4d5151a7f84c85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c317efff0445179f80feb67fc1c3bc"}},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import Adam\n","from transformers import BartTokenizer, BartConfig, BartForConditionalGeneration,BartModel\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","# the MyDataset class takes three arguments:\n","\n","# data_path: The path to the training data file.\n","# tokenizer: The tokenizer used to preprocess the input data.\n","# max_seq_len: The maximum sequence length allowed for the input sequences.\n","# In the __init__ method, the training data is loaded from the specified file, and each line of text is stored in a list.\n","\n","# In the __len__ method, the length of the dataset is returned (i.e., the number of lines in the training data file).\n","\n","# In the __getitem__ method, an individual training example is retrieved based on the specified index. The input text is tokenized using the specified tokenizer and truncated to the specified maximum sequence length, and the resulting token ids are converted to a PyTorch tensor and returned as the training example.\n","\n","# Instantiate BART tokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', do_lower_case=True, max_length=512)\n","\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path, max_seq_len,kind):\n","        \n","        self.max_seq_len = max_seq_len\n","\n","        self.toxic_ids = []\n","        self.non_toxic_ids = []\n","        c=0\n","        with open(data_path, 'r') as f:\n","            for line in f:\n","                line = line.strip()\n","                if line:\n","                    parts = line.split(',')\n","                    toxic_seq = parts[1]\n","                    non_toxic_seq = parts[2]\n","\n","                    toxic_ids = tokenizer.encode(\n","                        toxic_seq, add_special_tokens=True, truncation=True,\n","                        max_length=max_seq_len\n","                    )\n","                    non_toxic_ids = tokenizer.encode(\n","                        non_toxic_seq, add_special_tokens=True, truncation=True,\n","                        max_length=max_seq_len\n","                    )\n","                    self.toxic_ids.append(toxic_ids)\n","                    self.non_toxic_ids.append(non_toxic_ids)\n","                    \n","                    if c==0:\n","                      print('\\n',kind,' dataset preview .....')\n","                      print('*******************************************')\n","                      print('Input :: toxic ::',toxic_seq)\n","                      print('Input :: non toxic ::',non_toxic_seq)\n","                      print('encoded length toxic :',toxic_ids)\n","                      print('encoded length non toxic: ',non_toxic_ids)\n","                      print('*******************************************')\n","                    c=c+1\n","            print('total number of',kind,' data processed : ',c)\n","\n","    def __len__(self):\n","        return len(self.toxic_ids)\n","\n","    def __getitem__(self, index):\n","        toxic_ids = self.toxic_ids[index]\n","        non_toxic_ids = self.non_toxic_ids[index]\n","\n","        # Create a PyTorch tensor from the tokenized sequences\n","        toxic_ids = torch.tensor(toxic_ids)\n","        non_toxic_ids = torch.tensor(non_toxic_ids)\n","\n","        return {'toxic_ids': toxic_ids, 'non_toxic_ids': non_toxic_ids}\n"]},{"cell_type":"code","source":["#uncomment if memory issue happens. This will free up some space\n","# import torch\n","# torch.cuda.empty_cache()"],"metadata":{"id":"I-Ck9Yi_uCL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TYQd-fO70q4z","executionInfo":{"status":"ok","timestamp":1679267362710,"user_tz":420,"elapsed":10978,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"outputs":[],"source":["# Define hyperparameters\n","\n","BATCH_SIZE = 100 #4\n","NUM_EPOCHS = 4\n","LEARNING_RATE = 2e-5 #5e-5 #2e-4\n","WEIGHT_DECAY = 2e-5\n","MAX_SEQ_LEN = 128\n","D_MODEL = 256 #dimensionality of the input and output vectors of the Transformer model. It is also commonly referred to as the \"hidden size\" of the model.POWER OF 2\n","NUM_HEADS = 4 #8 #number of attention heads used in multi-head attention (D_MODEL/NUM_HEADS=INT)\n","NUM_ENCODER_LAYERS = 4\n","NUM_DECODER_LAYERS = 1\n","DIM_FEEDFORWARD = 1024 #(4 times of D_MODEL)\n","DROPOUT = 0.3\n","GRADIENT_ACCUMULATION_STEPS = 2 #2  # accumulate gradients over 2 batches\n","HIDDEN_SIZE = 768\n","\n","# Define BART encoder-decoder model\n","class BartEncoderDecoder(nn.Module):\n","    def __init__(self, bart_config):\n","        super().__init__()\n","        self.encoder = BartModel(bart_config) #The bare BART Model outputting raw hidden-states without any specific head on top.\n","        self.decoder = BartForConditionalGeneration(bart_config) #The BART Model with a language modeling head. Can be used for summarization.\n","        \n","    def forward(self, input_ids, decoder_input_ids):\n","        encoder_outputs = self.encoder(input_ids=input_ids)\n","        decoder_outputs = self.decoder(input_ids=decoder_input_ids,encoder_outputs=encoder_outputs)\n","        return decoder_outputs\n","\n","# Instantiate BART encoder-decoder model\n","bart_config = BartConfig(d_model=D_MODEL, encoder_layers=NUM_ENCODER_LAYERS, decoder_layers=NUM_DECODER_LAYERS, \n","                         encoder_attention_heads=NUM_HEADS, decoder_attention_heads=NUM_HEADS,\n","                         encoder_ffn_dim=DIM_FEEDFORWARD, decoder_ffn_dim=DIM_FEEDFORWARD, dropout=DROPOUT, hidden_size=HIDDEN_SIZE) #\n","bart_model = BartEncoderDecoder(bart_config).cuda() # move the model to CUDA"]},{"cell_type":"code","source":["\n","def loss_fn(outputs, targets, source_embeddings, target_embeddings):\n","    batch_size, seq_len, hidden_size = outputs.shape\n","    # Reshape the outputs tensor to (batch_size * seq_len, hidden_size)\n","    outputs = outputs.reshape(batch_size * seq_len, hidden_size)\n","    # Compute the cross-entropy loss\n","    ce_loss = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)(outputs, targets.view(-1))\n","    # Compute the similarity loss\n","    sim_loss = 1 - nn.CosineSimilarity(dim=1)(source_embeddings, target_embeddings)\n","    return ce_loss + sim_loss\n","\n","def collate_fn(batch, batch_size=BATCH_SIZE):\n","    # Pad sequences in batch to have the same length\n","    toxic_ids = pad_sequence([item['toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","    non_toxic_ids = pad_sequence([item['non_toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    # Split data into batches of the desired size\n","    num_batches = len(batch) // batch_size\n","    if len(batch) % batch_size != 0:\n","        num_batches += 1\n","    toxic_batches = list(torch.split(toxic_ids[:num_batches*batch_size], batch_size))\n","    non_toxic_batches = list(torch.split(non_toxic_ids[:num_batches*batch_size], batch_size))\n","\n","    # Pad the last batch to ensure that all batches have the same size\n","    if len(toxic_batches[-1]) < batch_size:\n","        toxic_batches[-1] = nn.functional.pad(toxic_batches[-1], (0, 0, 0, batch_size - len(toxic_batches[-1])), value=tokenizer.pad_token_id)\n","        non_toxic_batches[-1] = nn.functional.pad(non_toxic_batches[-1], (0, 0, 0, batch_size - len(non_toxic_batches[-1])), value=tokenizer.pad_token_id)\n","\n","    return [{'toxic_ids': t, 'non_toxic_ids': nt} for t, nt in zip(toxic_batches, non_toxic_batches)][0]"],"metadata":{"id":"r2hZfkqE9c2I","executionInfo":{"status":"ok","timestamp":1679267362714,"user_tz":420,"elapsed":14,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["bart_model"],"metadata":{"id":"2T65jPqJVe3H","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8077b3c5-a2a4-4dec-f6a4-0750c00f7b5e","executionInfo":{"status":"ok","timestamp":1679267373299,"user_tz":420,"elapsed":355,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartEncoderDecoder(\n","  (encoder): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (decoder): BartForConditionalGeneration(\n","    (model): BartModel(\n","      (shared): Embedding(50265, 768, padding_idx=1)\n","      (encoder): BartEncoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","            (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","            (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","            (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","            (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (decoder): BartDecoder(\n","        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","        (layers): ModuleList(\n","          (0): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=1024, bias=True)\n","            (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["In the line source_embeddings = bart_model.encoder(input_ids=src)[0][:, 0, :], bart_model.encoder(input_ids=src) applies the BART encoder to the input sequence src and returns a tuple of encoder hidden states, attention weights, and the final hidden state of the last layer.\n","\n","The [0] at the end of the function call accesses only the encoder hidden states from the tuple. The [:, 0, :] at the end selects the first token embedding for each input sequence in the batch. The first dimension : means that we want all the input sequences in the batch. The second dimension 0 selects only the first token embedding for each sequence, and the third dimension : selects all the features (or dimensions) in the embedding vector.\n","\n","The first token embedding is often referred to as the \"CLS\" token embedding, and it typically contains information about the overall sequence, which is useful for tasks such as sequence classification or sentence pair classification. In this case, the first token embedding is used to compute the similarity loss between the source and target embeddings."],"metadata":{"id":"5vPomRZ10PuP"}},{"cell_type":"code","source":["# Load training and validation data\n","train_data = MyDataset(train_path, MAX_SEQ_LEN,'training')\n","val_data = MyDataset(dev_path, MAX_SEQ_LEN,'validation')\n","\n","print('Instatiating Data loaders for training and validation dataset ......')\n","# Instantiate data loaders\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,collate_fn=collate_fn)\n","val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n","\n","def train(train_loader,learning_rate=LEARNING_RATE, epochs=NUM_EPOCHS, verbose=True):\n","\n","  # Instantiate optimizer and loss function\n","  optimizer = Adam(bart_model.parameters(), lr=learning_rate) #, weight_decay=WEIGHT_DECAY\n","  train_losses=[]\n","  \n","  print('\\nTokenizer information :: ')\n","  print('eos_token_id :',tokenizer.eos_token_id)\n","  print('pad_token_id :',tokenizer.pad_token_id)\n","  print('bos_token_id :', tokenizer.bos_token_id,'\\n')\n","\n","  # start time\n","  t0 = time.time()\n","  volume=0\n","  number_of_records_in_train_dataset=len([i for i in train_data])\n","  # Training loop\n","  for epoch in range(epochs):\n","      print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n","      \n","      # Train the model\n","      bart_model.train()\n","      train_loss = 0\n","      epoch_loss=0\n","      for step, batch in enumerate(train_loader):\n","          src = batch['toxic_ids'].cuda()\n","          tgt = batch['non_toxic_ids'].cuda()\n","          \n","          volume+=len(src)\n","          optimizer.zero_grad()\n","          encoder_outputs = bart_model.encoder(input_ids=src)\n","          source_embeddings = encoder_outputs.last_hidden_state.mean(dim=1)\n","          target_embeddings = bart_model.encoder(input_ids=tgt)[0][:, 0, :]\n","          \n","          outputs = bart_model(input_ids=src, decoder_input_ids=tgt[:, :-1].cuda())\n","          loss = loss_fn(outputs.logits, tgt[:, 1:].reshape(-1).cuda(), source_embeddings, target_embeddings)\n","          loss = loss.mean() # reduce the loss tensor to a scalar tensor by taking the mean\n","          loss /= GRADIENT_ACCUMULATION_STEPS\n","\n","          loss.backward()\n","          if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","          epoch_loss += loss.item()\n","\n","          # Report progress every batch\n","          if verbose and step % 10 == 0:\n","              print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(train_loader), loss.item()))\n","\n","      avg_loss = epoch_loss / len(train_loader)\n","      train_losses.append(avg_loss)\n","\n","      elapsed_time = time.time() - t0\n","      if verbose:\n","          print('Epoch [{}/{}], Average Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n","\n","  return train_losses, sum(train_losses) / len(train_losses)\n","\n","train_losses,avg_loss=train(train_loader)"],"metadata":{"id":"kNySrGWAVZM5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b97b296-790b-4f5e-e910-6bcf1a72a0ff","executionInfo":{"status":"ok","timestamp":1679267430721,"user_tz":420,"elapsed":49675,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," training  dataset preview .....\n","*******************************************\n","Input :: toxic :: pussy nobody asked for your input\n","Input :: non toxic :: nobody asked for your input\n","encoded length toxic : [0, 642, 28102, 5907, 553, 13, 110, 8135, 2]\n","encoded length non toxic:  [0, 33212, 9956, 553, 13, 110, 8135, 2]\n","*******************************************\n","total number of training  data processed :  1584\n","\n"," validation  dataset preview .....\n","*******************************************\n","Input :: toxic :: anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is a fucking moron\n","Input :: non toxic :: anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is not thinking about this\n","encoded length toxic : [0, 3785, 1264, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 201, 74, 33, 117, 1683, 15, 1123, 850, 16, 10, 23523, 14628, 261, 2]\n","encoded length non toxic:  [0, 3785, 1264, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 201, 74, 33, 117, 1683, 15, 1123, 850, 16, 45, 2053, 59, 42, 2]\n","*******************************************\n","total number of validation  data processed :  198\n","Instatiating Data loaders for training and validation dataset ......\n","\n","Tokenizer information :: \n","eos_token_id : 2\n","pad_token_id : 1\n","bos_token_id : 0 \n","\n","######  Epoch 1/4 ######\n","Epoch [1/4], Step [1/16], Loss: 5.9282\n","Epoch [1/4], Step [11/16], Loss: 5.7603\n","Epoch [1/4], Average Loss: 5.8230, Elapsed Time: 0:00:13\n","######  Epoch 2/4 ######\n","Epoch [2/4], Step [1/16], Loss: 5.7199\n","Epoch [2/4], Step [11/16], Loss: 5.5741\n","Epoch [2/4], Average Loss: 5.6155, Elapsed Time: 0:00:24\n","######  Epoch 3/4 ######\n","Epoch [3/4], Step [1/16], Loss: 5.5030\n","Epoch [3/4], Step [11/16], Loss: 5.4035\n","Epoch [3/4], Average Loss: 5.4353, Elapsed Time: 0:00:35\n","######  Epoch 4/4 ######\n","Epoch [4/4], Step [1/16], Loss: 5.3214\n","Epoch [4/4], Step [11/16], Loss: 5.2146\n","Epoch [4/4], Average Loss: 5.2419, Elapsed Time: 0:00:46\n"]}]},{"cell_type":"code","source":["print('number of records :',len(train_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_F09xXl4Tsa","outputId":"e334377d-0915-4e27-feea-750398f560f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of records : 16\n"]}]},{"cell_type":"code","source":["len([i for i in [i for i in train_loader]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cINvTeOQxH0e","outputId":"a661e02e-5013-49ce-ad80-d9067ebfc9b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["train_losses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQfgit4BLfue","outputId":"ab8215a5-7ee5-43fd-e3fa-6d71dd0138ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[5.803986579179764, 5.603913187980652, 5.432435095310211, 5.2441063821315765]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["len([i for i in train_data])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zmD-y3StUPg","outputId":"676085ed-2259-467c-d99e-b931f61193b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1584"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["test_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"sx5C7UtY7OpT","outputId":"677d23f9-b69f-4b79-f214-1c2a8ea4a22d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/data/clean_test.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":165}]},{"cell_type":"code","source":["\n","torch.save(bart_model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/models/bart_model_checkpoint.pth')\n","# download checkpoint file\n","files.download('/content/drive/MyDrive/Colab Notebooks/models/bart_model_checkpoint.pth')\n","# bart_model = bart_model.cuda()"],"metadata":{"id":"vIsZ-Es7qyOq","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"28266ffa-589c-4676-f500-c77371a40938"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_47ccf85b-0e7b-4301-bd4b-f678a3f0dea7\", \"bart_model_checkpoint.pth\", 498254529)"]},"metadata":{}}]},{"cell_type":"code","source":["state_dict = torch.load('/content/drive/MyDrive/Colab Notebooks/models/bart_model_checkpoint.pth')\n","print(state_dict.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTabPdBs7_qc","outputId":"efc63afb-e6f0-4a94-edc7-f4c459efb285"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['encoder.shared.weight', 'encoder.encoder.embed_tokens.weight', 'encoder.encoder.embed_positions.weight', 'encoder.encoder.layers.0.self_attn.k_proj.weight', 'encoder.encoder.layers.0.self_attn.k_proj.bias', 'encoder.encoder.layers.0.self_attn.v_proj.weight', 'encoder.encoder.layers.0.self_attn.v_proj.bias', 'encoder.encoder.layers.0.self_attn.q_proj.weight', 'encoder.encoder.layers.0.self_attn.q_proj.bias', 'encoder.encoder.layers.0.self_attn.out_proj.weight', 'encoder.encoder.layers.0.self_attn.out_proj.bias', 'encoder.encoder.layers.0.self_attn_layer_norm.weight', 'encoder.encoder.layers.0.self_attn_layer_norm.bias', 'encoder.encoder.layers.0.fc1.weight', 'encoder.encoder.layers.0.fc1.bias', 'encoder.encoder.layers.0.fc2.weight', 'encoder.encoder.layers.0.fc2.bias', 'encoder.encoder.layers.0.final_layer_norm.weight', 'encoder.encoder.layers.0.final_layer_norm.bias', 'encoder.encoder.layers.1.self_attn.k_proj.weight', 'encoder.encoder.layers.1.self_attn.k_proj.bias', 'encoder.encoder.layers.1.self_attn.v_proj.weight', 'encoder.encoder.layers.1.self_attn.v_proj.bias', 'encoder.encoder.layers.1.self_attn.q_proj.weight', 'encoder.encoder.layers.1.self_attn.q_proj.bias', 'encoder.encoder.layers.1.self_attn.out_proj.weight', 'encoder.encoder.layers.1.self_attn.out_proj.bias', 'encoder.encoder.layers.1.self_attn_layer_norm.weight', 'encoder.encoder.layers.1.self_attn_layer_norm.bias', 'encoder.encoder.layers.1.fc1.weight', 'encoder.encoder.layers.1.fc1.bias', 'encoder.encoder.layers.1.fc2.weight', 'encoder.encoder.layers.1.fc2.bias', 'encoder.encoder.layers.1.final_layer_norm.weight', 'encoder.encoder.layers.1.final_layer_norm.bias', 'encoder.encoder.layers.2.self_attn.k_proj.weight', 'encoder.encoder.layers.2.self_attn.k_proj.bias', 'encoder.encoder.layers.2.self_attn.v_proj.weight', 'encoder.encoder.layers.2.self_attn.v_proj.bias', 'encoder.encoder.layers.2.self_attn.q_proj.weight', 'encoder.encoder.layers.2.self_attn.q_proj.bias', 'encoder.encoder.layers.2.self_attn.out_proj.weight', 'encoder.encoder.layers.2.self_attn.out_proj.bias', 'encoder.encoder.layers.2.self_attn_layer_norm.weight', 'encoder.encoder.layers.2.self_attn_layer_norm.bias', 'encoder.encoder.layers.2.fc1.weight', 'encoder.encoder.layers.2.fc1.bias', 'encoder.encoder.layers.2.fc2.weight', 'encoder.encoder.layers.2.fc2.bias', 'encoder.encoder.layers.2.final_layer_norm.weight', 'encoder.encoder.layers.2.final_layer_norm.bias', 'encoder.encoder.layers.3.self_attn.k_proj.weight', 'encoder.encoder.layers.3.self_attn.k_proj.bias', 'encoder.encoder.layers.3.self_attn.v_proj.weight', 'encoder.encoder.layers.3.self_attn.v_proj.bias', 'encoder.encoder.layers.3.self_attn.q_proj.weight', 'encoder.encoder.layers.3.self_attn.q_proj.bias', 'encoder.encoder.layers.3.self_attn.out_proj.weight', 'encoder.encoder.layers.3.self_attn.out_proj.bias', 'encoder.encoder.layers.3.self_attn_layer_norm.weight', 'encoder.encoder.layers.3.self_attn_layer_norm.bias', 'encoder.encoder.layers.3.fc1.weight', 'encoder.encoder.layers.3.fc1.bias', 'encoder.encoder.layers.3.fc2.weight', 'encoder.encoder.layers.3.fc2.bias', 'encoder.encoder.layers.3.final_layer_norm.weight', 'encoder.encoder.layers.3.final_layer_norm.bias', 'encoder.encoder.layernorm_embedding.weight', 'encoder.encoder.layernorm_embedding.bias', 'encoder.decoder.embed_tokens.weight', 'encoder.decoder.embed_positions.weight', 'encoder.decoder.layers.0.self_attn.k_proj.weight', 'encoder.decoder.layers.0.self_attn.k_proj.bias', 'encoder.decoder.layers.0.self_attn.v_proj.weight', 'encoder.decoder.layers.0.self_attn.v_proj.bias', 'encoder.decoder.layers.0.self_attn.q_proj.weight', 'encoder.decoder.layers.0.self_attn.q_proj.bias', 'encoder.decoder.layers.0.self_attn.out_proj.weight', 'encoder.decoder.layers.0.self_attn.out_proj.bias', 'encoder.decoder.layers.0.self_attn_layer_norm.weight', 'encoder.decoder.layers.0.self_attn_layer_norm.bias', 'encoder.decoder.layers.0.encoder_attn.k_proj.weight', 'encoder.decoder.layers.0.encoder_attn.k_proj.bias', 'encoder.decoder.layers.0.encoder_attn.v_proj.weight', 'encoder.decoder.layers.0.encoder_attn.v_proj.bias', 'encoder.decoder.layers.0.encoder_attn.q_proj.weight', 'encoder.decoder.layers.0.encoder_attn.q_proj.bias', 'encoder.decoder.layers.0.encoder_attn.out_proj.weight', 'encoder.decoder.layers.0.encoder_attn.out_proj.bias', 'encoder.decoder.layers.0.encoder_attn_layer_norm.weight', 'encoder.decoder.layers.0.encoder_attn_layer_norm.bias', 'encoder.decoder.layers.0.fc1.weight', 'encoder.decoder.layers.0.fc1.bias', 'encoder.decoder.layers.0.fc2.weight', 'encoder.decoder.layers.0.fc2.bias', 'encoder.decoder.layers.0.final_layer_norm.weight', 'encoder.decoder.layers.0.final_layer_norm.bias', 'encoder.decoder.layernorm_embedding.weight', 'encoder.decoder.layernorm_embedding.bias', 'decoder.final_logits_bias', 'decoder.model.shared.weight', 'decoder.model.encoder.embed_tokens.weight', 'decoder.model.encoder.embed_positions.weight', 'decoder.model.encoder.layers.0.self_attn.k_proj.weight', 'decoder.model.encoder.layers.0.self_attn.k_proj.bias', 'decoder.model.encoder.layers.0.self_attn.v_proj.weight', 'decoder.model.encoder.layers.0.self_attn.v_proj.bias', 'decoder.model.encoder.layers.0.self_attn.q_proj.weight', 'decoder.model.encoder.layers.0.self_attn.q_proj.bias', 'decoder.model.encoder.layers.0.self_attn.out_proj.weight', 'decoder.model.encoder.layers.0.self_attn.out_proj.bias', 'decoder.model.encoder.layers.0.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.0.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.0.fc1.weight', 'decoder.model.encoder.layers.0.fc1.bias', 'decoder.model.encoder.layers.0.fc2.weight', 'decoder.model.encoder.layers.0.fc2.bias', 'decoder.model.encoder.layers.0.final_layer_norm.weight', 'decoder.model.encoder.layers.0.final_layer_norm.bias', 'decoder.model.encoder.layers.1.self_attn.k_proj.weight', 'decoder.model.encoder.layers.1.self_attn.k_proj.bias', 'decoder.model.encoder.layers.1.self_attn.v_proj.weight', 'decoder.model.encoder.layers.1.self_attn.v_proj.bias', 'decoder.model.encoder.layers.1.self_attn.q_proj.weight', 'decoder.model.encoder.layers.1.self_attn.q_proj.bias', 'decoder.model.encoder.layers.1.self_attn.out_proj.weight', 'decoder.model.encoder.layers.1.self_attn.out_proj.bias', 'decoder.model.encoder.layers.1.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.1.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.1.fc1.weight', 'decoder.model.encoder.layers.1.fc1.bias', 'decoder.model.encoder.layers.1.fc2.weight', 'decoder.model.encoder.layers.1.fc2.bias', 'decoder.model.encoder.layers.1.final_layer_norm.weight', 'decoder.model.encoder.layers.1.final_layer_norm.bias', 'decoder.model.encoder.layers.2.self_attn.k_proj.weight', 'decoder.model.encoder.layers.2.self_attn.k_proj.bias', 'decoder.model.encoder.layers.2.self_attn.v_proj.weight', 'decoder.model.encoder.layers.2.self_attn.v_proj.bias', 'decoder.model.encoder.layers.2.self_attn.q_proj.weight', 'decoder.model.encoder.layers.2.self_attn.q_proj.bias', 'decoder.model.encoder.layers.2.self_attn.out_proj.weight', 'decoder.model.encoder.layers.2.self_attn.out_proj.bias', 'decoder.model.encoder.layers.2.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.2.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.2.fc1.weight', 'decoder.model.encoder.layers.2.fc1.bias', 'decoder.model.encoder.layers.2.fc2.weight', 'decoder.model.encoder.layers.2.fc2.bias', 'decoder.model.encoder.layers.2.final_layer_norm.weight', 'decoder.model.encoder.layers.2.final_layer_norm.bias', 'decoder.model.encoder.layers.3.self_attn.k_proj.weight', 'decoder.model.encoder.layers.3.self_attn.k_proj.bias', 'decoder.model.encoder.layers.3.self_attn.v_proj.weight', 'decoder.model.encoder.layers.3.self_attn.v_proj.bias', 'decoder.model.encoder.layers.3.self_attn.q_proj.weight', 'decoder.model.encoder.layers.3.self_attn.q_proj.bias', 'decoder.model.encoder.layers.3.self_attn.out_proj.weight', 'decoder.model.encoder.layers.3.self_attn.out_proj.bias', 'decoder.model.encoder.layers.3.self_attn_layer_norm.weight', 'decoder.model.encoder.layers.3.self_attn_layer_norm.bias', 'decoder.model.encoder.layers.3.fc1.weight', 'decoder.model.encoder.layers.3.fc1.bias', 'decoder.model.encoder.layers.3.fc2.weight', 'decoder.model.encoder.layers.3.fc2.bias', 'decoder.model.encoder.layers.3.final_layer_norm.weight', 'decoder.model.encoder.layers.3.final_layer_norm.bias', 'decoder.model.encoder.layernorm_embedding.weight', 'decoder.model.encoder.layernorm_embedding.bias', 'decoder.model.decoder.embed_tokens.weight', 'decoder.model.decoder.embed_positions.weight', 'decoder.model.decoder.layers.0.self_attn.k_proj.weight', 'decoder.model.decoder.layers.0.self_attn.k_proj.bias', 'decoder.model.decoder.layers.0.self_attn.v_proj.weight', 'decoder.model.decoder.layers.0.self_attn.v_proj.bias', 'decoder.model.decoder.layers.0.self_attn.q_proj.weight', 'decoder.model.decoder.layers.0.self_attn.q_proj.bias', 'decoder.model.decoder.layers.0.self_attn.out_proj.weight', 'decoder.model.decoder.layers.0.self_attn.out_proj.bias', 'decoder.model.decoder.layers.0.self_attn_layer_norm.weight', 'decoder.model.decoder.layers.0.self_attn_layer_norm.bias', 'decoder.model.decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.model.decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.model.decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.model.decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.model.decoder.layers.0.fc1.weight', 'decoder.model.decoder.layers.0.fc1.bias', 'decoder.model.decoder.layers.0.fc2.weight', 'decoder.model.decoder.layers.0.fc2.bias', 'decoder.model.decoder.layers.0.final_layer_norm.weight', 'decoder.model.decoder.layers.0.final_layer_norm.bias', 'decoder.model.decoder.layernorm_embedding.weight', 'decoder.model.decoder.layernorm_embedding.bias', 'decoder.lm_head.weight'])\n"]}]},{"cell_type":"code","source":["len(train_loader.dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMaJFeHbdnPS","outputId":"136d353d-d809-4dcf-b9dc-0f34be323b86"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1584"]},"metadata":{},"execution_count":169}]},{"cell_type":"code","source":["import torch.optim as optim\n","def validate(model, val_loader, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer_type='Adam', epochs=NUM_EPOCHS,verbose=True):\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate) if optimizer_type == 'Adam' else optim.SGD(model.parameters(), lr=learning_rate)\n","    model.eval()\n","\n","    total_tokens = 0\n","    val_losses=[]\n","    generated_texts = []\n","    gold_texts = []\n","    t0 = time.time()\n","\n","    with torch.no_grad():\n","      for epoch in range(epochs):\n","        print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n","        epoch_loss=0\n","        for step,batch in enumerate(val_loader):\n","            src = batch['toxic_ids'].cuda()\n","            tgt = batch['non_toxic_ids'].cuda()\n","\n","            # Perform style transfer\n","            outputs = model(input_ids=src, decoder_input_ids=tgt[:, :-1].contiguous())\n","            generated_text = tokenizer.batch_decode(outputs.logits.argmax(-1), skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","            generated_texts.extend(generated_text)\n","            gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n","            gold_texts.extend(gold_text)\n","\n","            # Compute loss\n","            loss = F.cross_entropy(outputs.logits.view(-1, outputs.logits.size(-1)), tgt[:, 1:].contiguous().view(-1))                  \n","            epoch_loss += loss.item()\n","\n","        # Report progress every batch\n","        if verbose and step % 1 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(val_loader), loss.item()))\n","\n","        avg_loss = epoch_loss / len(val_loader)\n","        val_losses.append(avg_loss)\n","\n","        elapsed_time = time.time() - t0\n","        if verbose:\n","            print('Epoch [{}/{}], Average Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n","\n","    return val_losses,avg_loss, generated_texts, gold_texts\n","\n","val_loss,avg_loss, generated_texts, gold_texts=validate(bart_model, val_loader, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer_type='Adam') #'SGD'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ez1kUWEcXi-F","outputId":"affb593c-4ade-44d6-e145-e0932471e1a9","executionInfo":{"status":"ok","timestamp":1679267446260,"user_tz":420,"elapsed":7337,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["######  Epoch 1/4 ######\n","Epoch [1/4], Step [2/2], Loss: 10.6365\n","Epoch [1/4], Average Loss: 10.6583, Elapsed Time: 0:00:05\n","######  Epoch 2/4 ######\n","Epoch [2/4], Step [2/2], Loss: 10.6365\n","Epoch [2/4], Average Loss: 10.6583, Elapsed Time: 0:00:05\n","######  Epoch 3/4 ######\n","Epoch [3/4], Step [2/2], Loss: 10.6365\n","Epoch [3/4], Average Loss: 10.6583, Elapsed Time: 0:00:06\n","######  Epoch 4/4 ######\n","Epoch [4/4], Step [2/2], Loss: 10.6365\n","Epoch [4/4], Average Loss: 10.6583, Elapsed Time: 0:00:06\n"]}]},{"cell_type":"code","source":["val_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYC0GFzVgC27","outputId":"f2067e0e-ba7a-4805-e818-cd9cf8ee3ca8","executionInfo":{"status":"ok","timestamp":1679267460261,"user_tz":420,"elapsed":1093,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[10.658347606658936,\n"," 10.658347606658936,\n"," 10.658347606658936,\n"," 10.658347606658936]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["dev=pd.read_csv(dev_path,sep=\",\", header=None) \n","\n","for i in range(len(generated_texts[:5])):\n","  print(' Original text   :: ',dev[1][i])\n","  print(' Gold text       :: ',gold_texts[i])\n","  print(' Translated text :: ',generated_texts[i])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bAn7pvYaiKK","outputId":"f42f33f4-5db7-412f-e535-47edd3fede7b","executionInfo":{"status":"ok","timestamp":1679267463872,"user_tz":420,"elapsed":758,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original text   ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is a fucking moron\n"," Gold text       ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is not thinking about this\n"," Translated text ::  anyone who thinks canceling a pipeline and handcuffing fossil energy production in the us would have no effect on gas prices is not thinking about\n"," Original text   ::  my favorite part is that youre still madly replying as if its going to quell your cousin fucking urges\n"," Gold text       ::  my favorite part is that you are still replying\n"," Translated text ::  my favorite part is that you are still replying\n"," Original text   ::  but did you try it lol that and medical marijuana helped my cousins tinnitus she used to puke cause she would be so dizzy\n"," Gold text       ::  have you tried it that helped my cousin s tinnitus she used to puke cause she would be so dizzy\n"," Translated text ::  have you tried it that helped my cousin s tinnitus she used to puke cause she would be so dizzy\n"," Original text   ::  by the downvotes i see there are a bunch of uneducated trumpers here who dont understand oil you probably think bideg contols gas prices too \n"," Gold text       ::  by the downvotes i see there are a bunch of trump supporters here who dont understand oil you probably think bideg contols gas prices too\n"," Translated text ::  by the downvotes i see there are a bunch of trump supporters here who dont understand oil you probably think bideg contols gas prices too\n"," Original text   ::  cuckold carlson is a problem\n"," Gold text       ::  carlson is the problem\n"," Translated text ::  carlson is the problem\n"]}]},{"cell_type":"code","source":["print(range(1, 5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKi5eQB2hnZJ","outputId":"97442a37-b13b-4821-a181-f54ddf82d76b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["range(1, 5)\n"]}]},{"cell_type":"code","source":["import seaborn as sns\n","### Plot Training & Validation Loss\n","data = {'Epoch': range(1, 5), 'Training Loss': train_losses, 'Validation Loss': val_loss}\n","df = pd.DataFrame(data)\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","sns.set_style('whitegrid')\n","sns.set(font_scale=1.5)\n","\n","# Plot train & val loss\n","sns.lineplot(data=df, x=\"Epoch\", y=\"Training Loss\", label=\"Training Loss\", marker='o')\n","sns.lineplot(data=df, x=\"Epoch\", y=\"Validation Loss\", label=\"Validation Loss\", marker='o')\n","\n","# set the axis labels and title\n","ax.set(xlabel='Epoch', ylabel='Loss')\n","ax.set_title('Training and Validation Loss', fontsize=18)\n","\n","# set the legend and adjust its position\n","plt.legend(fontsize=14)\n","\n","# set the ticks fontsize\n","ax.tick_params(axis='both', which='major', labelsize=14)\n","# ax.grid(True, which='both', linestyle='--', color='lightgray')"],"metadata":{"id":"DwIX28xsI4CQ","colab":{"base_uri":"https://localhost:8080/","height":412},"outputId":"569eefe9-a5e0-4569-e178-0b82cba6d9e2","executionInfo":{"status":"ok","timestamp":1679267467757,"user_tz":420,"elapsed":1061,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["test_data = MyDataset(test_path, MAX_SEQ_LEN,'test')\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n"],"metadata":{"id":"ngvdJlOC82ay","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a315e2f-637f-49a6-d70a-117107cdd4af","executionInfo":{"status":"ok","timestamp":1679267482287,"user_tz":420,"elapsed":1329,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," test  dataset preview .....\n","*******************************************\n","Input :: toxic :: so maybe you should be more retarded\n","Input :: non toxic :: so maybe you should be more backward\n","encoded length toxic : [0, 2527, 2085, 47, 197, 28, 55, 47304, 2]\n","encoded length non toxic:  [0, 2527, 2085, 47, 197, 28, 55, 18173, 2]\n","*******************************************\n","total number of test  data processed :  199\n"]}]},{"cell_type":"code","source":["# import rouge_score\n","# from rouge_score import rouge_scorer, scoring\n","# from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","# from nltk.translate.rouge_score import rouge_l_sentence_level, rouge_l_summary_level\n","import evaluate\n","\n","rouge = evaluate.load('rouge')\n","bleu = evaluate.load('bleu')\n","\n","\n","# Define a smoothing function for Rouge-L\n","smoothie = SmoothingFunction().method4\n","\n","def model_evaluate(model, data_loader):\n","    model.eval()\n","    total_loss = 0\n","    total_accuracy = 0\n","    total_precision = 0\n","    total_recall = 0\n","    total_f1 = 0\n","    # Calculate the evaluation metrics\n","    total_correct = 0\n","    total_predicted = 0\n","    total_gold = 0\n","    total_batches = 0\n","\n","    total_rouge1 = 0\n","    total_rouge2 = 0\n","    total_rougel = 0\n","    total_rougelsum = 0\n","    total_gen_len = 0\n","\n","    golden_texts=[]\n","    predicted_generated_text=[]\n","    bleu_scores = []\n","    rouge = Rouge()\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader):\n","            toxic_src = batch['toxic_ids'].cuda()\n","            non_toxic_tgt = batch['non_toxic_ids'].cuda()\n","\n","            outputs = model(input_ids=toxic_src,decoder_input_ids=non_toxic_tgt[:, :-1].contiguous())\n","\n","            gold_text = tokenizer.batch_decode(non_toxic_tgt[:, 1:], skip_special_tokens=True)\n","            golden_texts.extend(gold_text)\n","\n","            loss = F.cross_entropy(outputs.logits.view(-1, outputs.logits.size(-1)), non_toxic_tgt[:, 1:].contiguous().view(-1))\n","\n","            # Get the predicted tokens by selecting the token with the highest score (argmax) for each position\n","            predicted_tokens = torch.argmax(outputs.logits, dim=-1)\n","\n","            # Convert the tensor to a list of lists of integers (batch_size x sequence_length)\n","            predicted_tokens_list = predicted_tokens.tolist()\n","\n","            # Decode the predicted tokens into strings using the tokenizer\n","            predicted_text = tokenizer.batch_decode(predicted_tokens_list, skip_special_tokens=True)\n","            \n","            predicted_generated_text.extend(predicted_text)\n","            \n","            total_loss += loss.item()\n","            \n","            print('per batch analysis',len(predicted_generated_text),len(golden_texts))\n","            for i, (predicted_sent, gold_sent) in enumerate(zip(predicted_generated_text, golden_texts)):\n","                # Calculate the number of correct tokens\n","                \n","                correct_tokens = sum([1 for p, g in zip(predicted_sent, gold_sent) if p == g])\n","                total_correct += correct_tokens\n","                \n","                # Calculate the number of predicted and gold tokens\n","                predicted_tokens = len(predicted_sent)\n","                total_predicted += predicted_tokens\n","                \n","                gold_tokens = len(gold_sent.split())\n","                total_gold += gold_tokens\n","               \n","            # Calculate average generated length\n","            total_gen_len += sum([len(sent.split()) for sent in predicted_text])\n","            total_batches += 1*len(predicted_text)\n","\n","\n","    print('number of records in test',total_batches)     \n","\n","    # Calculate average metrics for the entire dataset\n","    avg_loss = total_loss / total_batches\n","    avg_accuracy = total_correct / total_predicted if total_predicted > 0 else 0\n","    avg_precision = total_correct / total_predicted if total_predicted > 0 else 0\n","    avg_recall = total_correct / total_gold if total_gold > 0 else 0\n","    avg_f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if avg_precision + avg_recall > 0 else 0\n","\n","    print(\"Loss: {:.4f}\".format(avg_loss))\n","    print(\"Accuracy: {:.4f}\".format(avg_accuracy))\n","    print(\"Precision: {:.4f}\".format(avg_precision))\n","    print(\"Recall: {:.4f}\".format(avg_recall))\n","    print(\"F1 Score: {:.4f}\".format(avg_f1))\n","\n","    return predicted_generated_text,golden_texts\n","\n","predicted_generated_text,golden_texts=model_evaluate(bart_model, test_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1OhZ3518pDx","outputId":"f2679895-3da2-4ef5-ccd0-78baead28e5d","executionInfo":{"status":"ok","timestamp":1679268383190,"user_tz":420,"elapsed":6367,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 1/2 [00:00<00:00,  3.18it/s]"]},{"output_type":"stream","name":"stdout","text":["per batch analysis 100 100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:00<00:00,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["per batch analysis 200 200\n","number of records in test 200\n","Loss: 0.1065\n","Accuracy: 1.0000\n","Precision: 1.0000\n","Recall: 5.1655\n","F1 Score: 1.6756\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!pip install rouge-score --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCjTjO9ZA9Kt","outputId":"60f8a1ba-51c0-4f52-dcd1-008c74b97070","executionInfo":{"status":"ok","timestamp":1679267528884,"user_tz":420,"elapsed":6246,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install -U evaluate --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMDrwMu-BO3L","outputId":"5d6262cd-6399-4264-b345-905bd80194e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["rouge.compute(predictions=predicted_generated_text,references=golden_texts)"],"metadata":{"id":"X15MsWAyE66A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679268117900,"user_tz":420,"elapsed":1081,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}},"outputId":"07463de8-85e1-4d7b-8f9f-d3dd94ddb5a0"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rouge1': 0.9948979591836735,\n"," 'rouge2': 0.9948305084745763,\n"," 'rougeL': 0.994867012378722,\n"," 'rougeLsum': 0.9948979591836735}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print(bleu.compute(predictions=predicted_generated_text,references=golden_texts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g0oQhefLxoQ","executionInfo":{"status":"ok","timestamp":1679268211352,"user_tz":420,"elapsed":652,"user":{"displayName":"Shivangi Pandey","userId":"16350093937384471871"}},"outputId":"b7bb6abe-84ca-4500-d9da-6b9c44efd3c8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bleu': 0.9991401548251397, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 0.9991401548251397, 'length_ratio': 0.9991405242801891, 'translation_length': 2325, 'reference_length': 2327}\n"]}]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3EN3hR0oh0K","outputId":"2ce3016a-5962-49db-dba3-93489e98691d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3132"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["df_test=pd.read_csv(test_path,sep=\",\", header=None) \n","# display(df_test)\n","\n","for i in range(len(predicted_generated_text[:5])):\n","  print(' Original text   :: ',df_test[1][i])\n","  print(' Gold text       :: ',df_test[2][i])\n","  print(' Translated text :: ',predicted_generated_text[i])\n","\n","# Create a new DataFrame with the generated texts\n","df_gen = pd.DataFrame({'bart_tuning_output': predicted_generated_text}) \n","\n","# Add the generated_text column to the df_test dataframe\n","df_bart_output = pd.concat([df_test, df_gen], axis=1)\n","\n","# Save the updated dataframe as a CSV file\n","df_bart_output=df_bart_output.drop([0],axis=1)\n","df_bart_output=df_bart_output[:-1]\n","df_bart_output.to_csv('/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output.csv',sep='\\t',index=False,header=['toxic_text','gold_text','bart_tuning_output'])"],"metadata":{"id":"kM6-ak9I7vBM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d8aec29-4be2-431f-941b-045d6e05e6dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Original text   ::  so maybe you should be more retarded\n"," Gold text       ::  so maybe you should be more backward\n"," Translated text ::  so maybe you should be more backward\n"," Original text   ::  theres a megathread for vaccine or covid related topics don t talk about that shit here idiot\n"," Gold text       ::  theres actually a megathread for vaccine or covid related topics don t talk about that stuff here\n"," Translated text ::  theres actually a megathread for vaccine or covid related topics don t talk about that stuff here\n"," Original text   ::  the fuck you are on drugs\n"," Gold text       ::  uh you are not being realistic\n"," Translated text ::  uh you are not being realistic\n"," Original text   ::  nta dump his ass tablemanners are no rocket science treating other people like human beings is no rocket science his still a child\n"," Gold text       ::  you should leave him tablemanners are no rocket science treating other people like human beings is no rocket science his still a child\n"," Translated text ::  you should leave him tablemanners are no rocket science treating other people like human beings is no rocket science his still a child\n"," Original text   ::  youre soft as baby shit\n"," Gold text       ::  youre really soft\n"," Translated text ::  youre really soft\n"]}]},{"cell_type":"code","source":["output_file = '/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output.csv'\n","sample=pd.read_csv(output_file, sep=\"\\t\")\n","sample[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zDx3X9eBsnXb","outputId":"efbb72c3-829a-4376-8240-556690e86faa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          toxic_text  \\\n","0               so maybe you should be more retarded   \n","1  theres a megathread for vaccine or covid relat...   \n","2                          the fuck you are on drugs   \n","3  nta dump his ass tablemanners are no rocket sc...   \n","4                            youre soft as baby shit   \n","\n","                                           gold_text  \\\n","0               so maybe you should be more backward   \n","1  theres actually a megathread for vaccine or co...   \n","2                     uh you are not being realistic   \n","3  you should leave him tablemanners are no rocke...   \n","4                                  youre really soft   \n","\n","                                  bart_tuning_output  \n","0               so maybe you should be more backward  \n","1  theres actually a megathread for vaccine or co...  \n","2                     uh you are not being realistic  \n","3  you should leave him tablemanners are no rocke...  \n","4                                  youre really soft  "],"text/html":["\n","  <div id=\"df-090b7691-4ca2-47cb-85cf-27310a0b510b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>toxic_text</th>\n","      <th>gold_text</th>\n","      <th>bart_tuning_output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>so maybe you should be more retarded</td>\n","      <td>so maybe you should be more backward</td>\n","      <td>so maybe you should be more backward</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>theres a megathread for vaccine or covid relat...</td>\n","      <td>theres actually a megathread for vaccine or co...</td>\n","      <td>theres actually a megathread for vaccine or co...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the fuck you are on drugs</td>\n","      <td>uh you are not being realistic</td>\n","      <td>uh you are not being realistic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nta dump his ass tablemanners are no rocket sc...</td>\n","      <td>you should leave him tablemanners are no rocke...</td>\n","      <td>you should leave him tablemanners are no rocke...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>youre soft as baby shit</td>\n","      <td>youre really soft</td>\n","      <td>youre really soft</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-090b7691-4ca2-47cb-85cf-27310a0b510b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-090b7691-4ca2-47cb-85cf-27310a0b510b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-090b7691-4ca2-47cb-85cf-27310a0b510b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["#!pip install tqdm\n","import sys\n","# sys.path.append('./notebooks')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/notebooks')\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/models')\n","from DistilBertClassification import BertClassificationML, NonToxicScoreDataLoader, NonToxicScore\n","\n","# Load DistilBERT Classification Model to calculate NonToxicScore\n","score_model = BertClassificationML()\n","score_model = score_model.to(device)\n","\n","# Load training weights\n","pretrained_weights = torch.load('/content/drive/MyDrive/Colab Notebooks/models/DistilBertToxicClassification5.pth')\n","score_model.load_state_dict(pretrained_weights )"],"metadata":{"id":"nW_yJ19qgZmI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"500c2264-6bfe-43b0-f6f8-55d4d8197c3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":155}]},{"cell_type":"code","source":["output_file = '/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output.csv'\n","output_col = 'bart_tuning_output'\n","\n","# Create Data Loader\n","score_loader = NonToxicScoreDataLoader(output_file, output_col)\n","\n","# Calculate NonToxicScore\n","bart_NonToxicScores, avg_score = NonToxicScore(score_loader, score_model)"],"metadata":{"id":"WVzkmqLJNG3h","colab":{"base_uri":"https://localhost:8080/"},"outputId":"41e8ba9d-338e-431d-96d9-60516b3dd8df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'NonToxicScore': 0.6282647931269703}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b69be31f5fb149439a24993a439a9d38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab11d7e884244bddb0788d8756ce2738","IPY_MODEL_2a65bcddc1814b21979aa81aab403791","IPY_MODEL_18bb04646fda4b15966aa55319c3e68d"],"layout":"IPY_MODEL_6407a563ae7548fa864fb25c3c4150b6"}},"ab11d7e884244bddb0788d8756ce2738":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff35596ab5694974927e3423c3b949ae","placeholder":"​","style":"IPY_MODEL_519f4fb921f84db6b00aff550f0f8ef5","value":"Downloading (…)olve/main/vocab.json: 100%"}},"2a65bcddc1814b21979aa81aab403791":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb9f5fe70f0545608868629eace167cc","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ef965c9468f474daac37eb05070c25a","value":898822}},"18bb04646fda4b15966aa55319c3e68d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe67ed2807164a46987206140fe1ce2d","placeholder":"​","style":"IPY_MODEL_13b5b78fbd7e4891a7bd12b75959d68e","value":" 899k/899k [00:01&lt;00:00, 793kB/s]"}},"6407a563ae7548fa864fb25c3c4150b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff35596ab5694974927e3423c3b949ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"519f4fb921f84db6b00aff550f0f8ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb9f5fe70f0545608868629eace167cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ef965c9468f474daac37eb05070c25a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe67ed2807164a46987206140fe1ce2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b5b78fbd7e4891a7bd12b75959d68e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abd7eb5376f743acb4561d68f03ab182":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e038632b529b42528e0d4133acaa93ab","IPY_MODEL_a05189dbb05b4a299bff1cbc866ef971","IPY_MODEL_4cf84d9d3d3c41e18e0124ba1dcab703"],"layout":"IPY_MODEL_b8932123fe5844eeae163fd56c2000e9"}},"e038632b529b42528e0d4133acaa93ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a9e8c2ed54340269589531e8b358589","placeholder":"​","style":"IPY_MODEL_9d21fe3f1f8d45ed99c14942744e248e","value":"Downloading (…)olve/main/merges.txt: 100%"}},"a05189dbb05b4a299bff1cbc866ef971":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2075efe3dbc84d74b952098924b9ef77","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43bccf112aa44ca29629059ac7ad15f5","value":456318}},"4cf84d9d3d3c41e18e0124ba1dcab703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c580c5cd4717476e88af0764163aafcd","placeholder":"​","style":"IPY_MODEL_68bd169a0d1046acab4026a691b6bb86","value":" 456k/456k [00:00&lt;00:00, 499kB/s]"}},"b8932123fe5844eeae163fd56c2000e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a9e8c2ed54340269589531e8b358589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d21fe3f1f8d45ed99c14942744e248e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2075efe3dbc84d74b952098924b9ef77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43bccf112aa44ca29629059ac7ad15f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c580c5cd4717476e88af0764163aafcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68bd169a0d1046acab4026a691b6bb86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8753ca26301a4528bb4d5151a7f84c85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bf35c62d4fd466b977e55abafd9d4bb","IPY_MODEL_937e475849034a8aba7316f8f93442ed","IPY_MODEL_2da161b715b74d01ba43de99e24e1a26"],"layout":"IPY_MODEL_f85824f59e4849f788892a83313c0d49"}},"3bf35c62d4fd466b977e55abafd9d4bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c84b56ae7cf4e0a802095b58b6778dd","placeholder":"​","style":"IPY_MODEL_56201afcc93c46d58c8eabf5992ea97c","value":"Downloading (…)okenizer_config.json: 100%"}},"937e475849034a8aba7316f8f93442ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7cdecdcb3ce42409beceeefbc2176bf","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_776dccd4f64f4ee896282f0ded9ce3c5","value":26}},"2da161b715b74d01ba43de99e24e1a26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b0c5850cb34d9ba379ee1be617562e","placeholder":"​","style":"IPY_MODEL_bc7d0f3ae3f84ab09f43c99ff38632a8","value":" 26.0/26.0 [00:00&lt;00:00, 1.36kB/s]"}},"f85824f59e4849f788892a83313c0d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c84b56ae7cf4e0a802095b58b6778dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56201afcc93c46d58c8eabf5992ea97c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7cdecdcb3ce42409beceeefbc2176bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"776dccd4f64f4ee896282f0ded9ce3c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02b0c5850cb34d9ba379ee1be617562e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7d0f3ae3f84ab09f43c99ff38632a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51c317efff0445179f80feb67fc1c3bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_387a81cc4f9641cb915c7f535fbe8237","IPY_MODEL_ca7c7964dc8947b09d43faae4f669567","IPY_MODEL_daafdd68bcde439aaeca4af2cf6650db"],"layout":"IPY_MODEL_bcd6ef30bb2e45e4a06d25b7d41699d8"}},"387a81cc4f9641cb915c7f535fbe8237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ff802333c1b42e2960b84a3fa241cdc","placeholder":"​","style":"IPY_MODEL_09a56244a41a4cb8819cd2f5dcb3fa65","value":"Downloading (…)lve/main/config.json: 100%"}},"ca7c7964dc8947b09d43faae4f669567":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0728ff82b36a4e37804cb78f206e303a","max":1628,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4dec7f9dcc04b638efc94011f908426","value":1628}},"daafdd68bcde439aaeca4af2cf6650db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ead1ad0b47e4f3cb5ba69000745ca8e","placeholder":"​","style":"IPY_MODEL_dc2e4ac6df04464cbde84ac31dd14c15","value":" 1.63k/1.63k [00:00&lt;00:00, 60.6kB/s]"}},"bcd6ef30bb2e45e4a06d25b7d41699d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff802333c1b42e2960b84a3fa241cdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09a56244a41a4cb8819cd2f5dcb3fa65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0728ff82b36a4e37804cb78f206e303a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4dec7f9dcc04b638efc94011f908426":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ead1ad0b47e4f3cb5ba69000745ca8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc2e4ac6df04464cbde84ac31dd14c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}