{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GOAL\n",
    "\n",
    "In this notebook we are attempting to build a simple disentanglement model using BART encoder and decoder.\n",
    "1. Two encoders:\n",
    "  - A context encoder: to extract the semantic and context of toxic text.\n",
    "  - A masked encoder: completely remove offensive texts and replace them with masked tokens as input text, this encoder is represented for preliminary non-toxic style encoding. \n",
    "2. Decoder: using cross attention between the masked encoder and the context encoder as input to the decoder to transfer toxic texts to non-toxic texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISCLAIMER :  \n",
    "Due to nature of experiment the notebook contains profanity and toxic words. Please proceed with caution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so-yur1S9mS4",
    "tags": []
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1. Libraries and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35376,
     "status": "ok",
     "timestamp": 1679267274868,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "8uQnMctL9mS5",
    "outputId": "091f9ca3-60c9-45d4-e123-0dc3f96c95a3"
   },
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install tqdm boto3 requests regex sentencepiece sacremoses evaluate --quiet\n",
    "!pip install rouge --quiet\n",
    "!pip install better_profanity --quiet\n",
    "!pip install rouge-score --quiet\n",
    "!pip install -U evaluate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0jokLO9GqZp"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8166,
     "status": "ok",
     "timestamp": 1679267291833,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "7CALja8vLcZ9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BartTokenizer, BartConfig, BartForConditionalGeneration,BartModel,AutoTokenizer\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "from rouge import Rouge \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import evaluate\n",
    "from better_profanity import profanity\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import datetime\n",
    "import string\n",
    "import regex as re\n",
    "# upload external file before import\n",
    "# from google.colab import files\n",
    "# from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1679267298179,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "3cbELEg_S5iX",
    "outputId": "833335ab-14ec-4472-fdff-15c00f9cd64a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29946,
     "status": "ok",
     "timestamp": 1679267330969,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "YnqrYaGuxo3M",
    "outputId": "9da98e5f-6735-4ca0-87c0-fd0c8ae8231a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCThYsKtyrOn",
    "outputId": "869fb92a-7e52-4664-9525-f62c9df22c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/style_transfer_w266\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "# cd drive/MyDrive/w266/style_transfer_w266/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gMBfqnnShB06"
   },
   "outputs": [],
   "source": [
    "train_path='data/original-train.tsv'\n",
    "dev_path='data/original-dev.tsv'\n",
    "test_path='data/original-test.tsv'\n",
    "# train_path='/content/drive/MyDrive/Colab Notebooks/data/original-train.tsv'\n",
    "# dev_path='/content/drive/MyDrive/Colab Notebooks/data/original-dev.tsv'\n",
    "# test_path='/content/drive/MyDrive/Colab Notebooks/data/original-test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "7mzdBizMi1gj",
    "outputId": "984a0244-5cda-40db-c902-1609607c0a25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offensive-text</th>\n",
       "      <th>style-transferred-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok, this makes no sense. This will create vigi...</td>\n",
       "      <td>Ok, this makes no sense. This will create vigi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so fucking true. the amount of up and coming r...</td>\n",
       "      <td>so true. the amount of up and coming rappers t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go f yourself Republican scum who put us here ...</td>\n",
       "      <td>Republicans put us in this situation. I would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumb fucking take. People want to do things.</td>\n",
       "      <td>That's not a smart take. People want to do thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fuck no ðŸ˜‚</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>The View! And this crap hits my front page!? l...</td>\n",
       "      <td>This must be mostly bots but still, it's stran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Thatâ€™s racist.</td>\n",
       "      <td>Those actions are racist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>Cultural Marxism isn't a thing you weird fuck.</td>\n",
       "      <td>Cultural Marxism isn't a thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>LOL, anyone that questions the Democrat progra...</td>\n",
       "      <td>LOL, anyone that questions the Democrat progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>How about you guys actually read the bill, if ...</td>\n",
       "      <td>I wish everyone actually read the bill.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1583 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         offensive-text  \\\n",
       "1     Ok, this makes no sense. This will create vigi...   \n",
       "2     so fucking true. the amount of up and coming r...   \n",
       "3     Go f yourself Republican scum who put us here ...   \n",
       "4          Dumb fucking take. People want to do things.   \n",
       "5                                             Fuck no ðŸ˜‚   \n",
       "...                                                 ...   \n",
       "1579  The View! And this crap hits my front page!? l...   \n",
       "1580                                     Thatâ€™s racist.   \n",
       "1581     Cultural Marxism isn't a thing you weird fuck.   \n",
       "1582  LOL, anyone that questions the Democrat progra...   \n",
       "1583  How about you guys actually read the bill, if ...   \n",
       "\n",
       "                                 style-transferred-text  \n",
       "1     Ok, this makes no sense. This will create vigi...  \n",
       "2     so true. the amount of up and coming rappers t...  \n",
       "3     Republicans put us in this situation. I would ...  \n",
       "4     That's not a smart take. People want to do thi...  \n",
       "5                                                    no  \n",
       "...                                                 ...  \n",
       "1579  This must be mostly bots but still, it's stran...  \n",
       "1580                          Those actions are racist.  \n",
       "1581                    Cultural Marxism isn't a thing.  \n",
       "1582  LOL, anyone that questions the Democrat progra...  \n",
       "1583            I wish everyone actually read the bill.  \n",
       "\n",
       "[1583 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train=pd.read_csv(train_path,sep=\"\\t\", header=0)\n",
    "dev=pd.read_csv(dev_path,sep=\"\\t\", header=0) \n",
    "test=pd.read_csv(test_path,sep=\"\\t\", header=0) \n",
    "display(train[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niEwhBdNFnxW",
    "outputId": "e5321aa1-6ff8-4aba-9b08-a63b6a69f53d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['offensive-text'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2MqDpHEGNyi",
    "outputId": "730d9f87-a511-465f-edba-40f40fa23460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['offensive-text'].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBfPJTp0Tg6T",
    "outputId": "e27e4ed8-20fe-4924-d62d-7272a1b208bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.85353535353535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['offensive-text'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "i8Qz4GMUDCV3",
    "outputId": "8204df17-de4c-464f-8a87-3864ee9a522e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offensive-text</th>\n",
       "      <th>style-transferred-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [offensive-text, style-transferred-text]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['style-transferred-text']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "GZEMCYhu89Rx",
    "outputId": "7dbdc4c5-8ff5-4520-aabb-15a88fba01f2"
   },
   "outputs": [],
   "source": [
    "def clean_up_text(x):\n",
    "  \"\"\"Remove line breaks, special characters, within each post\"\"\"\n",
    "  # Remove special characters and punctuations\n",
    "  SPECIAL_CHARS_PATTERN = re.compile(r\"(\\*)|(\\~)|(\\=)|(\\.\\.\\.)|(\\;)|(\\:)|(\\â€™)|(\\_)|(\\-)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\\\)|(\\{)|(\\})\")\n",
    "  x = SPECIAL_CHARS_PATTERN.sub(\"\", x)\n",
    "\n",
    "  # Remove different types of line breaks and white spaces\n",
    "  x = re.sub(r\"\\n|\\r|\\r\\n|<br\\s*/?>\", \" \", x)\n",
    "  \n",
    "  # Remove extra white spaces\n",
    "  x = re.sub(r\"\\s+\", \" \", x.strip())\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5d13W9myt0w3"
   },
   "outputs": [],
   "source": [
    "def read_process_data(df):\n",
    "    # df[\"offensive-text\"] = df[\"offensive-text\"].str.lower()\n",
    "    # df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n",
    "    df[\"offensive-text\"] = df[\"offensive-text\"].apply(clean_up_text)\n",
    "    df[\"offensive-text\"] = df[\"offensive-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \") #\\n|\\r|\\r\\n|\n",
    "\n",
    "    # df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.lower()\n",
    "    # df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(rf\"([{string.punctuation}])+\",\" \", regex=True)\n",
    "    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].apply(clean_up_text)\n",
    "    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \")\n",
    "  \n",
    "    df['offensive-text']=df['offensive-text'].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n",
    "    df[\"style-transferred-text\"] = df[\"style-transferred-text\"].astype(str).apply(lambda x: x.encode('latin-1', 'ignore').decode('latin-1'))\n",
    "\n",
    "    print('The null count :: ',df.isnull().sum())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "h1sOu0-tufhH",
    "outputId": "c6f1e80a-1717-4ca6-84ee-49d927ed65b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null count ::  offensive-text            0\n",
      "style-transferred-text    0\n",
      "dtype: int64\n",
      "The null count ::  offensive-text            0\n",
      "style-transferred-text    0\n",
      "dtype: int64\n",
      "The null count ::  offensive-text            0\n",
      "style-transferred-text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PASS PROCESS \"True\" TO CREATE CLEANED DATASET : ONE TIME EFFORT\n",
    "def cleaned_data(process=False):\n",
    "  if process:\n",
    "    x=read_process_data(train)\n",
    "    x.to_csv('data/clean_train.csv', header = False)\n",
    "    z=read_process_data(test)\n",
    "    z.to_csv('data/clean_test.csv', header = False)\n",
    "    y=read_process_data(dev)\n",
    "    y.to_csv('data/clean_dev.csv', header = False)\n",
    "\n",
    "cleaned_data(process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "tp8w26y7z9eY"
   },
   "outputs": [],
   "source": [
    "train_path='data/clean_train.csv'\n",
    "dev_path='data/clean_dev.csv'\n",
    "test_path='data/clean_test.csv'\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(datetime.timedelta(seconds=int(round(seconds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeRVnvQ10d1K"
   },
   "source": [
    "Below code is implementation of BART (Bidirectional and Auto-Regressive Transformer) model for sequence-to-sequence (seq2seq) tasks using PyTorch. The BART model is a variant of the Transformer model and is pre-trained on a large corpus of text data using a denoising autoencoder objective. It is capable of generating high-quality text with coherent sentence structures.\n",
    "\n",
    "The code defines a PyTorch Dataset class MyDataset that reads the input and target text sequences from a text file and tokenizes them using the BART tokenizer. It then defines the collate_fn function to pad the sequences in each batch to the same length. The code then defines the BartEncoderDecoder class, which is the main model class that uses the BART encoder and decoder architecture.\n",
    "\n",
    "The code instantiates the BART tokenizer and the BartEncoderDecoder model, and loads the training and validation data using the MyDataset class. It also defines the optimizer and loss function. The code then runs the training loop for a specified number of epochs, during which it trains the model on the training set and evaluates it on the validation set.\n",
    "\n",
    "During training, the code iterates over the batches of training data and performs forward and backward passes through the model to compute the loss and update the model parameters using the Adam optimizer. The code also implements gradient accumulation by accumulating the gradients over a specified number of batches to reduce the memory requirements during training. After training on all the batches, the code computes the average loss over the entire training set and evaluates the model on the validation set.\n",
    "\n",
    "During validation, the code iterates over the batches of validation data and generates the predicted text sequences using the generate method of the BART decoder. It then computes the loss between the predicted and target sequences and accumulates the loss over all the batches to compute the average loss over the entire validation set. Finally, the code prints the average training and validation loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if memory issue happens. This will free up some space\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BART Disentanglement Model\n",
    "\n",
    "1. Used tokenizer = \"facebook/bart-base\" based on available resources\n",
    "\n",
    "2. To mask profanity words used better_profanity python package and along with this used BADWORD custom list to mask toxic words.\n",
    "\n",
    "3. Limited Batch size to 16 max as training dataset has 1584 records. Also used low number of epochs.\n",
    "\n",
    "4. We had a choice to use decoder.generate() or decoder.outputs() to get generated token ids. We will be using generate method. torch.argmax(outputs.logits, dim=-1) gives the index of the highest logit value for each position in the output sequence. This is not the same as the sequence of generated IDs produced by decoder.generate(), because decoder.generate() applies several additional steps during decoding, such as beam search and top-k sampling, that are not present in a simple argmax operation.\n",
    "The decoder.generate() method in BART uses beam search to generate multiple possible sequences, and then returns the highest-scoring sequence according to a scoring function that takes into account both the log-likelihood of the sequence and various penalties for things like repeated n-grams. This process is more complex than simply taking the argmax of the logits, and can lead to better quality generated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NTA.   Dump his ****. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.\n",
      " NTA.   Dump his <mask>. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.\n"
     ]
    }
   ],
   "source": [
    "# Test profanity library output\n",
    "toxic_seq = ' NTA.   Dump his ASS. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.'\n",
    "censored_text = profanity.censor(toxic_seq)\n",
    "print(censored_text)\n",
    "masked_toxic_seq=censored_text.replace('****','<mask>')\n",
    "print(masked_toxic_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wish you a major accident and a painful ****, there is no good reason for you to exist. I will be very happy to attend your funeral\n",
      "I wish you a major accident and a painful <mask>, there is no good reason for you to exist. I will be very happy to attend your funeral\n"
     ]
    }
   ],
   "source": [
    "# Test profanity library output\n",
    "toxic_seq = 'I wish you a major accident and a painful stroke, there is no good reason for you to exist. I will be very happy to attend your funeral'\n",
    "censored_text = profanity.censor(toxic_seq)\n",
    "print(censored_text)\n",
    "masked_toxic_seq=censored_text.replace('****','<mask>')\n",
    "print(masked_toxic_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b69be31f5fb149439a24993a439a9d38",
      "ab11d7e884244bddb0788d8756ce2738",
      "2a65bcddc1814b21979aa81aab403791",
      "18bb04646fda4b15966aa55319c3e68d",
      "6407a563ae7548fa864fb25c3c4150b6",
      "ff35596ab5694974927e3423c3b949ae",
      "519f4fb921f84db6b00aff550f0f8ef5",
      "eb9f5fe70f0545608868629eace167cc",
      "1ef965c9468f474daac37eb05070c25a",
      "fe67ed2807164a46987206140fe1ce2d",
      "13b5b78fbd7e4891a7bd12b75959d68e",
      "abd7eb5376f743acb4561d68f03ab182",
      "e038632b529b42528e0d4133acaa93ab",
      "a05189dbb05b4a299bff1cbc866ef971",
      "4cf84d9d3d3c41e18e0124ba1dcab703",
      "b8932123fe5844eeae163fd56c2000e9",
      "8a9e8c2ed54340269589531e8b358589",
      "9d21fe3f1f8d45ed99c14942744e248e",
      "2075efe3dbc84d74b952098924b9ef77",
      "43bccf112aa44ca29629059ac7ad15f5",
      "c580c5cd4717476e88af0764163aafcd",
      "68bd169a0d1046acab4026a691b6bb86",
      "8753ca26301a4528bb4d5151a7f84c85",
      "3bf35c62d4fd466b977e55abafd9d4bb",
      "937e475849034a8aba7316f8f93442ed",
      "2da161b715b74d01ba43de99e24e1a26",
      "f85824f59e4849f788892a83313c0d49",
      "5c84b56ae7cf4e0a802095b58b6778dd",
      "56201afcc93c46d58c8eabf5992ea97c",
      "f7cdecdcb3ce42409beceeefbc2176bf",
      "776dccd4f64f4ee896282f0ded9ce3c5",
      "02b0c5850cb34d9ba379ee1be617562e",
      "bc7d0f3ae3f84ab09f43c99ff38632a8",
      "51c317efff0445179f80feb67fc1c3bc",
      "387a81cc4f9641cb915c7f535fbe8237",
      "ca7c7964dc8947b09d43faae4f669567",
      "daafdd68bcde439aaeca4af2cf6650db",
      "bcd6ef30bb2e45e4a06d25b7d41699d8",
      "5ff802333c1b42e2960b84a3fa241cdc",
      "09a56244a41a4cb8819cd2f5dcb3fa65",
      "0728ff82b36a4e37804cb78f206e303a",
      "e4dec7f9dcc04b638efc94011f908426",
      "2ead1ad0b47e4f3cb5ba69000745ca8e",
      "dc2e4ac6df04464cbde84ac31dd14c15"
     ]
    },
    "executionInfo": {
     "elapsed": 12243,
     "status": "ok",
     "timestamp": 1679267351207,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "6olz1mhT-ovf",
    "outputId": "9f534f46-a586-4764-8eb4-4ad17f69ebc5"
   },
   "outputs": [],
   "source": [
    "# Instantiate BART tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base') \n",
    "\n",
    "profanity.load_censor_words()\n",
    "BADWORDS = ['suck','stupid','pimp','dumb','homo','slut','damn','ass','rape','poop','cock','lol','crap','sex','nazi','neo-nazi',\n",
    "    'fuck','bitch','pussy','penis','vagina','whore','shit','nigger','nigga','cocksucker','assrape','motherfucker','wanker','cunt', 'evil',\n",
    "    'faggot','fags','asshole','piss','cum','moron','cuckold','shit','filthy','retarded','screw','cucked','lick','lmfao','tf', 'dump', 'assholes'\n",
    "]\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    this class generate tokens of input, masked and target sentences \n",
    "    data_path: The path to the training data file.\n",
    "    max_seq_len: The maximum sequence length allowed for the input sequences.\n",
    "    kind : contains value like training, validation etc . This is used to print the token generation of phases like training , validation or testing\n",
    "\n",
    "    In the __init__ method, the training data is loaded from the specified file, and each line of text is stored in a list.\n",
    "    In the __len__ method, the length of the dataset is returned (i.e., the number of lines in the training data file).\n",
    "    In the __getitem__ method, an individual training example is retrieved based on the specified index. \n",
    "                              The input text is tokenized using the specified tokenizer and truncated to the specified maximum sequence length, \n",
    "                              and the resulting token ids are converted to a PyTorch tensor and returned as the training example.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, max_seq_len,kind):\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.toxic_ids = []\n",
    "        self.non_toxic_ids = []\n",
    "        self.masked_toxic_ids=[]\n",
    "\n",
    "        c=0\n",
    "        with open(data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    parts = line.split(',')\n",
    "                    toxic_seq = parts[1]\n",
    "                    non_toxic_seq = parts[2]\n",
    "\n",
    "                    # Replace profanity and badwords with <mask> token\n",
    "                    censored_text = profanity.censor(toxic_seq)\n",
    "                    masked_toxic_seq=censored_text.replace('****','<mask>')\n",
    "\n",
    "                    for words in BADWORDS:\n",
    "                      masked_toxic_seq=masked_toxic_seq.replace(words,'<mask>')\n",
    "                      masked_toxic_seq=masked_toxic_seq.replace(words.upper(),'<mask>')\n",
    "                      masked_toxic_seq=masked_toxic_seq.replace(words.title(),'<mask>')\n",
    "\n",
    "                    toxic_ids = tokenizer(toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)\n",
    "                    non_toxic_ids = tokenizer(non_toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)\n",
    "                    masked_toxic_ids= tokenizer(masked_toxic_seq, max_length=max_seq_len,padding=\"max_length\", truncation=True)\n",
    "                    \n",
    "                    self.toxic_ids.append(toxic_ids.input_ids)\n",
    "                    self.non_toxic_ids.append(non_toxic_ids.input_ids)\n",
    "                    self.masked_toxic_ids.append(masked_toxic_ids.input_ids)\n",
    "\n",
    "                    if c==0:\n",
    "                      print('\\n',kind,' dataset preview .....')\n",
    "                      print('*******************************************')\n",
    "                      print('Input :: toxic        ::',toxic_seq)\n",
    "                      print('Input :: masked toxic ::',masked_toxic_seq)\n",
    "                      print('Input :: non toxic    ::',non_toxic_seq)\n",
    "                      print('encoded length toxic :',toxic_ids)\n",
    "                      print('encoded length masked toxic: ',masked_toxic_ids)\n",
    "                      print('encoded length non toxic: ',non_toxic_ids)\n",
    "                      print('*******************************************')\n",
    "                    c=c+1\n",
    "            print('total number of',kind,' data processed : ',c)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.toxic_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        toxic_ids = self.toxic_ids[index]\n",
    "        non_toxic_ids = self.non_toxic_ids[index]\n",
    "        masked_toxic_ids =self.masked_toxic_ids[index]\n",
    "\n",
    "        # Create a PyTorch tensor from the tokenized sequences\n",
    "        toxic_ids = torch.tensor(toxic_ids, dtype=torch.int64)\n",
    "        non_toxic_ids = torch.tensor(non_toxic_ids, dtype=torch.int64)\n",
    "        masked_toxic_ids = torch.tensor(masked_toxic_ids, dtype=torch.int64)\n",
    "\n",
    "        return {'toxic_ids': toxic_ids, 'non_toxic_ids': non_toxic_ids, 'masked_toxic_ids': masked_toxic_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 10978,
     "status": "ok",
     "timestamp": 1679267362710,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "TYQd-fO70q4z"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "MAX_SEQ_LEN = 256\n",
    "D_MODEL = 256 # dimensionality of the input and output vectors of the Transformer model. It is also commonly referred to as the \"hidden size\" of the model.POWER OF 2\n",
    "NUM_HEADS = 4 #number of attention heads used in multi-head attention (D_MODEL/NUM_HEADS=INT)\n",
    "NUM_ENCODER_LAYERS = 4 \n",
    "NUM_DECODER_LAYERS = 4 \n",
    "DIM_FEEDFORWARD = 1024 #(4 times of D_MODEL)\n",
    "DROPOUT = 0.3\n",
    "GRADIENT_ACCUMULATION_STEPS = 2 # accumulate gradients over 2 batches\n",
    "HIDDEN_SIZE = 768\n",
    "\n",
    "# Define BART encoder-decoder model\n",
    "class BartEncoderDecoder(nn.Module):\n",
    "    def __init__(self, bart_config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_encoder = BartModel.from_pretrained('facebook/bart-base') #The bare BART Model outputting raw hidden-states without any specific head on top.\n",
    "        self.context_encoder.config = bart_config\n",
    "        self.masked_encoder_decoder = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "        self.masked_encoder_decoder.config = bart_config\n",
    "        self.bart_config=bart_config\n",
    "       \n",
    "    def forward(self, context_input_ids, masked_input_ids, target_ids=None):\n",
    "\n",
    "        # Generate hidden representations for the input sequence using the encoder\n",
    "        context_encoder_outputs = self.context_encoder(input_ids=context_input_ids).encoder_last_hidden_state\n",
    "        \n",
    "        # Pass the modified input sequence as input to the decoder, target sequence as label, encoder outputs (all layers) and generate the output sequence\n",
    "        # Cross attention between context encoder output and masked encoder output\n",
    "        decoder_outputs = self.masked_encoder_decoder(input_ids=masked_input_ids, encoder_outputs=context_encoder_outputs, \n",
    "                                       labels=target_ids) \n",
    "        return decoder_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate BART encoder-decoder model\n",
    "bart_config = BartConfig(d_model=D_MODEL, encoder_layers=NUM_ENCODER_LAYERS, decoder_layers=NUM_DECODER_LAYERS, \n",
    "                         encoder_attention_heads=NUM_HEADS, decoder_attention_heads=NUM_HEADS,\n",
    "                         encoder_ffn_dim=DIM_FEEDFORWARD, decoder_ffn_dim=DIM_FEEDFORWARD, dropout=DROPOUT, hidden_size=HIDDEN_SIZE) \n",
    "bart_model = BartEncoderDecoder(bart_config).cuda() # move the model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1679267362714,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "r2hZfkqE9c2I"
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    \"\"\"\n",
    "    This is loss function return cross entropy between decoder output and target tokens\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, vocab_size = outputs.logits.shape\n",
    "    outputs = outputs.logits.view(batch_size * seq_len, vocab_size)\n",
    "    \n",
    "    # Reshape the targets tensor to (batch_size * seq_len)\n",
    "    targets = targets.view(-1)\n",
    "    loss = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)(outputs, targets)\n",
    "    return loss\n",
    "\n",
    "def collate_fn(batch, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function is used to pad and make all input sentences of batch of equal sizes \n",
    "    \"\"\"\n",
    "    # Pad sequences in batch to have the same length\n",
    "    toxic_ids = pad_sequence([item['toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masked_toxic_ids = pad_sequence([item['masked_toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    non_toxic_ids = pad_sequence([item['non_toxic_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    # Split data into batches of the desired size\n",
    "    num_batches = len(batch) // batch_size\n",
    "    if len(batch) % batch_size != 0:\n",
    "        num_batches += 1\n",
    "    toxic_batches = list(torch.split(toxic_ids[:num_batches*batch_size], batch_size))\n",
    "    masked_toxic_batches = list(torch.split(masked_toxic_ids[:num_batches*batch_size], batch_size))\n",
    "    non_toxic_batches = list(torch.split(non_toxic_ids[:num_batches*batch_size], batch_size))\n",
    "\n",
    "    # Pad the last batch to ensure that all batches have the same size\n",
    "    if len(toxic_batches[-1]) < batch_size:\n",
    "        toxic_batches[-1] = nn.functional.pad(toxic_batches[-1], (0, 0, 0, batch_size - len(toxic_batches[-1])), value=tokenizer.pad_token_id)\n",
    "        masked_toxic_batches[-1] = nn.functional.pad(masked_toxic_batches[-1], (0, 0, 0, batch_size - len(masked_toxic_batches[-1])), value=tokenizer.pad_token_id)\n",
    "        non_toxic_batches[-1] = nn.functional.pad(non_toxic_batches[-1], (0, 0, 0, batch_size - len(non_toxic_batches[-1])), value=tokenizer.pad_token_id)\n",
    "\n",
    "    return [{'toxic_ids': t, 'non_toxic_ids': nt,'masked_toxic_ids': mt} for t, nt, mt in zip(toxic_batches, non_toxic_batches,masked_toxic_batches)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1679267373299,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "2T65jPqJVe3H",
    "outputId": "8077b3c5-a2a4-4dec-f6a4-0750c00f7b5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartEncoderDecoder(\n",
       "  (context_encoder): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (masked_encoder_decoder): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49675,
     "status": "ok",
     "timestamp": 1679267430721,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "kNySrGWAVZM5",
    "outputId": "9b97b296-790b-4f5e-e910-6bcf1a72a0ff"
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "def train(train_loader, epoch, learning_rate=LEARNING_RATE, epochs=NUM_EPOCHS, verbose=True, batch_size=BATCH_SIZE):\n",
    "  \"\"\"\n",
    "  This function is for training the model with forced learning at decoder side. \n",
    "  The encoder recieves input toxic sequence and decoder gets masked toxic sentence and target sequences.\n",
    "  \"\"\"\n",
    "  autograd.set_detect_anomaly(True)\n",
    "\n",
    "  # Instantiate optimizer and loss function\n",
    "  # train_losses=[]\n",
    "  \n",
    "  # print('\\nTokenizer information :: ')\n",
    "  # print('eos_token_id :',tokenizer.eos_token_id)\n",
    "  # print('pad_token_id :',tokenizer.pad_token_id)\n",
    "  # print('bos_token_id :', tokenizer.bos_token_id)\n",
    "  # print('sep_token_id :', tokenizer.sep_token_id,'\\n')\n",
    "\n",
    "  # start time\n",
    "  t0 = time.time()\n",
    "\n",
    "  # Training loop\n",
    "  # for epoch in range(epochs):\n",
    "  #     print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n",
    "      \n",
    "  # Train the model\n",
    "  bart_model.train()\n",
    "  train_loss = 0\n",
    "  epoch_loss=0\n",
    "\n",
    "  for step, batch in enumerate(train_loader):\n",
    "      src = batch['toxic_ids'].cuda()\n",
    "      tgt = batch['non_toxic_ids'].cuda()\n",
    "      masked_src=batch['masked_toxic_ids'].cuda()\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs=bart_model(context_input_ids=src, masked_input_ids=masked_src, target_ids=tgt)\n",
    "\n",
    "      loss = outputs.loss\n",
    "      # loss = loss_fn(outputs, tgt.cuda())\n",
    "      # loss = loss.mean() # reduce the loss tensor to a scalar tensor by taking the mean\n",
    "      # loss /= GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "      loss.backward()\n",
    "      # if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      scheduler.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "\n",
    "      # Report progress every 10 batches\n",
    "      if verbose and step % 10 == 0:\n",
    "          print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(train_loader), loss.item()))\n",
    "\n",
    "  avg_loss = epoch_loss / len(train_loader)\n",
    "  # train_losses.append(avg_loss)\n",
    "\n",
    "  elapsed_time = time.time() - t0\n",
    "  if verbose:\n",
    "      print('Epoch [{}/{}], Average Train Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n",
    "\n",
    "  # return train_losses, sum(train_losses) / len(train_losses)\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_F09xXl4Tsa",
    "outputId": "e334377d-0915-4e27-feea-750398f560f8"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def get_max_length(input_sequence):\n",
    "    # Return a multiple of the input sequence length as the maximum length\n",
    "    return int(len(input_sequence) * 1.75)\n",
    "\n",
    "def get_min_length(input_sequence):\n",
    "    # Return a multiple of the input sequence length as the maximum length\n",
    "    return int(len(input_sequence))\n",
    "\n",
    "def validate(val_loader, epoch, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer_type='Adam', epochs=NUM_EPOCHS,verbose=True):\n",
    "    \"\"\"\n",
    "    Function to perform validation cycle on data loader and generate sentences\n",
    "    \"\"\"\n",
    "\n",
    "    bart_model.eval()\n",
    "    \n",
    "    # total_tokens = 0\n",
    "    # val_losses=[]\n",
    "    generated_texts = []\n",
    "    gold_texts = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # for epoch in range(epochs):\n",
    "      #   print ('######  Epoch {}/{} ######'.format(epoch+1, epochs))\n",
    "      epoch_loss=0\n",
    "      for step,batch in enumerate(val_loader):\n",
    "          src = batch['toxic_ids'].cuda()\n",
    "          tgt = batch['non_toxic_ids'].cuda()\n",
    "          masked_src=batch['masked_toxic_ids'].cuda()\n",
    "\n",
    "          outputs=bart_model(context_input_ids=src, masked_input_ids=masked_src, target_ids=tgt)\n",
    "\n",
    "          loss = outputs.loss\n",
    "          # loss = loss_fn(outputs, tgt.cuda())         \n",
    "          epoch_loss += loss.item()\n",
    "      \n",
    "          # generate style transfer\n",
    "          generated_ids = bart_model.masked_encoder_decoder.generate(\n",
    "              input_ids=masked_src.cuda(),\n",
    "              # max_length=get_max_length(masked_src.cuda()),\n",
    "              max_length=256,\n",
    "              min_length=get_min_length(tgt.cuda()),\n",
    "              num_beams=5,\n",
    "              early_stopping=True,\n",
    "              top_k=50, \n",
    "              length_penalty=2, #1.2\n",
    "              repetition_penalty=1,\n",
    "              no_repeat_ngram_size=5,\n",
    "              top_p = 0.95,\n",
    "              temperature=0.8,\n",
    "              decoder_start_token_id=bart_config.decoder_start_token_id\n",
    "          )\n",
    "\n",
    "          generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "          generated_texts.extend(generated_text)\n",
    "\n",
    "          gold_text = tokenizer.batch_decode(tgt[:, 1:], skip_special_tokens=True)\n",
    "          gold_texts.extend(gold_text)   \n",
    "\n",
    "          \n",
    "          # Report progress every 10 step\n",
    "          if verbose and step % 10 == 0:\n",
    "              print('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}'.format(epoch+1, epochs, step+1, len(val_loader), loss.item()))\n",
    "\n",
    "    avg_loss = epoch_loss / len(val_loader)\n",
    "    # val_losses.append(avg_loss)\n",
    "\n",
    "    elapsed_time = time.time() - t0\n",
    "    if verbose:\n",
    "        print('Epoch [{}/{}], Average Validation Loss: {:.4f}, Elapsed Time: {}'.format(epoch+1, epochs, avg_loss, format_time(elapsed_time)))\n",
    "\n",
    "    # Calculate rouge score\n",
    "    df_gen = pd.DataFrame({'predictions': generated_texts, 'references': gold_texts}) \n",
    "    # score = rouge.compute(predictions=generated_texts,references=gold_texts)\n",
    "    score = rouge.compute(predictions=df_gen['predictions'],\n",
    "              references=df_gen['references'])\n",
    "    print(score)\n",
    "\n",
    "    # return val_losses,avg_loss, generated_texts, gold_texts\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cINvTeOQxH0e",
    "outputId": "a661e02e-5013-49ce-ad80-d9067ebfc9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training  dataset preview .....\n",
      "*******************************************\n",
      "Input :: toxic        :: Pussy nobody asked for your input.\n",
      "Input :: masked toxic :: <mask> nobody asked for your input.\n",
      "Input :: non toxic    :: Nobody asked for your input\n",
      "encoded length toxic : {'input_ids': [0, 510, 28102, 5907, 553, 13, 110, 8135, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length masked toxic:  {'input_ids': [0, 50264, 5907, 553, 13, 110, 8135, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length non toxic:  {'input_ids': [0, 18975, 553, 13, 110, 8135, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "*******************************************\n",
      "total number of training  data processed :  1584\n",
      "\n",
      " validation  dataset preview .....\n",
      "*******************************************\n",
      "Input :: toxic        :: Anyone who thinks canceling a pipeline and handcuffing fossil energy production in the US would have no effect on gas prices is a fucking moron\n",
      "Input :: masked toxic :: Anyone who thinks canceling a pipeline and handcuffing fossil energy production in the US would have no effect on gas prices is a <mask> <mask>\n",
      "Input :: non toxic    :: Anyone who thinks canceling a pipeline and handcuffing fossil energy production in the US would have no effect on gas prices is not thinking about this\n",
      "encoded length toxic : {'input_ids': [0, 25480, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 382, 74, 33, 117, 1683, 15, 1123, 850, 16, 10, 23523, 14628, 261, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length masked toxic:  {'input_ids': [0, 25480, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 382, 74, 33, 117, 1683, 15, 1123, 850, 16, 10, 50264, 50264, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length non toxic:  {'input_ids': [0, 25480, 54, 4265, 21338, 1527, 10, 4116, 8, 42149, 5865, 154, 11422, 1007, 931, 11, 5, 382, 74, 33, 117, 1683, 15, 1123, 850, 16, 45, 2053, 59, 42, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "*******************************************\n",
      "total number of validation  data processed :  198\n",
      "Instatiating Data loaders for training and validation dataset ......\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation data\n",
    "train_data = MyDataset(train_path, MAX_SEQ_LEN, 'training')\n",
    "val_data = MyDataset(dev_path, MAX_SEQ_LEN, 'validation')\n",
    "\n",
    "print('Instatiating Data loaders for training and validation dataset ......')\n",
    "# Instantiate data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQfgit4BLfue",
    "outputId": "ab8215a5-7ee5-43fd-e3fa-6d71dd0138ad"
   },
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "# optimizer = Adam(bart_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = AdamW(bart_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Create learning rate scheduler.\n",
    "T_max = NUM_EPOCHS*len(train_loader)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=10, num_training_steps=T_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######  Epoch 1/4 ######\n",
      "-----  Training -----\n",
      "Epoch [1/4], Step [1/198], Train Loss: 16.4967\n",
      "Epoch [1/4], Step [11/198], Train Loss: 12.5388\n",
      "Epoch [1/4], Step [21/198], Train Loss: 11.1322\n",
      "Epoch [1/4], Step [31/198], Train Loss: 8.2833\n",
      "Epoch [1/4], Step [41/198], Train Loss: 5.8983\n",
      "Epoch [1/4], Step [51/198], Train Loss: 4.7588\n",
      "Epoch [1/4], Step [61/198], Train Loss: 4.1752\n",
      "Epoch [1/4], Step [71/198], Train Loss: 3.5442\n",
      "Epoch [1/4], Step [81/198], Train Loss: 3.1109\n",
      "Epoch [1/4], Step [91/198], Train Loss: 2.5821\n",
      "Epoch [1/4], Step [101/198], Train Loss: 2.2307\n",
      "Epoch [1/4], Step [111/198], Train Loss: 1.8226\n",
      "Epoch [1/4], Step [121/198], Train Loss: 1.5328\n",
      "Epoch [1/4], Step [131/198], Train Loss: 1.2018\n",
      "Epoch [1/4], Step [141/198], Train Loss: 0.9940\n",
      "Epoch [1/4], Step [151/198], Train Loss: 0.9297\n",
      "Epoch [1/4], Step [161/198], Train Loss: 0.7243\n",
      "Epoch [1/4], Step [171/198], Train Loss: 0.5998\n",
      "Epoch [1/4], Step [181/198], Train Loss: 0.5032\n",
      "Epoch [1/4], Step [191/198], Train Loss: 0.5387\n",
      "Epoch [1/4], Average Train Loss: 3.8008, Elapsed Time: 0:02:50\n",
      "\n",
      "-----  Validation -----\n",
      "Epoch [1/4], Step [1/25], Validation Loss: 0.4658\n",
      "Epoch [1/4], Step [11/25], Validation Loss: 0.3027\n",
      "Epoch [1/4], Step [21/25], Validation Loss: 0.3882\n",
      "Epoch [1/4], Average Validation Loss: 0.3782, Elapsed Time: 0:00:25\n",
      "{'rouge1': 0.4722185919496665, 'rouge2': 0.3553865559065429, 'rougeL': 0.47180882764718823, 'rougeLsum': 0.4722103454495227}\n",
      "\n",
      "######  Epoch 2/4 ######\n",
      "-----  Training -----\n",
      "Epoch [2/4], Step [1/198], Train Loss: 0.3847\n",
      "Epoch [2/4], Step [11/198], Train Loss: 0.4707\n",
      "Epoch [2/4], Step [21/198], Train Loss: 0.3791\n",
      "Epoch [2/4], Step [31/198], Train Loss: 0.4156\n",
      "Epoch [2/4], Step [41/198], Train Loss: 0.3584\n",
      "Epoch [2/4], Step [51/198], Train Loss: 0.3903\n",
      "Epoch [2/4], Step [61/198], Train Loss: 0.2700\n",
      "Epoch [2/4], Step [71/198], Train Loss: 0.3908\n",
      "Epoch [2/4], Step [81/198], Train Loss: 0.3510\n",
      "Epoch [2/4], Step [91/198], Train Loss: 0.3547\n",
      "Epoch [2/4], Step [101/198], Train Loss: 0.4294\n",
      "Epoch [2/4], Step [111/198], Train Loss: 0.3911\n",
      "Epoch [2/4], Step [121/198], Train Loss: 0.3228\n",
      "Epoch [2/4], Step [131/198], Train Loss: 0.3901\n",
      "Epoch [2/4], Step [141/198], Train Loss: 0.3216\n",
      "Epoch [2/4], Step [151/198], Train Loss: 0.2898\n",
      "Epoch [2/4], Step [161/198], Train Loss: 0.3648\n",
      "Epoch [2/4], Step [171/198], Train Loss: 0.2521\n",
      "Epoch [2/4], Step [181/198], Train Loss: 0.3115\n",
      "Epoch [2/4], Step [191/198], Train Loss: 0.3602\n",
      "Epoch [2/4], Average Train Loss: 0.3461, Elapsed Time: 0:02:44\n",
      "\n",
      "-----  Validation -----\n",
      "Epoch [2/4], Step [1/25], Validation Loss: 0.3255\n",
      "Epoch [2/4], Step [11/25], Validation Loss: 0.1735\n",
      "Epoch [2/4], Step [21/25], Validation Loss: 0.2505\n",
      "Epoch [2/4], Average Validation Loss: 0.2513, Elapsed Time: 0:00:25\n",
      "{'rouge1': 0.4728279596627545, 'rouge2': 0.35524905740641244, 'rougeL': 0.47297425075252225, 'rougeLsum': 0.4731228123257011}\n",
      "\n",
      "######  Epoch 3/4 ######\n",
      "-----  Training -----\n",
      "Epoch [3/4], Step [1/198], Train Loss: 0.2294\n",
      "Epoch [3/4], Step [11/198], Train Loss: 0.2276\n",
      "Epoch [3/4], Step [21/198], Train Loss: 0.2433\n",
      "Epoch [3/4], Step [31/198], Train Loss: 0.2754\n",
      "Epoch [3/4], Step [41/198], Train Loss: 0.2985\n",
      "Epoch [3/4], Step [51/198], Train Loss: 0.2464\n",
      "Epoch [3/4], Step [61/198], Train Loss: 0.2154\n",
      "Epoch [3/4], Step [71/198], Train Loss: 0.2924\n",
      "Epoch [3/4], Step [81/198], Train Loss: 0.2244\n",
      "Epoch [3/4], Step [91/198], Train Loss: 0.4125\n",
      "Epoch [3/4], Step [101/198], Train Loss: 0.2717\n",
      "Epoch [3/4], Step [111/198], Train Loss: 0.2795\n",
      "Epoch [3/4], Step [121/198], Train Loss: 0.2537\n",
      "Epoch [3/4], Step [131/198], Train Loss: 0.2598\n",
      "Epoch [3/4], Step [141/198], Train Loss: 0.1767\n",
      "Epoch [3/4], Step [151/198], Train Loss: 0.2788\n",
      "Epoch [3/4], Step [161/198], Train Loss: 0.3007\n",
      "Epoch [3/4], Step [171/198], Train Loss: 0.3117\n",
      "Epoch [3/4], Step [181/198], Train Loss: 0.2723\n",
      "Epoch [3/4], Step [191/198], Train Loss: 0.2880\n",
      "Epoch [3/4], Average Train Loss: 0.2690, Elapsed Time: 0:02:52\n",
      "\n",
      "-----  Validation -----\n",
      "Epoch [3/4], Step [1/25], Validation Loss: 0.3083\n",
      "Epoch [3/4], Step [11/25], Validation Loss: 0.1624\n",
      "Epoch [3/4], Step [21/25], Validation Loss: 0.2353\n",
      "Epoch [3/4], Average Validation Loss: 0.2372, Elapsed Time: 0:00:26\n",
      "{'rouge1': 0.47552863074977897, 'rouge2': 0.35838264709344714, 'rougeL': 0.4754840110151889, 'rougeLsum': 0.4758584752202496}\n",
      "\n",
      "######  Epoch 4/4 ######\n",
      "-----  Training -----\n",
      "Epoch [4/4], Step [1/198], Train Loss: 0.2059\n",
      "Epoch [4/4], Step [11/198], Train Loss: 0.3066\n",
      "Epoch [4/4], Step [21/198], Train Loss: 0.2302\n",
      "Epoch [4/4], Step [31/198], Train Loss: 0.2308\n",
      "Epoch [4/4], Step [41/198], Train Loss: 0.2346\n",
      "Epoch [4/4], Step [51/198], Train Loss: 0.2573\n",
      "Epoch [4/4], Step [61/198], Train Loss: 0.2961\n",
      "Epoch [4/4], Step [71/198], Train Loss: 0.2525\n",
      "Epoch [4/4], Step [81/198], Train Loss: 0.2254\n",
      "Epoch [4/4], Step [91/198], Train Loss: 0.2767\n",
      "Epoch [4/4], Step [101/198], Train Loss: 0.1797\n",
      "Epoch [4/4], Step [111/198], Train Loss: 0.2095\n",
      "Epoch [4/4], Step [121/198], Train Loss: 0.1831\n",
      "Epoch [4/4], Step [131/198], Train Loss: 0.2403\n",
      "Epoch [4/4], Step [141/198], Train Loss: 0.2172\n",
      "Epoch [4/4], Step [151/198], Train Loss: 0.2631\n",
      "Epoch [4/4], Step [161/198], Train Loss: 0.2079\n",
      "Epoch [4/4], Step [171/198], Train Loss: 0.1954\n",
      "Epoch [4/4], Step [181/198], Train Loss: 0.2543\n",
      "Epoch [4/4], Step [191/198], Train Loss: 0.2173\n",
      "Epoch [4/4], Average Train Loss: 0.2563, Elapsed Time: 0:02:54\n",
      "\n",
      "-----  Validation -----\n",
      "Epoch [4/4], Step [1/25], Validation Loss: 0.3041\n",
      "Epoch [4/4], Step [11/25], Validation Loss: 0.1584\n",
      "Epoch [4/4], Step [21/25], Validation Loss: 0.2295\n",
      "Epoch [4/4], Average Validation Loss: 0.2338, Elapsed Time: 0:00:26\n",
      "{'rouge1': 0.4767928373377912, 'rouge2': 0.3599101113036987, 'rougeL': 0.47727766786801207, 'rougeLsum': 0.4773081232344746}\n"
     ]
    }
   ],
   "source": [
    "# Initialized Training & Validation Losses\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print ('\\n######  Epoch {}/{} ######'.format(epoch+1, NUM_EPOCHS))\n",
    "    # Training Loss per epoch\n",
    "    print ('-----  Training -----')\n",
    "    avg_train_loss = train(train_loader, epoch)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Loss per epoch\n",
    "    print ('\\n-----  Validation -----')\n",
    "    avg_val_loss = validate(val_loader, epoch)\n",
    "    val_losses.append(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zmD-y3StUPg",
    "outputId": "676085ed-2259-467c-d99e-b931f61193b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "### Plot Training & Validation Loss\n",
    "data = {'Epoch': range(1, 5), 'Training Loss': train_losses, 'Validation Loss': val_losses}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Plot train & val loss\n",
    "sns.lineplot(data=df, x=\"Epoch\", y=\"Training Loss\", label=\"Training Loss\", marker='o')\n",
    "sns.lineplot(data=df, x=\"Epoch\", y=\"Validation Loss\", label=\"Validation Loss\", marker='o')\n",
    "\n",
    "# set the axis labels and title\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "ax.set_title('Training and Validation Loss', fontsize=18)\n",
    "\n",
    "# set the legend and adjust its position\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# set the ticks fontsize\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "# ax.grid(True, which='both', linestyle='--', color='lightgray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "vIsZ-Es7qyOq",
    "outputId": "28266ffa-589c-4676-f500-c77371a40938"
   },
   "outputs": [],
   "source": [
    "torch.save(bart_model.state_dict(), 'models/bart_disentanglement.pth')\n",
    "# download checkpoint file\n",
    "# files.download('/content/drive/MyDrive/Colab Notebooks/models/bart_model2_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTabPdBs7_qc",
    "outputId": "efc63afb-e6f0-4a94-edc7-f4c459efb285"
   },
   "outputs": [],
   "source": [
    "# state_dict = torch.load('/content/drive/MyDrive/Colab Notebooks/models/bart_model2_checkpoint.pth')\n",
    "# print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test set  \n",
    "In intial attempts we observed that generated text length was very varying in comparison to golden text. \n",
    "1.  Sometimes longer input sentences were losing the words during translation. \n",
    "2.  Small input sentences has longer translated sentences\n",
    "3.  Smaller sentences has meaningless words added in the end ie context of the input sentence was gettung lost.\n",
    "\n",
    "To address this, \n",
    "1. we adjusted the decoding parameters, such as the length penalty or the minimum and maximum length constraints, to encourage the model to generate appropriate length of text. We added length penalization of 2 to discourage longer generation of sentence without meaningful context. \n",
    "2. Instead of sampling only from the most likely K words, we ended up using Top-p sampling to choose from the smallest possible set of words whose cumulative probability exceeds the probability p. \n",
    "3. We set this value high inorder to get high probablistic word. \n",
    "4. We experimented with beam search size from 3-10 and observed that 5 gave us reasonble translated text\n",
    "\n",
    "After fine tuning generate method,we observed that model started performing little well in case of short sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1679267482287,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "ngvdJlOC82ay",
    "outputId": "0a315e2f-637f-49a6-d70a-117107cdd4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test  dataset preview .....\n",
      "*******************************************\n",
      "Input :: toxic        :: So maybe you should be more retarded.\n",
      "Input :: masked toxic :: So maybe you should be more <mask>.\n",
      "Input :: non toxic    :: So maybe you should be more backward\n",
      "encoded length toxic : {'input_ids': [0, 2847, 2085, 47, 197, 28, 55, 47304, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length masked toxic:  {'input_ids': [0, 2847, 2085, 47, 197, 28, 55, 50264, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "encoded length non toxic:  {'input_ids': [0, 2847, 2085, 47, 197, 28, 55, 18173, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "*******************************************\n",
      "total number of test  data processed :  199\n"
     ]
    }
   ],
   "source": [
    "test_data = MyDataset(test_path, MAX_SEQ_LEN,'test')\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6367,
     "status": "ok",
     "timestamp": 1679268383190,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "L1OhZ3518pDx",
    "outputId": "f2679895-3da2-4ef5-ccd0-78baead28e5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:25<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records in test 200\n",
      "Loss: 0.0289\n",
      "Accuracy: 0.2709\n",
      "Precision: 0.2709\n",
      "Recall: 1.7798\n",
      "F1 Score: 0.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "bleu = evaluate.load('bleu')\n",
    "\n",
    "\n",
    "# Define a smoothing function for Rouge-L\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "def model_evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    # Calculate the evaluation metrics\n",
    "    total_correct = 0\n",
    "    total_predicted = 0\n",
    "    total_gold = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    total_rouge1 = 0\n",
    "    total_rouge2 = 0\n",
    "    total_rougel = 0\n",
    "    total_rougelsum = 0\n",
    "    total_gen_len = 0\n",
    "\n",
    "    golden_texts=[]\n",
    "    predicted_generated_text=[]\n",
    "    bleu_scores = []\n",
    "    rouge = Rouge()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            toxic_src = batch['toxic_ids'].cuda()\n",
    "            non_toxic_tgt = batch['non_toxic_ids'].cuda()\n",
    "            masked_toxic_src= batch['masked_toxic_ids'].cuda()\n",
    "            \n",
    "            generated_ids = bart_model.masked_encoder_decoder.generate(\n",
    "                input_ids=masked_toxic_src.cuda(),\n",
    "                # max_length=get_max_length(masked_toxic_src.cuda()),\n",
    "                max_length=256,\n",
    "                min_length=get_min_length(non_toxic_tgt.cuda()),\n",
    "                num_beams=5,\n",
    "                early_stopping=True,\n",
    "                top_k=50, #50\n",
    "                length_penalty=2, #1.2\n",
    "                repetition_penalty=1,\n",
    "                no_repeat_ngram_size=5,\n",
    "                top_p = 0.95,\n",
    "                temperature=0.8,\n",
    "                decoder_start_token_id=bart_config.decoder_start_token_id\n",
    "            )\n",
    "\n",
    "            predicted_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            if len(predicted_text) == 0:\n",
    "                predicted_text = \"None\"\n",
    "            predicted_generated_text.extend(predicted_text)\n",
    "\n",
    "            gold_text = tokenizer.batch_decode(non_toxic_tgt[:, 1:], skip_special_tokens=True)\n",
    "            golden_texts.extend(gold_text)\n",
    "\n",
    "            # calculating cross entropy loss\n",
    "            outputs=bart_model(context_input_ids=toxic_src, masked_input_ids=masked_toxic_src, target_ids=non_toxic_tgt)\n",
    "            loss = outputs.loss\n",
    "            # loss = loss_fn(outputs, non_toxic_tgt.cuda())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            for i, (predicted_sent, gold_sent) in enumerate(zip(predicted_generated_text, golden_texts)):\n",
    "                # Calculate the number of correct tokens\n",
    "                \n",
    "                correct_tokens = sum([1 for p, g in zip(predicted_sent, gold_sent) if p == g])\n",
    "                total_correct += correct_tokens\n",
    "                \n",
    "                # Calculate the number of predicted and gold tokens\n",
    "                predicted_tokens = len(predicted_sent)\n",
    "                total_predicted += predicted_tokens\n",
    "                \n",
    "                gold_tokens = len(gold_sent.split())\n",
    "                total_gold += gold_tokens\n",
    "               \n",
    "            # Calculate average generated length\n",
    "            total_gen_len += sum([len(sent.split()) for sent in predicted_text])\n",
    "            total_batches += 1*len(predicted_text)\n",
    "\n",
    "\n",
    "    print('number of records in test',total_batches)     \n",
    "\n",
    "    # Calculate average metrics for the entire dataset\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_correct / total_predicted if total_predicted > 0 else 0\n",
    "    avg_precision = total_correct / total_predicted if total_predicted > 0 else 0\n",
    "    avg_recall = total_correct / total_gold if total_gold > 0 else 0\n",
    "    avg_f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if avg_precision + avg_recall > 0 else 0\n",
    "\n",
    "    print(\"Loss: {:.4f}\".format(avg_loss))\n",
    "    print(\"Accuracy: {:.4f}\".format(avg_accuracy))\n",
    "    print(\"Precision: {:.4f}\".format(avg_precision))\n",
    "    print(\"Recall: {:.4f}\".format(avg_recall))\n",
    "    print(\"F1 Score: {:.4f}\".format(avg_f1))\n",
    "\n",
    "    return predicted_generated_text,golden_texts\n",
    "\n",
    "predicted_generated_text,golden_texts=model_evaluate(bart_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1679268211352,
     "user": {
      "displayName": "Shivangi Pandey",
      "userId": "16350093937384471871"
     },
     "user_tz": 420
    },
    "id": "6g0oQhefLxoQ",
    "outputId": "b7bb6abe-84ca-4500-d9da-6b9c44efd3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.40839219475928473, 'precisions': [0.5323934206109433, 0.431090320259086, 0.3730127956572315, 0.324926439680538], 'brevity_penalty': 1.0, 'length_ratio': 1.299738219895288, 'translation_length': 2979, 'reference_length': 2292}\n"
     ]
    }
   ],
   "source": [
    "print(bleu.compute(predictions=predicted_generated_text,references=golden_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kM6-ak9I7vBM",
    "outputId": "8d8aec29-4be2-431f-941b-045d6e05e6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text   ::  So maybe you should be more retarded.\n",
      "Gold text       ::  So maybe you should be more backward\n",
      "Translated text ::  So maybe you should be more careful.\n",
      "\n",
      "Original text   ::  THERES A MEGATHREAD FOR VACCINE OR COVID RELATED TOPICS. DON'T TALK ABOUT THAT SHIT HERE IDIOT!\n",
      "Gold text       ::  THERES ACTUALLY A MEGATHREAD FOR VACCINE OR COVID RELATED TOPICS. DON'T TALK ABOUT THAT STUFF HERE!\n",
      "Translated text ::  THERES A MEGATHREAD FOR VACCINE OR COLLABORATE RELATED TOPICS. DON'T TALK ABOUT THAT. CLICK HERE IDIOT!\n",
      "\n",
      "Original text   ::  the fuck. you are on drugs\n",
      "Gold text       ::  uh.. you are not being realistic\n",
      "Translated text ::  the U.S. you are on drugs\n",
      "\n",
      "Original text   ::  NTA. Dump his ass. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.\n",
      "Gold text       ::  You should leave him. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.\n",
      "Translated text ::  NTA. He is still a child and his life is not rocket science. Tablemanners are no rocket science. Treating other people like human beings is no rocket science. His still a child.\n",
      "\n",
      "Original text   ::  Youre soft as baby shit\n",
      "Gold text       ::  Youre really soft\n",
      "Translated text ::  Youre soft as baby.\n",
      "\n",
      "Original text   ::  Because everyone knows why. Its jadas fault. Will was just triggered because of all the shit he has to deal with because of her.\n",
      "Gold text       ::  Because everyone knows it's jadas fault. Will was just triggered because of everything he has to deal with because of her.\n",
      "Translated text ::  Because everyone knows why. Its jadas fault. Will was just triggered because of all the shit he has to deal with because of her.\n",
      "\n",
      "Original text   ::  And poor kids are just as bright as white kids. Your blundering bafoon chooses racism as well\n",
      "Gold text       ::  He said poor kids are just as bright as white kids.\n",
      "Translated text ::  And poor kids are just as bright as white kids. Your blundering bafoon chooses racism as well\n",
      "\n",
      "Original text   ::  Tucker is a garbage person that no one will miss when hes gone hes also a racist rublerouser\n",
      "Gold text       ::  Tucker is a bad person who instigates racism\n",
      "Translated text ::  Tucker is a garbage person that no one will miss when hes gone hes also a racist rublerouser\n",
      "\n",
      "Original text   ::  Theres plenty of evidence, its exactly why they wont allow forensic audits wipes voting machines clean of their records\n",
      "Gold text       ::  There is evidence, which is why they won't allow forensic audits.\n",
      "Translated text ::  \"Theres plenty of evidence\n",
      "\n",
      "Original text   ::  Came here to say this, carlsen is a freaking moron and defines recreational outrage imo\n",
      "Gold text       ::  Came here to say this, carlsen is pretty unintelligent and defines recreational outrage imo\n",
      "Translated text ::  \"Came here to say this\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(test_path,sep=\",\", header=None) \n",
    "# df_test = pd.read_csv('data/original-test.tsv', sep='\\t')\n",
    "\n",
    "for i in range(len(predicted_generated_text[:10])):\n",
    "  print('\\nOriginal text   :: ',df_test[1][i])\n",
    "  print('Gold text       :: ',df_test[2][i])\n",
    "  print('Translated text :: ',predicted_generated_text[i])\n",
    "\n",
    "# Create a new DataFrame with the generated texts\n",
    "df_gen = pd.DataFrame({'bart_tuning_output': predicted_generated_text}) \n",
    "\n",
    "# Add the generated_text column to the df_test dataframe\n",
    "df_bart_output = pd.concat([df_test, df_gen], axis=1)\n",
    "\n",
    "# Save the updated dataframe as a CSV file\n",
    "df_bart_output=df_bart_output.drop([0],axis=1)\n",
    "df_bart_output=df_bart_output[:-1]\n",
    "df_bart_output.to_csv('outputs/bart_disentanglement.csv',sep='\\t',index=False,header=['toxic_text','gold_text','bart_tuning_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zDx3X9eBsnXb",
    "outputId": "efbb72c3-829a-4376-8240-556690e86faa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic_text</th>\n",
       "      <th>gold_text</th>\n",
       "      <th>bart_tuning_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So maybe you should be more retarded.</td>\n",
       "      <td>So maybe you should be more backward</td>\n",
       "      <td>So maybe you should be more careful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...</td>\n",
       "      <td>THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...</td>\n",
       "      <td>THERES A MEGATHREAD FOR VACCINE OR COLLABORATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the fuck. you are on drugs</td>\n",
       "      <td>uh.. you are not being realistic</td>\n",
       "      <td>the U.S. you are on drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTA. Dump his ass. Tablemanners are no rocket ...</td>\n",
       "      <td>You should leave him. Tablemanners are no rock...</td>\n",
       "      <td>NTA. He is still a child and his life is not r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Youre soft as baby shit</td>\n",
       "      <td>Youre really soft</td>\n",
       "      <td>Youre soft as baby.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NTA, Jesus your brother is dumb. How long did ...</td>\n",
       "      <td>NTA, your brother is not thinking straight. Ho...</td>\n",
       "      <td>\"NTA is not a political party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Formula onenascar.shit it exactly the same exc...</td>\n",
       "      <td>Formula onenascar.it exactly the same except t...</td>\n",
       "      <td>Formula onenascar.com calls it exactly the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BRB, gonna go call the mods pathetic egotistic...</td>\n",
       "      <td>BRB, gonna go call the mods.</td>\n",
       "      <td>\"BRITAIN IS RESPONSIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CUCKOLD Carlson is a problem</td>\n",
       "      <td>Carlson is the problem</td>\n",
       "      <td>Tucker Carlson is a problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>I think you need to check your head</td>\n",
       "      <td>I think you need to check yourself</td>\n",
       "      <td>I think you need to check your head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            toxic_text  \\\n",
       "0                So maybe you should be more retarded.   \n",
       "1    THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...   \n",
       "2                           the fuck. you are on drugs   \n",
       "3    NTA. Dump his ass. Tablemanners are no rocket ...   \n",
       "4                              Youre soft as baby shit   \n",
       "..                                                 ...   \n",
       "194  NTA, Jesus your brother is dumb. How long did ...   \n",
       "195  Formula onenascar.shit it exactly the same exc...   \n",
       "196  BRB, gonna go call the mods pathetic egotistic...   \n",
       "197                       CUCKOLD Carlson is a problem   \n",
       "198                I think you need to check your head   \n",
       "\n",
       "                                             gold_text  \\\n",
       "0                 So maybe you should be more backward   \n",
       "1    THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...   \n",
       "2                     uh.. you are not being realistic   \n",
       "3    You should leave him. Tablemanners are no rock...   \n",
       "4                                    Youre really soft   \n",
       "..                                                 ...   \n",
       "194  NTA, your brother is not thinking straight. Ho...   \n",
       "195  Formula onenascar.it exactly the same except t...   \n",
       "196                       BRB, gonna go call the mods.   \n",
       "197                             Carlson is the problem   \n",
       "198                 I think you need to check yourself   \n",
       "\n",
       "                                    bart_tuning_output  \n",
       "0                 So maybe you should be more careful.  \n",
       "1    THERES A MEGATHREAD FOR VACCINE OR COLLABORATE...  \n",
       "2                            the U.S. you are on drugs  \n",
       "3    NTA. He is still a child and his life is not r...  \n",
       "4                                  Youre soft as baby.  \n",
       "..                                                 ...  \n",
       "194                      \"NTA is not a political party  \n",
       "195  Formula onenascar.com calls it exactly the sam...  \n",
       "196                            \"BRITAIN IS RESPONSIBLE  \n",
       "197                        Tucker Carlson is a problem  \n",
       "198                I think you need to check your head  \n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_file = '/content/drive/MyDrive/Colab Notebooks/outputs/bart_tuning_output2.csv'\n",
    "output_file = 'outputs/bart_disentanglement.csv'\n",
    "df_finetune = pd.read_csv(output_file, sep=\"\\t\")\n",
    "df_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.5984567230870393, 'rouge2': 0.47918544423221626, 'rougeL': 0.5948542625757081, 'rougeLsum': 0.5960471426133374}\n"
     ]
    }
   ],
   "source": [
    "print(rouge.compute(predictions=df_finetune['bart_tuning_output'],\n",
    "              references=df_finetune['gold_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Toxicity Score based on DistilBert classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nW_yJ19qgZmI",
    "outputId": "500c2264-6bfe-43b0-f6f8-55d4d8197c3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./notebooks')\n",
    "from DistilBertClassification import BertClassificationML, NonToxicScoreDataLoader, NonToxicScore\n",
    "\n",
    "# Load DistilBERT Classification Model to calculate NonToxicScore\n",
    "score_model = BertClassificationML()\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "# Load training weights\n",
    "pretrained_weights = torch.load('models/DistilBertToxicClassification7.pth')\n",
    "score_model.load_state_dict(pretrained_weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVzkmqLJNG3h",
    "outputId": "41e8ba9d-338e-431d-96d9-60516b3dd8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NonToxicScore': 0.5730693882264561}\n"
     ]
    }
   ],
   "source": [
    "output_file = 'outputs/bart_disentanglement.csv'\n",
    "output_col = 'bart_tuning_output'\n",
    "\n",
    "# Create Data Loader\n",
    "score_loader = NonToxicScoreDataLoader(output_file, output_col, max_length=256)\n",
    "\n",
    "# Calculate NonToxicScore\n",
    "bart_NonToxicScores, avg_score = NonToxicScore(score_loader, score_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic_text</th>\n",
       "      <th>gold_text</th>\n",
       "      <th>bart_tuning_output</th>\n",
       "      <th>NonToxicScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...</td>\n",
       "      <td>THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...</td>\n",
       "      <td>THERES A MEGATHREAD FOR VACCINE OR COLLABORATE...</td>\n",
       "      <td>0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Because everyone knows why. Its jadas fault. W...</td>\n",
       "      <td>Because everyone knows it's jadas fault. Will ...</td>\n",
       "      <td>Because everyone knows why. Its jadas fault. W...</td>\n",
       "      <td>0.083680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>And poor kids are just as bright as white kids...</td>\n",
       "      <td>He said poor kids are just as bright as white ...</td>\n",
       "      <td>And poor kids are just as bright as white kids...</td>\n",
       "      <td>0.070962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tucker is a garbage person that no one will mi...</td>\n",
       "      <td>Tucker is a bad person who instigates racism</td>\n",
       "      <td>Tucker is a garbage person that no one will mi...</td>\n",
       "      <td>0.007579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fuck off dude. Worst of the fucking worst!</td>\n",
       "      <td>Stop dude. Worst of the worst!</td>\n",
       "      <td>Hey dude. Worst of the worst of the worst!</td>\n",
       "      <td>0.450018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>You mean that chick with a dick?</td>\n",
       "      <td>You mean that transgender woman?</td>\n",
       "      <td>You mean that chick with a gun?</td>\n",
       "      <td>0.039810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Youve been completely subverted yet here you a...</td>\n",
       "      <td>It's a little ironic that you've been subverte...</td>\n",
       "      <td>Youve been completely subverted yet here you a...</td>\n",
       "      <td>0.197244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>I wish I could spit my unvaccinated saliva on ...</td>\n",
       "      <td>I wish I could weaponize my unvaccinated saliva.</td>\n",
       "      <td>I wish I could spit my unvaccinated saliva on ...</td>\n",
       "      <td>0.033816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Formula onenascar.shit it exactly the same exc...</td>\n",
       "      <td>Formula onenascar.it exactly the same except t...</td>\n",
       "      <td>Formula onenascar.com calls it exactly the sam...</td>\n",
       "      <td>0.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>I think you need to check your head</td>\n",
       "      <td>I think you need to check yourself</td>\n",
       "      <td>I think you need to check your head</td>\n",
       "      <td>0.375294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            toxic_text  \\\n",
       "1    THERES A MEGATHREAD FOR VACCINE OR COVID RELAT...   \n",
       "5    Because everyone knows why. Its jadas fault. W...   \n",
       "6    And poor kids are just as bright as white kids...   \n",
       "7    Tucker is a garbage person that no one will mi...   \n",
       "10          Fuck off dude. Worst of the fucking worst!   \n",
       "..                                                 ...   \n",
       "185                   You mean that chick with a dick?   \n",
       "190  Youve been completely subverted yet here you a...   \n",
       "191  I wish I could spit my unvaccinated saliva on ...   \n",
       "195  Formula onenascar.shit it exactly the same exc...   \n",
       "198                I think you need to check your head   \n",
       "\n",
       "                                             gold_text  \\\n",
       "1    THERES ACTUALLY A MEGATHREAD FOR VACCINE OR CO...   \n",
       "5    Because everyone knows it's jadas fault. Will ...   \n",
       "6    He said poor kids are just as bright as white ...   \n",
       "7         Tucker is a bad person who instigates racism   \n",
       "10                      Stop dude. Worst of the worst!   \n",
       "..                                                 ...   \n",
       "185                   You mean that transgender woman?   \n",
       "190  It's a little ironic that you've been subverte...   \n",
       "191   I wish I could weaponize my unvaccinated saliva.   \n",
       "195  Formula onenascar.it exactly the same except t...   \n",
       "198                 I think you need to check yourself   \n",
       "\n",
       "                                    bart_tuning_output  NonToxicScore  \n",
       "1    THERES A MEGATHREAD FOR VACCINE OR COLLABORATE...       0.001780  \n",
       "5    Because everyone knows why. Its jadas fault. W...       0.083680  \n",
       "6    And poor kids are just as bright as white kids...       0.070962  \n",
       "7    Tucker is a garbage person that no one will mi...       0.007579  \n",
       "10          Hey dude. Worst of the worst of the worst!       0.450018  \n",
       "..                                                 ...            ...  \n",
       "185                    You mean that chick with a gun?       0.039810  \n",
       "190  Youve been completely subverted yet here you a...       0.197244  \n",
       "191  I wish I could spit my unvaccinated saliva on ...       0.033816  \n",
       "195  Formula onenascar.com calls it exactly the sam...       0.002139  \n",
       "198                I think you need to check your head       0.375294  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at output texts with low NonToxicScore, or still classified as Toxic after Style Transfering\n",
    "df_finetune['NonToxicScore'] = bart_NonToxicScores\n",
    "\n",
    "df_finetune_lowscore = df_finetune[df_finetune['NonToxicScore'] < 0.5][['toxic_text', 'gold_text', 'bart_tuning_output', 'NonToxicScore']]\n",
    "df_finetune_lowscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Toxic Text: THERES A MEGATHREAD FOR VACCINE OR COVID RELATED TOPICS. DON'T TALK ABOUT THAT SHIT HERE IDIOT!\n",
      "Style Transfer Text: THERES A MEGATHREAD FOR VACCINE OR COLLABORATE RELATED TOPICS. DON'T TALK ABOUT THAT. CLICK HERE IDIOT!\n",
      "NonToxicScore: 0.001779827754944563\n",
      "\n",
      "Toxic Text: Because everyone knows why. Its jadas fault. Will was just triggered because of all the shit he has to deal with because of her.\n",
      "Style Transfer Text: Because everyone knows why. Its jadas fault. Will was just triggered because of all the shit he has to deal with because of her.\n",
      "NonToxicScore: 0.0836801826953888\n",
      "\n",
      "Toxic Text: And poor kids are just as bright as white kids. Your blundering bafoon chooses racism as well\n",
      "Style Transfer Text: And poor kids are just as bright as white kids. Your blundering bafoon chooses racism as well\n",
      "NonToxicScore: 0.07096169143915176\n",
      "\n",
      "Toxic Text: Tucker is a garbage person that no one will miss when hes gone hes also a racist rublerouser\n",
      "Style Transfer Text: Tucker is a garbage person that no one will miss when hes gone hes also a racist rublerouser\n",
      "NonToxicScore: 0.007579335942864418\n",
      "\n",
      "Toxic Text: Fuck off dude. Worst of the fucking worst!\n",
      "Style Transfer Text: Hey dude. Worst of the worst of the worst!\n",
      "NonToxicScore: 0.45001792907714844\n",
      "\n",
      "Toxic Text: This is so cringe. What a fucking loser.\n",
      "Style Transfer Text: This is so cringe. What a loser.\n",
      "NonToxicScore: 0.00854953471571207\n",
      "\n",
      "Toxic Text: What the fuck is this supposed to mean?\n",
      "Style Transfer Text: What the hell is this supposed to mean?\n",
      "NonToxicScore: 0.015962418168783188\n",
      "\n",
      "Toxic Text: Less than no valuethats cute coming from some pretentious douchebag that cant comprehend reading comprehension lol.\n",
      "Style Transfer Text: Less than no valuethats cute coming from some pretentious kid that cant comprehend reading comprehension.\n",
      "NonToxicScore: 0.3437647521495819\n",
      "\n",
      "Toxic Text: But but but what about this other guy. But but but this isn't fair. Whiny ass little babies\n",
      "Style Transfer Text: But but but what about this other guy. But but but this isn't fair. Whiny little babies\n",
      "NonToxicScore: 0.18955440819263458\n",
      "\n",
      "Toxic Text: Stop being a weasel. Address what I actually wrote or fuck off.\n",
      "Style Transfer Text: Stop being a weasel. Address what I actually wrote or said.\n",
      "NonToxicScore: 0.010105091147124767\n",
      "\n",
      "Toxic Text: You are a special kind of idiot.\n",
      "Style Transfer Text: You are a special kind of idiot.\n",
      "NonToxicScore: 0.0016686463495716453\n",
      "\n",
      "Toxic Text: Ya daughter is getting tricked out by Greek Nerds at UNC  NOW im a troll. Just so u know what it looks like\n",
      "Style Transfer Text: Ya daughter is getting tricked out by Greek Nerds at UNC  NOW im a troll. Just so u know what it looks like\n",
      "NonToxicScore: 0.01579446904361248\n",
      "\n",
      "Toxic Text: Really bad stance. What an unbelievable moron you are.\n",
      "Style Transfer Text: Really bad stance. What an unbelievable person you are.\n",
      "NonToxicScore: 0.3835955858230591\n",
      "\n",
      "Toxic Text: The need to feel superior to others is by far the ugliest human trait. You are very very ugly. Eat dicks sizzle tits.\n",
      "Style Transfer Text: The need to feel superior to others is by far the ugliest human trait. You are very very self-absorbed. Eat dicks sizzle.\n",
      "NonToxicScore: 0.0029656768310815096\n",
      "\n",
      "Toxic Text: Lame ass liberal Antifa and Fraudchi style smear. I hope you are woke enough to see what you have coming before it hits you.\n",
      "Style Transfer Text: Lame on you for your liberal Antifa and Frauds. This is a shitshow. This is a political smear. I hope you are woke enough to see what you have coming before it hits you.\n",
      "NonToxicScore: 0.010600537993013859\n",
      "\n",
      "Toxic Text: Bob for president! Stop apologizing to the sodomites!\n",
      "Style Transfer Text: Bob for president! Stop apologizing to the sodomites!\n",
      "NonToxicScore: 0.02798234112560749\n",
      "\n",
      "Toxic Text: Damn you're actually stupid\n",
      "Style Transfer Text: You think you're actually an idiot\n",
      "NonToxicScore: 0.002328812377527356\n",
      "\n",
      "Toxic Text: Like the Dem dope addicts too when they spend their pay on smack and coke for a good rush.\n",
      "Style Transfer Text: Like the Dem dope addicts too when they spend their pay on smack and coke for a good rush.\n",
      "NonToxicScore: 0.014576934278011322\n",
      "\n",
      "Toxic Text: You're sick. Mentally.\n",
      "Style Transfer Text: You're sick. Mentally.\n",
      "NonToxicScore: 0.020667148754000664\n",
      "\n",
      "Toxic Text: They literally steal and sell babies in convenience stores. Sorry but most are scum. a small escape their filthy culture and integrate\n",
      "Style Transfer Text: They literally steal and sell babies in convenience stores. Sorry but most are in the U.S. a small escape from their own culture and society.\n",
      "NonToxicScore: 0.24557490646839142\n",
      "\n",
      "Toxic Text: In other news 40 of Americans are racist homophobic trash and 99 of that trash supports the Republican Party. Draw your own conclusions\n",
      "Style Transfer Text: In other news 40 of Americans are racist or transphobic and 99 of that trash supports the Republican Party. Draw your own conclusions\n",
      "NonToxicScore: 0.12171372026205063\n",
      "\n",
      "Toxic Text: I love ya but men think those nails are corny as fuck. Its like having a neck tatoo\n",
      "Style Transfer Text: I love ya but men think those nails are corny as hell. Its like having a neck tatoo\n",
      "NonToxicScore: 0.021406318992376328\n",
      "\n",
      "Toxic Text: What the fuck is that supposed to even mean? English is my strong suit but Miss Pitt here doesn't sound like she even listens to herself.\n",
      "Style Transfer Text: What the hell is that supposed to even mean? English is my strong suit but Miss Pitt here doesn't sound like she even listens to herself.\n",
      "NonToxicScore: 0.04158861190080643\n",
      "\n",
      "Toxic Text: You're ridiculous and stupid. That's all you get from me.\n",
      "Style Transfer Text: You're ridiculous and stupid. That's all you get from me.\n",
      "NonToxicScore: 0.0035018075723201036\n",
      "\n",
      "Toxic Text: holy shit based\n",
      "Style Transfer Text: holy shit this is not based\n",
      "NonToxicScore: 0.0022682424169033766\n",
      "\n",
      "Toxic Text: Well ketchup and mustard don't give a shit about your feelings and your questions of physics\n",
      "Style Transfer Text: Well ketchup and mustard don't give a shit about your feelings and your questions of physics\n",
      "NonToxicScore: 0.007511931471526623\n",
      "\n",
      "Toxic Text: Yeah that dude is a punk ass\n",
      "Style Transfer Text: Yeah that dude is a dick\n",
      "NonToxicScore: 0.0016119811916723847\n",
      "\n",
      "Toxic Text: Sir this is the ukraine megathread. What the fuck are you on about?\n",
      "Style Transfer Text: Sir this is the ukraine megathread. What the hell are you on about?\n",
      "NonToxicScore: 0.1375780999660492\n",
      "\n",
      "Toxic Text: wtf that old senile delusional fuck said he was sending us more money\n",
      "Style Transfer Text: I think that old senile delusional person said he was sending us more money\n",
      "NonToxicScore: 0.0822131559252739\n",
      "\n",
      "Toxic Text: Whatever. Youre still full of shit and victimhood\n",
      "Style Transfer Text: Whatever. Youre still full of self pity and victimhood\n",
      "NonToxicScore: 0.08637735992670059\n",
      "\n",
      "Toxic Text: Can someone explain to me what the fuck this has to do with socialism?\n",
      "Style Transfer Text: Can someone explain to me what the hell all of this has to do with socialism?\n",
      "NonToxicScore: 0.07041240483522415\n",
      "\n",
      "Toxic Text: Crawl back to your echo chamber, pathetic little worm.\n",
      "Style Transfer Text: \"Crawl back to your echo chamber\n",
      "NonToxicScore: 0.18617992103099823\n",
      "\n",
      "Toxic Text: Why don't you stick to your weird gross rape fantasies and leave economics to the adults?\n",
      "Style Transfer Text: Why don't you stick to your weird gross fantasy fantasies and leave economics to the adults?\n",
      "NonToxicScore: 0.19713632762432098\n",
      "\n",
      "Toxic Text: I'm not OP's husband. What the ever loving fuck is wrong with you people?\n",
      "Style Transfer Text: I'm not OP's husband. What the ever loving shit is wrong with you people?\n",
      "NonToxicScore: 0.006261016242206097\n",
      "\n",
      "Toxic Text: I fucking hate this guy. And everyone else that voted against this.\n",
      "Style Transfer Text: I really hate this guy. And everyone else that voted against this.\n",
      "NonToxicScore: 0.23005793988704681\n",
      "\n",
      "Toxic Text: You're a fucking moron lol\n",
      "Style Transfer Text: You're a fucking moron\n",
      "NonToxicScore: 0.0013028732500970364\n",
      "\n",
      "Toxic Text: Kill all pedos. Why are we entertaining this madness\n",
      "Style Transfer Text: We're all pedos. Why are we entertaining this madness\n",
      "NonToxicScore: 0.005929950159043074\n",
      "\n",
      "Toxic Text: Why do you even contribute when you have nothing of value to share? Seriously choke on your ignorance and die a painful death.\n",
      "Style Transfer Text: Why do you even contribute when you have nothing of value to share? Seriously choke on your ignorance and die a painful death.\n",
      "NonToxicScore: 0.005984685383737087\n",
      "\n",
      "Toxic Text: Go f yourself Republican scum who put us here with your uneducated voting like you even care. I do want to defund the police.\n",
      "Style Transfer Text: Go fucks with the Republican Party who put us here with your uneducated voting like you even care. I do want to defund the police.\n",
      "NonToxicScore: 0.0012665693648159504\n",
      "\n",
      "Toxic Text: Where do you live that is pro democratic because it sure as shit isn't the USA haha\n",
      "Style Transfer Text: Where do you live that is pro democratic because it sure as hell isn't the USA haha\n",
      "NonToxicScore: 0.07055886089801788\n",
      "\n",
      "Toxic Text: The party of accountability and hypocrisy. I wonder how many other investigators got thrown in jail for looking to close.\n",
      "Style Transfer Text: The party of accountability and hypocrisy. I wonder how many other investigators got thrown in jail for looking to close.\n",
      "NonToxicScore: 0.4606316387653351\n",
      "\n",
      "Toxic Text: May Mother Russia spare you from your certain demise\n",
      "Style Transfer Text: May Mother Russia spare you from your certain demise\n",
      "NonToxicScore: 0.051813412457704544\n",
      "\n",
      "Toxic Text: I don't hate transgenders. I hate jousting.\n",
      "Style Transfer Text: I don't hate transgenders. I hate jousting.\n",
      "NonToxicScore: 0.11789695918560028\n",
      "\n",
      "Toxic Text: Boo hoo Im gonna be a poor doctor someday said no one ever. Suck it up pussy\n",
      "Style Transfer Text: Boo hoo Im gonna be a poor doctor someday said no one ever. Shut it up.\n",
      "NonToxicScore: 0.013556684367358685\n",
      "\n",
      "Toxic Text: Umm the first amendment whoopie you ugly cow.\n",
      "Style Transfer Text: Umm the first amendment whoopie you are a cow.\n",
      "NonToxicScore: 0.005811724346131086\n",
      "\n",
      "Toxic Text: I'm glad people still dare ask these questions. The Internet is full of dicks, it's easy to grow timid here.\n",
      "Style Transfer Text: \"I'm glad people still dare ask these questions. The Internet is full of dicks\n",
      "NonToxicScore: 0.005735054612159729\n",
      "\n",
      "Toxic Text: Your tastebuds are FUCKED. Return them or exchange them.\n",
      "Style Transfer Text: Your tastebuds are a waste of time. Return them or exchange them.\n",
      "NonToxicScore: 0.17555327713489532\n",
      "\n",
      "Toxic Text: 90 of truckers are already vaccinated lol. Bunch of bitch ass cry babys\n",
      "Style Transfer Text: 90 of truckers are already vaccinated against measles. Bunch of them will cry\n",
      "NonToxicScore: 0.21529120206832886\n",
      "\n",
      "Toxic Text: If you're a self serving coward then yes\n",
      "Style Transfer Text: If you're a self serving coward then yes\n",
      "NonToxicScore: 0.012665235437452793\n",
      "\n",
      "Toxic Text: if it's past 4 months you're a monster\n",
      "Style Transfer Text: if it's past 4 months you're a monster\n",
      "NonToxicScore: 0.019489355385303497\n",
      "\n",
      "Toxic Text: Yes it was you are a total lying piece of shit.\n",
      "Style Transfer Text: Yes it was you are a total lying piece of shit.\n",
      "NonToxicScore: 0.0014512540074065328\n",
      "\n",
      "Toxic Text: What the hell does your comment have to do with anything?\n",
      "Style Transfer Text: What the hell does your comment have to do with anything?\n",
      "NonToxicScore: 0.01588103361427784\n",
      "\n",
      "Toxic Text: Effing ghouls pushing this bill. Demonic.\n",
      "Style Transfer Text: Effing ghouls pushing this bill.\n",
      "NonToxicScore: 0.006742826662957668\n",
      "\n",
      "Toxic Text: Nazi blood runs deep\n",
      "Style Transfer Text: The blood of the Russian blood runs deep\n",
      "NonToxicScore: 0.4288955330848694\n",
      "\n",
      "Toxic Text: are you fucking retarded? there are literally laws against antisemitism in most western countries. what government is telling their citizens to hate jews?\n",
      "Style Transfer Text: are you a Jew or a Jew? there are literally laws against antisemitism in most western countries. what government is telling their citizens to hate jews?\n",
      "NonToxicScore: 0.024186735972762108\n",
      "\n",
      "Toxic Text: Fuck me reddit has got to have the greatest concentration of brain dead idiots on the whole internet.\n",
      "Style Transfer Text: Because reddit has got to have the greatest concentration of brain dead idiots on the whole internet.\n",
      "NonToxicScore: 0.002856186358258128\n",
      "\n",
      "Toxic Text: Her body her choice Jesus thats such bullshit. I feel sorry for your loss but just know you dodged a bullet. She sounds reckless\n",
      "Style Transfer Text: Her body her choice Jesus thats such a shame. I feel sorry for your loss but just know you dodged a bullet.\n",
      "NonToxicScore: 0.07340802252292633\n",
      "\n",
      "Toxic Text: How do you know Im mocking themAre you pushing your preconceived notions onto me and judging me when maybe I just enjoy it?\n",
      "Style Transfer Text: How do you know Im mocking themAre you pushing your preconceived notions onto me and judging me when maybe I just enjoy it?\n",
      "NonToxicScore: 0.4874475598335266\n",
      "\n",
      "Toxic Text: Holy shit the gaslighting. Do her a favor and move yourself out of her house and just go live in the hotel.\n",
      "Style Transfer Text: Holy shit the gaslighting. Do her a favor and move yourself out of her house and just go live in the hotel.\n",
      "NonToxicScore: 0.004218779504299164\n",
      "\n",
      "Toxic Text: True. We can't pretend neo Nazis are equal to normal human beings. They should be publicly hanged before they infect society\n",
      "Style Transfer Text: True. We can't pretend neo-Nazi cults are equal to normal human beings. They should be publicly hanged before they infect society\n",
      "NonToxicScore: 0.062254924327135086\n",
      "\n",
      "Toxic Text: So lets forget that buddy is traitor? Nah.\n",
      "Style Transfer Text: So lets forget that buddy is traitor? Nah.\n",
      "NonToxicScore: 0.013885400258004665\n",
      "\n",
      "Toxic Text: Too bad she isnt a crack smoking pedophile money embezzler like hunter, then it would be easy to make her look bad.\n",
      "Style Transfer Text: \"Too bad she isnt a crack smoking crack addict or a money embezzler like me.\"\n",
      "NonToxicScore: 0.03257450461387634\n",
      "\n",
      "Toxic Text: Who gives a fuck? Autistic people that can't even look at a camera should not be doing live TV interviews. Pretty simple.\n",
      "Style Transfer Text: Who gives a shit? Autistic people that can't even look at a camera should not be doing live TV interviews. Pretty simple.\n",
      "NonToxicScore: 0.0015506986528635025\n",
      "\n",
      "Toxic Text: You sound so fucking cringe dude haha. Are you a neck beard?\n",
      "Style Transfer Text: You sound so much like a cringe dude haha. Are you a neck beard?\n",
      "NonToxicScore: 0.03626857325434685\n",
      "\n",
      "Toxic Text: You actually fell for that? Youre a retard.\n",
      "Style Transfer Text: You actually fell for that? Youre a fucking moron.\n",
      "NonToxicScore: 0.0012349501485005021\n",
      "\n",
      "Toxic Text: Not a kid defending himself. A little punk bitch who deserves to be unalived.\n",
      "Style Transfer Text: Not a kid defending himself. A little punk. A kid who deserves to be unalived.\n",
      "NonToxicScore: 0.3136787414550781\n",
      "\n",
      "Toxic Text: Shut up, atheism is gay\n",
      "Style Transfer Text: \"Shut up. You're a fucking idiot.\"\n",
      "NonToxicScore: 0.001251733279787004\n",
      "\n",
      "Toxic Text: You are obviously a homofobe\n",
      "Style Transfer Text: You are obviously a non-follower\n",
      "NonToxicScore: 0.30786022543907166\n",
      "\n",
      "Toxic Text: You're on the wrong subreddit to be spewing that kind of shit. Shut the fuck up now.\n",
      "Style Transfer Text: You're on the wrong subreddit to be spewing that kind of stuff. Shut the fuck up now.\n",
      "NonToxicScore: 0.0015881411964073777\n",
      "\n",
      "Toxic Text: You cant clean yourself if your brain is all fucked up?\n",
      "Style Transfer Text: You cant clean yourself if your brain is all messed up?\n",
      "NonToxicScore: 0.062241747975349426\n",
      "\n",
      "Toxic Text: You're a moron, holy sht. Lol\n",
      "Style Transfer Text: \"You're a moron.\"\n",
      "NonToxicScore: 0.0015171364648267627\n",
      "\n",
      "Toxic Text: What's the conspiracy? Lol. People not liking a group of likeminded assholes that you happen to like isn't a conspiracy\n",
      "Style Transfer Text: What's the conspiracy? It's not a conspiracy. People not liking a group of likeminded assholes that you happen to like isn't a conspiracy\n",
      "NonToxicScore: 0.007132941856980324\n",
      "\n",
      "Toxic Text: Grow the fuck up\n",
      "Style Transfer Text: Grow the hell out of it\n",
      "NonToxicScore: 0.027144502848386765\n",
      "\n",
      "Toxic Text: You call them journalists? You are laughably ignorant.\n",
      "Style Transfer Text: You call them journalists? You are laughably ignorant.\n",
      "NonToxicScore: 0.11662966012954712\n",
      "\n",
      "Toxic Text: You guys love oppression. Let me get some barbecue recipes. I know you Klansmen are always having cookouts.\n",
      "Style Transfer Text: You guys love oppression. Let me get some barbecue recipes. I know you Klansmen are always having cookouts.\n",
      "NonToxicScore: 0.12138096988201141\n",
      "\n",
      "Toxic Text: You mean that chick with a dick?\n",
      "Style Transfer Text: You mean that chick with a gun?\n",
      "NonToxicScore: 0.039810340851545334\n",
      "\n",
      "Toxic Text: Youve been completely subverted yet here you are talking about brainwashing. \n",
      "Style Transfer Text: Youve been completely subverted yet here you are talking about brainwashing. \n",
      "NonToxicScore: 0.19724401831626892\n",
      "\n",
      "Toxic Text: I wish I could spit my unvaccinated saliva on you and your family.\n",
      "Style Transfer Text: I wish I could spit my unvaccinated saliva on you and your family.\n",
      "NonToxicScore: 0.033816203474998474\n",
      "\n",
      "Toxic Text: Formula onenascar.shit it exactly the same except the former has lighter cars. Who can turn left faster? The answer is! Who gives a shit.\n",
      "Style Transfer Text: Formula onenascar.com calls it exactly the same except the former has lighter cars. Who can turn left faster? The answer is! Who gives a shit?\n",
      "NonToxicScore: 0.0021393755450844765\n",
      "\n",
      "Toxic Text: I think you need to check your head\n",
      "Style Transfer Text: I think you need to check your head\n",
      "NonToxicScore: 0.3752938210964203\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_finetune_lowscore)):\n",
    "    print('\\nToxic Text:', df_finetune_lowscore['toxic_text'].values[i])\n",
    "    print('Style Transfer Text:', df_finetune_lowscore.bart_tuning_output.values[i])\n",
    "    print('NonToxicScore:', df_finetune_lowscore.NonToxicScore.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b0c5850cb34d9ba379ee1be617562e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0728ff82b36a4e37804cb78f206e303a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09a56244a41a4cb8819cd2f5dcb3fa65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13b5b78fbd7e4891a7bd12b75959d68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18bb04646fda4b15966aa55319c3e68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe67ed2807164a46987206140fe1ce2d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13b5b78fbd7e4891a7bd12b75959d68e",
      "value": " 899k/899k [00:01&lt;00:00, 793kB/s]"
     }
    },
    "1ef965c9468f474daac37eb05070c25a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2075efe3dbc84d74b952098924b9ef77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a65bcddc1814b21979aa81aab403791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb9f5fe70f0545608868629eace167cc",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ef965c9468f474daac37eb05070c25a",
      "value": 898822
     }
    },
    "2da161b715b74d01ba43de99e24e1a26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02b0c5850cb34d9ba379ee1be617562e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bc7d0f3ae3f84ab09f43c99ff38632a8",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.36kB/s]"
     }
    },
    "2ead1ad0b47e4f3cb5ba69000745ca8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "387a81cc4f9641cb915c7f535fbe8237": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ff802333c1b42e2960b84a3fa241cdc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_09a56244a41a4cb8819cd2f5dcb3fa65",
      "value": "Downloading (â€¦)lve/main/config.json: 100%"
     }
    },
    "3bf35c62d4fd466b977e55abafd9d4bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c84b56ae7cf4e0a802095b58b6778dd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_56201afcc93c46d58c8eabf5992ea97c",
      "value": "Downloading (â€¦)okenizer_config.json: 100%"
     }
    },
    "43bccf112aa44ca29629059ac7ad15f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cf84d9d3d3c41e18e0124ba1dcab703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c580c5cd4717476e88af0764163aafcd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_68bd169a0d1046acab4026a691b6bb86",
      "value": " 456k/456k [00:00&lt;00:00, 499kB/s]"
     }
    },
    "519f4fb921f84db6b00aff550f0f8ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51c317efff0445179f80feb67fc1c3bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_387a81cc4f9641cb915c7f535fbe8237",
       "IPY_MODEL_ca7c7964dc8947b09d43faae4f669567",
       "IPY_MODEL_daafdd68bcde439aaeca4af2cf6650db"
      ],
      "layout": "IPY_MODEL_bcd6ef30bb2e45e4a06d25b7d41699d8"
     }
    },
    "56201afcc93c46d58c8eabf5992ea97c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c84b56ae7cf4e0a802095b58b6778dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ff802333c1b42e2960b84a3fa241cdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6407a563ae7548fa864fb25c3c4150b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68bd169a0d1046acab4026a691b6bb86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "776dccd4f64f4ee896282f0ded9ce3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8753ca26301a4528bb4d5151a7f84c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bf35c62d4fd466b977e55abafd9d4bb",
       "IPY_MODEL_937e475849034a8aba7316f8f93442ed",
       "IPY_MODEL_2da161b715b74d01ba43de99e24e1a26"
      ],
      "layout": "IPY_MODEL_f85824f59e4849f788892a83313c0d49"
     }
    },
    "8a9e8c2ed54340269589531e8b358589": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "937e475849034a8aba7316f8f93442ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7cdecdcb3ce42409beceeefbc2176bf",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_776dccd4f64f4ee896282f0ded9ce3c5",
      "value": 26
     }
    },
    "9d21fe3f1f8d45ed99c14942744e248e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a05189dbb05b4a299bff1cbc866ef971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2075efe3dbc84d74b952098924b9ef77",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43bccf112aa44ca29629059ac7ad15f5",
      "value": 456318
     }
    },
    "ab11d7e884244bddb0788d8756ce2738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff35596ab5694974927e3423c3b949ae",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_519f4fb921f84db6b00aff550f0f8ef5",
      "value": "Downloading (â€¦)olve/main/vocab.json: 100%"
     }
    },
    "abd7eb5376f743acb4561d68f03ab182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e038632b529b42528e0d4133acaa93ab",
       "IPY_MODEL_a05189dbb05b4a299bff1cbc866ef971",
       "IPY_MODEL_4cf84d9d3d3c41e18e0124ba1dcab703"
      ],
      "layout": "IPY_MODEL_b8932123fe5844eeae163fd56c2000e9"
     }
    },
    "b69be31f5fb149439a24993a439a9d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab11d7e884244bddb0788d8756ce2738",
       "IPY_MODEL_2a65bcddc1814b21979aa81aab403791",
       "IPY_MODEL_18bb04646fda4b15966aa55319c3e68d"
      ],
      "layout": "IPY_MODEL_6407a563ae7548fa864fb25c3c4150b6"
     }
    },
    "b8932123fe5844eeae163fd56c2000e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc7d0f3ae3f84ab09f43c99ff38632a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcd6ef30bb2e45e4a06d25b7d41699d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c580c5cd4717476e88af0764163aafcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca7c7964dc8947b09d43faae4f669567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0728ff82b36a4e37804cb78f206e303a",
      "max": 1628,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4dec7f9dcc04b638efc94011f908426",
      "value": 1628
     }
    },
    "daafdd68bcde439aaeca4af2cf6650db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ead1ad0b47e4f3cb5ba69000745ca8e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dc2e4ac6df04464cbde84ac31dd14c15",
      "value": " 1.63k/1.63k [00:00&lt;00:00, 60.6kB/s]"
     }
    },
    "dc2e4ac6df04464cbde84ac31dd14c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e038632b529b42528e0d4133acaa93ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a9e8c2ed54340269589531e8b358589",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9d21fe3f1f8d45ed99c14942744e248e",
      "value": "Downloading (â€¦)olve/main/merges.txt: 100%"
     }
    },
    "e4dec7f9dcc04b638efc94011f908426": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb9f5fe70f0545608868629eace167cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7cdecdcb3ce42409beceeefbc2176bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85824f59e4849f788892a83313c0d49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe67ed2807164a46987206140fe1ce2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff35596ab5694974927e3423c3b949ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
